{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "py36",
      "language": "python",
      "name": "py36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "probability_programing_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FHS5gW_4KcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import reduce\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.distributions as torchdist\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "from collections import OrderedDict\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHXusc_94Kce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normal_dist = torchdist.Normal(loc=torch.tensor(0.), scale=torch.tensor(1.))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arqd0dwN4Kcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = normal_dist.sample()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRUN8aC74Kcn",
        "colab_type": "code",
        "outputId": "75ba9a08-1477-4e4e-c83b-083918a6b01d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.1703)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHfTqG-_4Kcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = normal_dist.sample([100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUcBotC74Kcw",
        "colab_type": "code",
        "outputId": "d71c3080-be7e-4a89-9b96-2cb151fffbf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9.5947e-01, -5.6808e-01,  2.2568e+00,  1.6878e+00, -8.3937e-02,\n",
              "         2.1099e-01, -3.0872e-01, -1.2366e-01, -1.2864e+00, -1.8052e-01,\n",
              "        -7.4491e-01,  6.2527e-01, -1.2256e+00,  6.8100e-01, -2.6506e-01,\n",
              "         7.3905e-01, -1.0274e-03,  5.8095e-01, -6.2256e-01, -1.2663e+00,\n",
              "        -1.8376e-01, -8.3729e-01,  3.5513e-01, -1.2916e-01, -8.1556e-01,\n",
              "         1.5365e+00,  3.0820e-01, -2.3973e-01,  6.9910e-01,  1.2599e+00,\n",
              "         4.9197e-01, -3.6305e-01,  1.6510e-01,  1.9559e+00, -2.0298e-01,\n",
              "        -7.4663e-01, -7.3795e-01, -7.9270e-01, -1.7287e-01,  1.5130e+00,\n",
              "         1.8305e+00, -6.7202e-01,  2.3165e-01, -1.3704e+00, -4.1486e-02,\n",
              "        -3.2633e-01,  2.1755e+00, -4.2317e-01,  1.0028e+00, -3.5716e-01,\n",
              "        -7.4725e-01, -1.3898e+00,  6.5268e-01,  5.2362e-01, -2.6940e-02,\n",
              "         1.3372e+00,  5.5868e-01,  8.1047e-01,  1.0785e+00, -5.1183e-02,\n",
              "         1.2227e-01, -1.4348e+00,  1.9163e+00, -2.7883e-01,  1.0212e-01,\n",
              "         1.4102e-01,  7.5990e-01,  5.6817e-01,  1.3345e+00, -7.5024e-01,\n",
              "         6.6308e-01, -2.8424e-01, -1.4894e+00,  4.1763e-01, -4.3443e-01,\n",
              "        -1.2544e+00,  7.3723e-01, -1.1365e+00, -1.1011e-01,  1.7391e+00,\n",
              "         6.7028e-01, -1.7803e-01, -3.9668e-01,  1.6380e+00, -9.1901e-01,\n",
              "        -1.4391e+00,  2.8523e-01, -1.0914e+00, -1.6404e+00, -8.1248e-02,\n",
              "        -5.9547e-01, -1.8518e+00, -1.3661e+00, -2.8771e-01, -8.7990e-01,\n",
              "         3.1257e-01, -9.5667e-01,  1.0808e+00,  4.4896e-01,  4.5069e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vqfszqY4Kc0",
        "colab_type": "code",
        "outputId": "becb843f-a60e-443d-d45d-b6de1dbb57c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "plt.hist(x.detach().numpy())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 3., 11., 13., 14., 18., 14., 12.,  5.,  6.,  4.]),\n",
              " array([-1.8517666 , -1.4409101 , -1.0300537 , -0.61919725, -0.20834084,\n",
              "         0.2025156 ,  0.613372  ,  1.0242285 ,  1.4350849 ,  1.8459413 ,\n",
              "         2.2567978 ], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T29uQgj4Kc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toy_poly():\n",
        "    x = 5 * torch.rand(100, 1)\n",
        "    # linear_op = -3 - 4*x + x**2\n",
        "    linear_op = 4 * torch.sin(x*2)\n",
        "    y = torchdist.Normal(linear_op, 1).sample()\n",
        "    return x, y\n",
        "\n",
        "x_train, y_train = toy_poly()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uBU48pX4Kc9",
        "colab_type": "code",
        "outputId": "90f0fc70-9973-468a-94cb-42395b8a6a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(x_train.numpy(), y_train.numpy(), 'o')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb296685e80>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SacrOGtmAxEt",
        "colab_type": "text"
      },
      "source": [
        "### multivariable gaussian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAKYYp1sIT2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomMultivariateNormal(torch.distributions.MultivariateNormal):\n",
        "    def __init__(self, loc, covariance_matrix=None, precision_matrix=None, scale_tril=None, validate_args=None):\n",
        "        super(CustomMultivariateNormal, self).__init__(\n",
        "            loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\n",
        "\n",
        "    def __getattribute__(self, name):        \n",
        "        if name == '_unbroadcasted_scale_tril':            \n",
        "            # return F.relu(object.__getattribute__(self, name)) + 1e-4\n",
        "            return F.relu(object.__getattribute__(self, name)).clamp(min=1e-8)\n",
        "            # return torch.exp(object.__getattribute__(self, name))\n",
        "        else:            \n",
        "            return object.__getattribute__(self, name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XK-k4eeAwwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "decb2d5b-183f-4f24-bac1-9c16537af44b"
      },
      "source": [
        "n_dim = 2\n",
        "mu = nn.Parameter(torch.zeros(n_dim))\n",
        "# log_sigma = nn.Parameter(torch.eye(n_dim).clamp(min=1e-8).log())\n",
        "# sigma = torch.exp(log_sigma)\n",
        "sigma = nn.Parameter(torch.cholesky(torch.eye(n_dim).clamp(1e-4)))\n",
        "# sigma = nn.Parameter(torch.tensor([[2., 0.],[1., 1.]]).clamp(min=1e-4))\n",
        "\n",
        "print(sigma)\n",
        "# mvn = torchdist.MultivariateNormal(loc=mu, covariance_matrix=sigma)\n",
        "mvn = CustomMultivariateNormal(loc=mu, scale_tril=sigma)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e-04, 1.0000e+00]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq3ZayBPfqcT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6e8b1dca-6a8c-41b2-ff49-8a6ade67cf93"
      },
      "source": [
        "x1 = torch.tensor([3.0], requires_grad=True)\n",
        "x2 = torch.tensor([0.0], requires_grad=True)\n",
        "y = 2 * x1 + 3 * x2 + 1\n",
        "y.backward()\n",
        "print(x1.grad)\n",
        "print(x2.grad)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.])\n",
            "tensor([3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjkYQ-g6Skb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4055feb2-1256-4771-cdfa-601a9e810746"
      },
      "source": [
        "a = mvn.rsample()\n",
        "b = a.mean()\n",
        "print(b.item())\n",
        "b.backward()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.012288033962249756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68seXm4aS61v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "13d22a77-9599-4d39-fbc7-4f900f9ad0bc"
      },
      "source": [
        "print(mu.grad)\n",
        "print(sigma.grad)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.5000, 0.5000])\n",
            "tensor([[-0.3164,  0.0000],\n",
            "        [-0.3164,  0.3287]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9DCDGJ8lLe3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c223053b-e844-4df0-f6a2-0a7ae366fc0a"
      },
      "source": [
        "a = torch.eye(3) + 1e-8\n",
        "a1 = torch.cholesky(a)\n",
        "print(a1)\n",
        "b = a1.log()\n",
        "print(b)\n",
        "c = b.exp()\n",
        "print(c)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e-08, 1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e-08, 1.0000e-08, 1.0000e+00]])\n",
            "tensor([[  0.0000,     -inf,     -inf],\n",
            "        [-18.4207,   0.0000,     -inf],\n",
            "        [-18.4207, -18.4207,   0.0000]])\n",
            "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e-08, 1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e-08, 1.0000e-08, 1.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx1QdHSv9t1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ParameterDistribution2:\n",
        "    def __init__(self, dist, loc_dict):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        dist: torch.distributions.distribution.Distribution            \n",
        "        \"\"\"\n",
        "        if not isinstance(dist, torch.distributions.Distribution):\n",
        "            raise ValueError('dist must be torch.distributions.Distribution')\n",
        "        self.dist = dist\n",
        "        self.loc_dict = loc_dict\n",
        "\n",
        "    def sample(self):\n",
        "        with torch.no_grad():        \n",
        "            w_sample = self.rsample()\n",
        "        return w_sample\n",
        "\n",
        "    def rsample(self):\n",
        "        sample_1d = self.dist.rsample()\n",
        "        w_sample = OrderedDict()\n",
        "        for n, loc_info in self.loc_dict.items():\n",
        "            loc = loc_info['loc']\n",
        "            size = loc_info['size']\n",
        "            sample = sample_1d[slice(*loc)]\n",
        "            w_sample[n] = sample.view(*size)\n",
        "\n",
        "        return w_sample\n",
        "\n",
        "    def log_prob(self, w):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        w: dict\n",
        "            key: parameter name\n",
        "            value: torch.Tensor\n",
        "        \"\"\" \n",
        "        return self.dist.log_prob(w)\n",
        "\n",
        "def transform_param(w, loc_dict):\n",
        "    param_dict = OrderedDict()\n",
        "    for n, loc_info in loc_dict.items():\n",
        "        loc = loc_info['loc']\n",
        "        size = loc_info['size']\n",
        "        sample = w[slice(*loc)]\n",
        "        param_dict[n] = sample.view(*size)\n",
        "\n",
        "    return param_dict\n",
        "\n",
        "\n",
        "class VIModel2(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(VIModel2, self).__init__()\n",
        "        self.loc_dict, n_dim = self.get_params(model)\n",
        "        \n",
        "        self.mu = nn.Parameter(torch.zeros(n_dim))\n",
        "        \n",
        "        # self.sigma = nn.Parameter(torch.eye(n_dim))\n",
        "        self.sigma = nn.Parameter(torch.cholesky(torch.eye(n_dim).clamp(1e-8)))\n",
        "        # self.sigma = nn.Parameter(torch.eye(n_dim).clamp(1e-8))\n",
        "        # TODO: __init__の中でcovariance_matrixをいじっているため2回目のbackwardで引っかかる\n",
        "        self.dist = CustomMultivariateNormal(loc=self.mu, scale_tril=self.sigma)\n",
        "\n",
        "        # log_sigma = torch.cholesky(torch.eye(n_dim) + 1e-8).log() - 32\n",
        "        # self.log_sigma = nn.Parameter(log_sigma)\n",
        "        # self.dist = CustomMultivariateNormal(loc=self.mu, scale_tril=self.log_sigma)\n",
        "\n",
        "    def get_params(self, model):\n",
        "        start = 0\n",
        "        loc_dict = OrderedDict()\n",
        "        for n, p in model.named_parameters():\n",
        "            num = reduce(lambda x, y: x*y, p.size())\n",
        "            end = start + num\n",
        "            loc_info = {\n",
        "                'size': p.size(),\n",
        "                'loc': (start, end)\n",
        "            }\n",
        "            start = end\n",
        "            \n",
        "            loc_dict[n] = loc_info\n",
        "        \n",
        "        n_dim = start\n",
        "        print(loc_dict)\n",
        "        print(n_dim)\n",
        "        return loc_dict, n_dim\n",
        "\n",
        "def normal_prior_distV2(model):\n",
        "    n_dim = 0\n",
        "    for n, p in model.named_parameters():\n",
        "        num = reduce(lambda x, y: x*y, p.size())\n",
        "        n_dim += num\n",
        "\n",
        "    mu = torch.zeros(n_dim)\n",
        "    sigma = torch.eye(n_dim) * 10\n",
        "    # dist = torchdist.MultivariateNormal(loc=mu, scale_tril=sigma)\n",
        "    dist = CustomMultivariateNormal(loc=mu, scale_tril=sigma)\n",
        "    return dist\n",
        "\n",
        "def kl_divergenceV2(q_w, p_w, loc_dict, model, x, y, idx):\n",
        "\n",
        "    # sampling from q(w)\n",
        "    w_sample = q_w.rsample()\n",
        "    # print('w_sample', w_sample)\n",
        "\n",
        "    param_dict = transform_param(w_sample, loc_dict)\n",
        "    # print('param_dict', param_dict)\n",
        "    model.set_params(param_dict)\n",
        "\n",
        "    # calculate f(x)\n",
        "    # p(y|x,w) = N(f(x; w), 1)\n",
        "    out1, out2 = model(x)\n",
        "    if out1.size(-1) != 1:\n",
        "        raise ValueError\n",
        "\n",
        "    # print('output', output)\n",
        "    p_y_xw = torchdist.Normal(out1, torch.ones_like(out1))\n",
        "    # p_y_xw = torchdist.Normal(out1, out2)\n",
        "\n",
        "    # log(p(w, x, y)) = log(p(w)) + sum(log(p(y|x,w)))\n",
        "    val_log_p_w = p_w.log_prob(w_sample)\n",
        "    # val_log_p_y_xw = p_y_xw.log_prob(y).mean()    \n",
        "    val_log_p_y_xw = p_y_xw.log_prob(y).sum()\n",
        "    # val_log_q_w = q_w.log_prob(w_sample)\n",
        "    val_log_q_w = -q_w.entropy()\n",
        "\n",
        "    if (idx+1) % 100 == 0:\n",
        "        out_desc = out1.detach()\n",
        "        print('%d loss q(w) %f p(w) %f p(y|xw) %f min %f mean %f max %f' \n",
        "              % (idx, val_log_q_w.item(), val_log_p_w.item(), val_log_p_y_xw.item(), \n",
        "                 out_desc.min(), out_desc.mean(), out_desc.max()))\n",
        "    \n",
        "    return val_log_q_w - val_log_p_w - val_log_p_y_xw\n",
        "    # return val_log_q_w - val_log_p_y_xw\n",
        "    # return - val_log_p_y_xw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1o0zKSIvJGJ",
        "colab_type": "text"
      },
      "source": [
        "## module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHSGmEYg94QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomNormal(torch.distributions.Normal):\n",
        "    def __init__(self, loc, scale, validate_args=None, eps=1e-4):\n",
        "        super(CustomNormal, self).__init__(loc, scale, validate_args)\n",
        "        self.eps = eps\n",
        "\n",
        "    def __getattribute__(self, name):        \n",
        "        if name == 'scale':            \n",
        "            return torch.exp(object.__getattribute__(self, name)).clamp(min=self.eps)\n",
        "        else:            \n",
        "            return object.__getattribute__(self, name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTV0IcEsvItt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TensorModule:\n",
        "    def __init__(self):\n",
        "        self.training = True\n",
        "        self._parameters = OrderedDict()\n",
        "        self._modules = OrderedDict()\n",
        "        self._tmodules = OrderedDict()\n",
        "        self._buffers = OrderedDict()\n",
        "\n",
        "    def __call__(self, *input, **kwargs):\n",
        "        result = self.forward(*input, **kwargs)\n",
        "        return result\n",
        "    \n",
        "    def forward(self, *input):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __setattr__(self, name, value):\n",
        "        def remove_from(*dicts):\n",
        "            for d in dicts:\n",
        "                if name in d:\n",
        "                    del d[name]\n",
        "\n",
        "        params = self.__dict__.get('_parameters')\n",
        "        if name.startswith('p_') and isinstance(value, torch.Tensor):\n",
        "            if params is None:\n",
        "                raise AttributeError\n",
        "            remove_from(self.__dict__, self._buffers, self._modules)\n",
        "            self.register_parameter(name, value)\n",
        "        elif params is not None and name in params:\n",
        "            if value is not None:\n",
        "                raise TypeError\n",
        "            self.register_parameter(name, value)\n",
        "        else:\n",
        "            modules = self.__dict__.get('_modules')\n",
        "            if isinstance(value, TensorModule):\n",
        "                if modules is None:\n",
        "                    raise AttributeError\n",
        "                remove_from(self.__dict__, self._parameters, self._buffers)\n",
        "                modules[name] = value\n",
        "            elif modules is not None and name in modules:\n",
        "                if value is not None:\n",
        "                    raise TypeError\n",
        "                modules[name] = value\n",
        "            else:\n",
        "                buffers = self.__dict__.get('_buffers')\n",
        "                if buffers is not None and name in buffers:\n",
        "                    if value is not None and not isinstance(value, torch.Tensor):\n",
        "                        raise TypeError\n",
        "                    buffers[name] = value\n",
        "                else:\n",
        "                    object.__setattr__(self, name, value)\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        if '_parameters' in self.__dict__:\n",
        "            _parameters = self.__dict__['_parameters']\n",
        "            if name in _parameters:\n",
        "                return _parameters[name]\n",
        "\n",
        "        if '_buffers' in self.__dict__:\n",
        "            _buffers = self.__dict__['_buffers']\n",
        "            if name in _buffers:\n",
        "                return _buffers[name]\n",
        "        \n",
        "        if '_modules' in self.__dict__:\n",
        "            _modules = self.__dict__['_modules']\n",
        "            if name in _modules:\n",
        "                return _modules[name]\n",
        "\n",
        "    def register_parameter(self, name, param):\n",
        "        # debug\n",
        "        if name in self._parameters:\n",
        "            prev_param = self._parameters[name]\n",
        "        else:\n",
        "            prev_param = None\n",
        "        # print('%s: %s -> %s' % (name, str(prev_param), str(param)))\n",
        "\n",
        "        if '.' in name:\n",
        "            raise KeyError\n",
        "\n",
        "        if param is None:\n",
        "            self._parameters[name] = None\n",
        "        elif not isinstance(param, torch.Tensor):\n",
        "            raise TypeError\n",
        "        else:\n",
        "            self._parameters[name] = param\n",
        "\n",
        "    def register_buffer(self, name, tensor):\n",
        "        if '.' in name:\n",
        "            raise KeyError\n",
        "        elif tensor is not None and not isinstance(tensor, torch.Tensor):\n",
        "            raise TypeError\n",
        "        else:\n",
        "            self._buffers[name] = tensor\n",
        "\n",
        "    def named_modules(self, memo=None, prefix=''):\n",
        "        if memo is None:\n",
        "            memo = set()\n",
        "        if self not in memo:\n",
        "            memo.add(self)\n",
        "            yield prefix, self\n",
        "            for name, module in self._modules.items():\n",
        "                if module is None:\n",
        "                    continue\n",
        "                submodule_prefix = prefix + ('.' if prefix else '') + name\n",
        "                for m in module.named_modules(memo, submodule_prefix):\n",
        "                    yield m   \n",
        "\n",
        "    def _named_members(self, get_members_fn, prefix='', recurse=True):\n",
        "        memo = set()\n",
        "        modules = self.named_modules(prefix=prefix) if recurse else [(prefix, self)]\n",
        "        for module_prefix, module in modules:\n",
        "            members = get_members_fn(module)\n",
        "            for k, v in members:\n",
        "                if v is None or v in memo:\n",
        "                    continue\n",
        "                memo.add(v)\n",
        "                name = module_prefix + ('.' if module_prefix else '') + k\n",
        "                yield name, v\n",
        "\n",
        "    def named_parameters(self, prefix='', recurse=True):\n",
        "        gen = self._named_members(\n",
        "            lambda module: module._parameters.items(),\n",
        "            prefix=prefix, recurse=True\n",
        "        )\n",
        "        for elem in gen:\n",
        "            yield elem\n",
        "\n",
        "    def _load_from_state_dict(self, state_dict, prefix):\n",
        "        local_name_params = itertools.chain(self._parameters.items(), self._buffers.items())\n",
        "        local_state = {k: v for k, v in local_name_params if v is not None}\n",
        "\n",
        "        for name, param in local_state.items():\n",
        "            key = prefix + name\n",
        "            if key in state_dict:\n",
        "                input_param = state_dict[key]\n",
        "                setattr(self, name, input_param)\n",
        "                # with torch.no_grad():                        \n",
        "                # param.copy_(input_param)\n",
        "\n",
        "    def set_params(self, state_dict):\n",
        "        def load(module, prefix=''):\n",
        "            module._load_from_state_dict(state_dict, prefix)\n",
        "        \n",
        "            for name, child in module._modules.items():\n",
        "                if child is not None:\n",
        "                    load(child, prefix + name + '.')\n",
        "        load(self)\n",
        "        load = None\n",
        "        \n",
        "    def train(self, mode=True):\n",
        "        self.training =  mode\n",
        "        for module in self.children():\n",
        "            module.train(mode)\n",
        "        return self\n",
        "\n",
        "    def eval(self):\n",
        "        return self.train(False)\n",
        "\n",
        "    def children(self):\n",
        "        for name, module in self.named_children():\n",
        "            yield module\n",
        "\n",
        "    def named_children(self):\n",
        "        memo = set()\n",
        "        for name, module in self._modules.items():\n",
        "            if module is not None and module not in memo:\n",
        "                memo.add(module)\n",
        "                yield name, module\n",
        "\n",
        "class TensorLinear(TensorModule):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(TensorLinear, self).__init__()\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        # self.weight = TensorParameter((out_features, in_features))\n",
        "        self.p_weight = torch.zeros((out_features, in_features), dtype=torch.float32)\n",
        "        if bias:\n",
        "            self.p_bias = torch.zeros((out_features, ), dtype=torch.float32)\n",
        "        else:\n",
        "            # original self.register_parameter('bias', None)\n",
        "            self.p_bias = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.linear(input, self.p_weight, self.p_bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq8VmrS7g_WM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class _NormBase(TensorModule):\n",
        "    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True,\n",
        "                 track_running_stats=True):\n",
        "        super(_NormBase, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.affine = affine\n",
        "        self.track_running_stats = track_running_stats\n",
        "        if self.affine:\n",
        "            self.p_weight = torch.Tensor(num_features)\n",
        "            self.p_bias = torch.Tensor(num_features)\n",
        "        else:\n",
        "            self.register_parameter('p_weight', None)\n",
        "            self.register_parameter('p_bias', None)\n",
        "        if self.track_running_stats:\n",
        "            self.register_buffer('running_mean', torch.zeros(num_features))\n",
        "            self.register_buffer('running_var', torch.ones(num_features))\n",
        "            self.register_buffer('num_batches_tracked', torch.tensor(0, dtype=torch.long))\n",
        "        else:\n",
        "            self.register_parameter('running_mean', None)\n",
        "            self.register_parameter('running_var', None)\n",
        "            self.register_parameter('num_batches_tracked', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_running_stats(self):\n",
        "        if self.track_running_stats:\n",
        "            self.running_mean.zero_()\n",
        "            self.running_var.fill_(1)\n",
        "            self.num_batches_tracked.zero_()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.reset_running_stats()\n",
        "        if self.affine:\n",
        "            torch.nn.init.ones_(self.p_weight)\n",
        "            torch.nn.init.zeros_(self.p_bias)\n",
        "\n",
        "class _BatchNorm(_NormBase):\n",
        "    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True, \n",
        "                 track_running_stats=True):\n",
        "        super(_BatchNorm, self).__init__(num_features, eps, momentum, affine,\n",
        "                                         track_running_stats)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        self._check_input_dim(input)\n",
        "\n",
        "        if self.momentum is None:\n",
        "            exponential_average_factor = 0.0\n",
        "        else:\n",
        "            exponential_average_factor = self.momentum\n",
        "\n",
        "        if self.training and self.track_running_stats:            \n",
        "            if self.num_batches_tracked is not None:\n",
        "                self.num_batches_tracked = self.num_batches_tracked + 1\n",
        "                if self.momentum is None:  # use cumulative moving average\n",
        "                    exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n",
        "                else:  # use exponential moving average\n",
        "                    exponential_average_factor = self.momentum\n",
        "\n",
        "        return F.batch_norm(\n",
        "            input, self.running_mean, self.running_var, self.p_weight, self.p_bias,\n",
        "            self.training or not self.track_running_stats,\n",
        "            exponential_average_factor, self.eps)\n",
        "        \n",
        "\n",
        "class TensorBatchNorm1d(_BatchNorm):\n",
        "    def _check_input_dim(self, input):\n",
        "        if input.dim() != 2 and input.dim() !=3:\n",
        "            raise ValueError('invalid dim')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnsg0P_Kttn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TensorLinearNet(TensorModule):\n",
        "    def __init__(self):\n",
        "        super(TensorLinearNet, self).__init__()\n",
        "        n = 8\n",
        "        self.linear1 = TensorLinear(1, n)\n",
        "        self.linear2 = TensorLinear(n, n)\n",
        "        # self.linear3 = TensorLinear(n, n)\n",
        "        # self.linear4 = TensorLinear(n, n)\n",
        "\n",
        "        self.last_layer = TensorLinear(n, 1)\n",
        "\n",
        "        self.bn1 = TensorBatchNorm1d(n)\n",
        "        self.bn2 = TensorBatchNorm1d(n)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.linear2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # x = self.linear3(x)\n",
        "        # x = F.relu(x)\n",
        "\n",
        "        # x = self.linear4(x)\n",
        "        x = self.last_layer(x)\n",
        "\n",
        "        x1 = x\n",
        "        x2 = None\n",
        "\n",
        "        return x1, x2\n",
        "\n",
        "class TensorLinearNet2(TensorModule):\n",
        "    def __init__(self):\n",
        "        super(TensorLinearNet2, self).__init__()\n",
        "        self.linear11 = TensorLinear(1, 8)\n",
        "        self.linear12 = TensorLinear(8, 1)\n",
        "        self.linear21 = TensorLinear(1, 8)\n",
        "        self.linear22 = TensorLinear(8, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.linear11(x)        \n",
        "        x = self.relu(x)\n",
        "        x = self.linear12(x)\n",
        "\n",
        "        x2 = x*x\n",
        "        x2 = self.linear21(x2)\n",
        "        x2 = self.relu(x2)\n",
        "        x2 = self.linear22(x2)\n",
        "        \n",
        "        x = x + x2\n",
        "        \n",
        "        return x, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezTSw0Np4KdA",
        "colab_type": "text"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_vkvU5W4KdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearNet, self).__init__()\n",
        "        \n",
        "    def forward(self, w, x):\n",
        "        \"\"\"\n",
        "        w: shape of (3,)\n",
        "        x: shape of (batch,)\n",
        "        \"\"\"\n",
        "        #         phi_x = torch.tensor([])\n",
        "        y = w[0] + w[1]*x + w[2]*x**2\n",
        "        return y\n",
        "\n",
        "class LinearNet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearNet2, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(1, 8)\n",
        "        self.linear2 = nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7fdgqQI4KdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ParameterDistribution:\n",
        "    def __init__(self, dist):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        dist: dict\n",
        "            key: paramter name\n",
        "            value: torch.distributions.distribution.Distribution\n",
        "        \"\"\"\n",
        "        if not isinstance(dist, OrderedDict):\n",
        "            raise ValueError('dist must be OrderedDict')\n",
        "        self.dist = dist\n",
        "\n",
        "    def sample(self):\n",
        "        w_sample = OrderedDict()\n",
        "        for n, d in self.dist.items():\n",
        "            w_sample[n] = d.sample()\n",
        "\n",
        "        return w_sample\n",
        "\n",
        "    def rsample(self):\n",
        "        w_sample = OrderedDict()\n",
        "        for n, d in self.dist.items():\n",
        "            w_sample[n] = d.rsample()\n",
        "\n",
        "        return w_sample\n",
        "\n",
        "    def log_prob(self, w):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        w: dict\n",
        "            key: parameter name\n",
        "            value: torch.Tensor\n",
        "        \"\"\"\n",
        "        sum_log_prob = 0\n",
        "        for k, v in w.items():\n",
        "            distribution = self.dist[k]\n",
        "            sum_log_prob += distribution.log_prob(v).sum()\n",
        "\n",
        "        return sum_log_prob\n",
        "\n",
        "class VIModel(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(VIModel, self).__init__()\n",
        "        # set param\n",
        "\n",
        "        param_dict = self.get_params(model)\n",
        "        self.dist = self.normal_dist(param_dict)        \n",
        "        self.__setparams(param_dict)        \n",
        "\n",
        "    def get_params(self, model):\n",
        "        param_dict = OrderedDict()\n",
        "        for n, p in model.named_parameters():\n",
        "            mu = nn.Parameter(torch.zeros_like(p.data))\n",
        "            log_sigma = nn.Parameter(torch.zeros_like(p.data))\n",
        "            \n",
        "            eta_dict = {\n",
        "                'mu': mu,\n",
        "                'log_sigma': log_sigma\n",
        "            }\n",
        "            param_dict[n] = eta_dict\n",
        "\n",
        "        return param_dict\n",
        "\n",
        "    def normal_dist(self, param_dict):\n",
        "        dist = OrderedDict()\n",
        "        for n, eta_dict in param_dict.items():\n",
        "            mu = eta_dict['mu']\n",
        "            log_sigma = eta_dict['log_sigma']\n",
        "            # sigma = torch.exp(log_sigma)\n",
        "\n",
        "            # dist[n] = torchdist.Normal(mu, sigma)\n",
        "            dist[n] = CustomNormal(mu, log_sigma)\n",
        "\n",
        "        return dist\n",
        "\n",
        "    def __setparams(self, param_dict):\n",
        "        for n, eta_dict in param_dict.items():\n",
        "            for eta_name, eta_param in eta_dict.items():\n",
        "                # parameter\n",
        "                name =  '_'.join([n.replace('.', '_'), eta_name])\n",
        "                setattr(self, name, eta_param)\n",
        "                \n",
        "\n",
        "def normal_dist(model):\n",
        "    dist = OrderedDict()\n",
        "    for n, p in model.named_parameters():\n",
        "        mu = nn.Parameter(torch.zeros_like(p.data))\n",
        "        sigma = torch.exp(nn.Parameter(torch.zeros_like(p.data)))        \n",
        "        dist[n] = torchdist.Normal(mu, sigma)\n",
        "\n",
        "    return dist\n",
        "\n",
        "def normal_prior_dist(model):\n",
        "    dist = OrderedDict()\n",
        "    for n, p in model.named_parameters():\n",
        "        param_size = p.size()        \n",
        "        mu = torch.zeros(param_size)\n",
        "        # [10, 10, ...]\n",
        "        sigma = torch.zeros((1,)).new_full(param_size, 10.0)\n",
        "        dist[n] = torchdist.Normal(mu, sigma)\n",
        "\n",
        "    return dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjMlRDMN4KdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kl_divergence(q_w, p_w, model, x, y, n_params, idx):\n",
        "\n",
        "    # sampling from q(w)\n",
        "    w_sample = q_w.rsample()\n",
        "    \n",
        "    model.set_params(w_sample)\n",
        "\n",
        "    # calculate f(x)\n",
        "    # p(y|x,w) = N(f(x; w), 1)\n",
        "    out1, out2 = model(x)\n",
        "\n",
        "    # print('output', output)\n",
        "    p_y_xw = torchdist.Normal(out1, torch.ones_like(out1) / 2)\n",
        "    # p_y_xw = torchdist.Normal(out1, out2)\n",
        "\n",
        "    # log(p(w, x, y)) = log(p(w)) + sum(log(p(y|x,w)))    \n",
        "    # val_log_joint_prob = p_w.log_prob(w_sample) + p_y_xw.log_prob(y).sum()    \n",
        "    val_log_p_w = p_w.log_prob(w_sample) / n_params\n",
        "    # val_log_p_w = p_w.log_prob(w_sample)\n",
        "    val_log_p_y_xw = p_y_xw.log_prob(y).mean()\n",
        "    val_log_q_w = q_w.log_prob(w_sample) / n_params\n",
        "    # val_log_q_w = q_w.log_prob(w_sample)\n",
        "\n",
        "    if (idx+1) % 100 == 0:\n",
        "        print('%d loss q(w) %f p(w) %f p(y|xw) %f' \n",
        "              % (idx, val_log_q_w.item(), val_log_p_w.item(), val_log_p_y_xw.item()))\n",
        "    \n",
        "    return val_log_q_w - val_log_p_w - val_log_p_y_xw\n",
        "    # return - val_log_p_y_xw\n",
        "\n",
        "def kl_divergence_nsamples(q_w, p_w, loc_dict, model, x, y, idx):\n",
        "\n",
        "    val_loss = 0\n",
        "    n_samples = 10\n",
        "    for _ in range(n_samples):\n",
        "        val_loss += kl_divergenceV2(q_w, p_w, loc_dict, model, x, y, idx) / n_samples\n",
        "    return val_loss\n",
        "\n",
        "\n",
        "def loss_func(model, x, y):\n",
        "    y_pred = model(x)\n",
        "    loss = ((y - y_pred)**2).mean()\n",
        "    return loss\n",
        "\n",
        "def freeze_param(model):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def setw(module, w_dict, prefix):\n",
        "    var_names = list(module._parameters.keys())\n",
        "    for var_name in var_names:\n",
        "        if prefix == '':\n",
        "            full_name = var_name\n",
        "        else:\n",
        "            full_name = '.'.join([prefix, var_name])\n",
        "        print(full_name)\n",
        "        value = w_dict[full_name]        \n",
        "        # module.__setattr__ == \n",
        "        \n",
        "        # value_param =  nn.Parameter(value, requires_grad=False)\n",
        "        # dengerous process\n",
        "        value.__class__ = nn.Parameter\n",
        "        setattr(module, var_name, value)\n",
        "        print('test')\n",
        "        # module.register_parameter(var_name, value_param)\n",
        "        # module._parameters[var_name] = value\n",
        "        \n",
        "    for child_name, child_module in module._modules.items():\n",
        "        if prefix == '':\n",
        "            child_full_name = child_name\n",
        "        else:\n",
        "            child_full_name = '.'.join([prefix, child_name])\n",
        "        setw(child_module, w_dict, child_full_name)\n",
        "\n",
        "def printw(module, prefix=''):\n",
        "    var_names = list(module._parameters.keys())\n",
        "    for var_name in var_names:        \n",
        "        if prefix == '':\n",
        "            full_name = var_name\n",
        "        else:\n",
        "            full_name = '.'.join([prefix, var_name])\n",
        "        print(full_name)\n",
        "        print(getattr(module, var_name))        \n",
        "\n",
        "    for child_name, child_module in module._modules.items():\n",
        "        if prefix == '':\n",
        "            child_full_name = child_name\n",
        "        else:\n",
        "            child_full_name = '.'.join([prefix, child_name])\n",
        "        printw(child_module, child_full_name)\n",
        "\n",
        "def write_graph(writer, model, x):\n",
        "    writer.add_graph(model, input_to_model=x)\n",
        "\n",
        "def get_n_params(model):\n",
        "    n_all_params = 0\n",
        "    for n, p in model.named_parameters():\n",
        "        if p is not None:\n",
        "            n_params = 1\n",
        "            for dim in p.size():\n",
        "                n_params *= dim\n",
        "            n_all_params += n_params\n",
        "    return n_all_params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEMKHByHrdgv",
        "colab_type": "text"
      },
      "source": [
        "## exec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xDgvNTsoAN-",
        "colab_type": "text"
      },
      "source": [
        "Calculate prediction distribution\n",
        "$$\n",
        "\\begin{align}\n",
        "& KL[q(W; \\eta)||p(W|X, Y)] \\\\\n",
        "&= \\int q(W; \\eta) \\log \\frac{q(W; \\eta)}{p(W|X, Y)} dW\\\\\n",
        "&= \\int q(W; \\eta) \\log q(W; \\eta)dW - \\int q(W; \\eta) \\log \\frac{p(Y|W, X)p(W)}{p(Y|X)}dW \\\\\n",
        "&= \\int q(W; \\eta) \\log q(W; \\eta)dW - \\int q(W; \\eta) \\log p(Y|W, X)dW - \\int q(W; \\eta) \\log p(W)dW + const.\\\\\n",
        "&= E[\\log q(W; \\eta)] - E[\\log p(Y|W, X)] - E[\\log p(W)] + const.\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pn6FEfV4KdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5d7c5f47-8815-4667-ec83-9eac6b9d0554"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "x_train_norm = torch.tensor(scaler.fit_transform(x_train), dtype=torch.float32)\n",
        "\n",
        "# model = LinearNet2()\n",
        "model = TensorLinearNet()\n",
        "vimodel = VIModel2(model)\n",
        "q_w = vimodel.dist\n",
        "p_w = normal_prior_distV2(model)\n",
        "\n",
        "# optimizer = torch.optim.Adam(params=vimodel.parameters(), lr=5e-4)\n",
        "optimizer = torch.optim.SGD(params=vimodel.parameters(), lr=1e-5, \n",
        "                            momentum=0.9,\n",
        "                            weight_decay=1e-4)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('linear1.p_weight', {'size': torch.Size([8, 1]), 'loc': (0, 8)}), ('linear1.p_bias', {'size': torch.Size([8]), 'loc': (8, 16)}), ('linear2.p_weight', {'size': torch.Size([8, 8]), 'loc': (16, 80)}), ('linear2.p_bias', {'size': torch.Size([8]), 'loc': (80, 88)}), ('last_layer.p_weight', {'size': torch.Size([1, 8]), 'loc': (88, 96)}), ('last_layer.p_bias', {'size': torch.Size([1]), 'loc': (96, 97)}), ('bn1.p_weight', {'size': torch.Size([8]), 'loc': (97, 105)}), ('bn1.p_bias', {'size': torch.Size([8]), 'loc': (105, 113)}), ('bn2.p_weight', {'size': torch.Size([8]), 'loc': (113, 121)}), ('bn2.p_bias', {'size': torch.Size([8]), 'loc': (121, 129)})])\n",
            "129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "87ydpXz34KdS",
        "colab_type": "code",
        "outputId": "da6ac81d-e1d6-48fb-d5ab-14adbcf15339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_params = get_n_params(model)\n",
        "model.train()\n",
        "for i in range(10000):    \n",
        "    with torch.set_grad_enabled(True):    \n",
        "        optimizer.zero_grad()        \n",
        "        loss = kl_divergence_nsamples(q_w, p_w, vimodel.loc_dict, model, x_train_norm, y_train, i)\n",
        "        loss.backward()\n",
        "        optimizer.step()        \n",
        "        \n",
        "    if str(loss.item()) == 'nan':\n",
        "        break\n",
        "\n",
        "    if (i+1) % 100== 0:\n",
        "        # mu = vimodel.eta_mu.detach().numpy()\n",
        "        # sigma = torch.exp(vimodel.eta_log_sigma.detach()).numpy()\n",
        "        # print('loss: %f mu: %s sigma: %s' % (loss.detach().numpy(), str(mu), str(sigma)))\n",
        "        # print(loss.size())\n",
        "        print('iter: %d loss: %f ' % (i, loss.item(),))\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 loss q(w) -174.651291 p(w) -416.189697 p(y|xw) -476.719513 min 1.135807 mean 1.427819 max 1.821273\n",
            "99 loss q(w) -174.651291 p(w) -416.118439 p(y|xw) -699.060425 min -3.490112 mean 0.383341 max 6.257768\n",
            "99 loss q(w) -174.651291 p(w) -416.208374 p(y|xw) -529.508911 min -1.873231 mean -0.039258 max 1.140490\n",
            "99 loss q(w) -174.651291 p(w) -416.142029 p(y|xw) -494.413757 min 0.040293 mean 0.578379 max 1.118329\n",
            "99 loss q(w) -174.651291 p(w) -416.226868 p(y|xw) -456.993958 min 0.572834 mean 0.932189 max 1.412390\n",
            "99 loss q(w) -174.651291 p(w) -416.051788 p(y|xw) -498.828003 min 0.196843 mean 0.511165 max 0.806414\n",
            "99 loss q(w) -174.651291 p(w) -416.244690 p(y|xw) -517.712585 min -0.142879 mean 0.547055 max 1.164692\n",
            "99 loss q(w) -174.651291 p(w) -416.136932 p(y|xw) -501.192352 min 1.008643 mean 1.222236 max 1.915819\n",
            "99 loss q(w) -174.651291 p(w) -416.074799 p(y|xw) -498.204681 min -1.740955 mean 0.540804 max 2.427521\n",
            "99 loss q(w) -174.651291 p(w) -416.241394 p(y|xw) -561.897095 min -0.094409 mean 0.889412 max 3.034891\n",
            "iter: 99 loss: 764.965332 \n",
            "199 loss q(w) -170.773102 p(w) -416.333160 p(y|xw) -508.415955 min 0.983720 mean 1.442458 max 3.064151\n",
            "199 loss q(w) -170.773102 p(w) -416.169739 p(y|xw) -639.072815 min 0.755531 mean 1.511958 max 3.107975\n",
            "199 loss q(w) -170.773102 p(w) -416.090454 p(y|xw) -520.898682 min 1.233865 mean 1.721170 max 2.437921\n",
            "199 loss q(w) -170.773102 p(w) -416.308105 p(y|xw) -475.549805 min 0.765171 mean 1.014990 max 2.206642\n",
            "199 loss q(w) -170.773102 p(w) -416.184692 p(y|xw) -490.896027 min 0.317775 mean 0.468941 max 0.637186\n",
            "199 loss q(w) -170.773102 p(w) -416.208282 p(y|xw) -459.617462 min 1.077365 mean 1.255353 max 1.594159\n",
            "199 loss q(w) -170.773102 p(w) -416.156403 p(y|xw) -478.139252 min 1.055079 mean 1.415807 max 2.286193\n",
            "199 loss q(w) -170.773102 p(w) -416.076416 p(y|xw) -503.617249 min 1.150590 mean 1.348874 max 1.890885\n",
            "199 loss q(w) -170.773102 p(w) -416.153503 p(y|xw) -497.648468 min 0.183205 mean 0.552886 max 1.411784\n",
            "199 loss q(w) -170.773102 p(w) -416.107330 p(y|xw) -438.893036 min 0.480165 mean 1.005320 max 1.813699\n",
            "iter: 199 loss: 746.680542 \n",
            "299 loss q(w) -168.658569 p(w) -416.201630 p(y|xw) -484.473450 min 0.984656 mean 1.367292 max 2.641227\n",
            "299 loss q(w) -168.658569 p(w) -416.190430 p(y|xw) -537.022217 min 0.636140 mean 1.454790 max 3.079998\n",
            "299 loss q(w) -168.658569 p(w) -416.129120 p(y|xw) -475.134705 min 0.596120 mean 0.953636 max 1.655742\n",
            "299 loss q(w) -168.658569 p(w) -416.088257 p(y|xw) -506.953979 min 1.174776 mean 1.437285 max 1.777929\n",
            "299 loss q(w) -168.658569 p(w) -416.137695 p(y|xw) -521.232300 min 0.721443 mean 1.614923 max 1.991711\n",
            "299 loss q(w) -168.658569 p(w) -416.233185 p(y|xw) -473.815582 min 0.926973 mean 1.119559 max 1.384586\n",
            "299 loss q(w) -168.658569 p(w) -416.168884 p(y|xw) -514.627380 min 0.932029 mean 1.435665 max 1.862103\n",
            "299 loss q(w) -168.658569 p(w) -416.033936 p(y|xw) -493.710175 min 0.544465 mean 0.803067 max 1.384329\n",
            "299 loss q(w) -168.658569 p(w) -416.129272 p(y|xw) -477.193787 min 0.955263 mean 1.157374 max 1.624040\n",
            "299 loss q(w) -168.658569 p(w) -416.168854 p(y|xw) -468.215210 min 0.650045 mean 1.004527 max 2.636378\n",
            "iter: 299 loss: 742.727478 \n",
            "399 loss q(w) -167.927658 p(w) -416.187805 p(y|xw) -489.554108 min 0.673598 mean 0.851736 max 1.918508\n",
            "399 loss q(w) -167.927658 p(w) -416.119995 p(y|xw) -509.167206 min 0.212655 mean 0.324935 max 0.467724\n",
            "399 loss q(w) -167.927658 p(w) -416.243073 p(y|xw) -515.176086 min 0.394247 mean 0.539803 max 0.773582\n",
            "399 loss q(w) -167.927658 p(w) -416.106415 p(y|xw) -481.272705 min 0.559167 mean 0.641236 max 0.932362\n",
            "399 loss q(w) -167.927658 p(w) -416.229156 p(y|xw) -477.759827 min 0.575793 mean 0.788773 max 1.366129\n",
            "399 loss q(w) -167.927658 p(w) -416.261261 p(y|xw) -507.836853 min 0.668183 mean 1.149333 max 1.469621\n",
            "399 loss q(w) -167.927658 p(w) -416.158813 p(y|xw) -525.849670 min 1.256384 mean 1.751029 max 2.268937\n",
            "399 loss q(w) -167.927658 p(w) -416.120209 p(y|xw) -508.580353 min 0.753709 mean 1.347275 max 3.107633\n",
            "399 loss q(w) -167.927658 p(w) -416.154785 p(y|xw) -518.341248 min 0.855397 mean 1.483944 max 2.058956\n",
            "399 loss q(w) -167.927658 p(w) -416.210083 p(y|xw) -471.572479 min 0.591106 mean 0.750470 max 0.995228\n",
            "iter: 399 loss: 748.762573 \n",
            "499 loss q(w) -168.137238 p(w) -416.261536 p(y|xw) -473.657562 min 0.786495 mean 0.885035 max 1.106642\n",
            "499 loss q(w) -168.137238 p(w) -416.214630 p(y|xw) -480.795563 min 0.688879 mean 0.815148 max 1.082417\n",
            "499 loss q(w) -168.137238 p(w) -416.138367 p(y|xw) -529.267151 min 0.090279 mean 0.568295 max 1.012044\n",
            "499 loss q(w) -168.137238 p(w) -416.084747 p(y|xw) -506.121216 min 0.957466 mean 1.310215 max 1.593144\n",
            "499 loss q(w) -168.137238 p(w) -416.048218 p(y|xw) -522.574402 min -0.151567 mean 0.983136 max 1.649463\n",
            "499 loss q(w) -168.137238 p(w) -416.268982 p(y|xw) -485.457947 min 1.216196 mean 1.256938 max 1.347484\n",
            "499 loss q(w) -168.137238 p(w) -416.131500 p(y|xw) -437.063934 min 0.753774 mean 1.204403 max 2.597250\n",
            "499 loss q(w) -168.137238 p(w) -416.187866 p(y|xw) -475.728851 min 0.732206 mean 0.891608 max 1.160120\n",
            "499 loss q(w) -168.137238 p(w) -416.214264 p(y|xw) -452.363861 min 0.126953 mean 0.734014 max 1.587346\n",
            "499 loss q(w) -168.137238 p(w) -416.116302 p(y|xw) -485.694153 min 0.821653 mean 1.037744 max 1.920111\n",
            "iter: 499 loss: 732.901794 \n",
            "599 loss q(w) -168.696594 p(w) -416.277283 p(y|xw) -444.377991 min 0.801286 mean 1.068615 max 1.999873\n",
            "599 loss q(w) -168.696594 p(w) -416.087860 p(y|xw) -485.151489 min 0.631196 mean 0.674244 max 0.769918\n",
            "599 loss q(w) -168.696594 p(w) -416.145416 p(y|xw) -448.992126 min 0.632511 mean 1.137638 max 2.839341\n",
            "599 loss q(w) -168.696594 p(w) -416.232788 p(y|xw) -502.379333 min 0.421909 mean 1.048169 max 1.722997\n",
            "599 loss q(w) -168.696594 p(w) -416.128235 p(y|xw) -520.462769 min 0.262960 mean 0.703427 max 1.172032\n",
            "599 loss q(w) -168.696594 p(w) -416.258820 p(y|xw) -509.809601 min 0.559510 mean 0.910312 max 1.243804\n",
            "599 loss q(w) -168.696594 p(w) -416.167603 p(y|xw) -469.460846 min 0.826682 mean 1.198144 max 2.047315\n",
            "599 loss q(w) -168.696594 p(w) -416.135376 p(y|xw) -549.268433 min 0.073687 mean 0.698934 max 1.143132\n",
            "599 loss q(w) -168.696594 p(w) -416.210968 p(y|xw) -499.729553 min 1.312568 mean 1.508566 max 2.576152\n",
            "599 loss q(w) -168.696594 p(w) -416.201416 p(y|xw) -504.883209 min 1.143422 mean 1.316601 max 1.550599\n",
            "iter: 599 loss: 740.939514 \n",
            "699 loss q(w) -169.234985 p(w) -416.175812 p(y|xw) -568.993530 min 0.764054 mean 1.587264 max 2.351902\n",
            "699 loss q(w) -169.234985 p(w) -416.382812 p(y|xw) -439.393555 min 0.799661 mean 1.187298 max 1.836600\n",
            "699 loss q(w) -169.234985 p(w) -416.238373 p(y|xw) -466.769867 min 0.894760 mean 1.368871 max 2.196362\n",
            "699 loss q(w) -169.234985 p(w) -416.276306 p(y|xw) -486.892395 min 0.815075 mean 0.921971 max 1.220849\n",
            "699 loss q(w) -169.234985 p(w) -416.342773 p(y|xw) -456.015381 min -0.132009 mean 0.767793 max 2.094156\n",
            "699 loss q(w) -169.234985 p(w) -416.299011 p(y|xw) -528.135376 min 0.860754 mean 1.422346 max 2.878667\n",
            "699 loss q(w) -169.234985 p(w) -416.241486 p(y|xw) -461.115387 min 0.702756 mean 0.971444 max 1.300069\n",
            "699 loss q(w) -169.234985 p(w) -416.145203 p(y|xw) -498.247009 min 1.278380 mean 1.509110 max 1.718917\n",
            "699 loss q(w) -169.234985 p(w) -416.162811 p(y|xw) -464.865143 min 1.052773 mean 1.232428 max 1.620779\n",
            "699 loss q(w) -169.234985 p(w) -416.095581 p(y|xw) -487.512909 min 0.816718 mean 0.959316 max 1.723643\n",
            "iter: 699 loss: 732.795166 \n",
            "799 loss q(w) -170.010330 p(w) -416.341370 p(y|xw) -467.198975 min 0.632755 mean 1.104884 max 1.618794\n",
            "799 loss q(w) -170.010330 p(w) -416.305756 p(y|xw) -519.186829 min 0.457390 mean 1.298421 max 2.945830\n",
            "799 loss q(w) -170.010330 p(w) -416.286072 p(y|xw) -478.867645 min 1.386809 mean 1.664402 max 1.981915\n",
            "799 loss q(w) -170.010330 p(w) -416.244629 p(y|xw) -490.976868 min 0.695998 mean 0.800940 max 0.974031\n",
            "799 loss q(w) -170.010330 p(w) -416.289124 p(y|xw) -488.191010 min 0.669051 mean 0.825950 max 1.287689\n",
            "799 loss q(w) -170.010330 p(w) -416.282745 p(y|xw) -474.042023 min 0.740595 mean 0.849101 max 1.045771\n",
            "799 loss q(w) -170.010330 p(w) -416.075775 p(y|xw) -491.417908 min 1.129614 mean 1.605977 max 2.236887\n",
            "799 loss q(w) -170.010330 p(w) -416.114197 p(y|xw) -475.844208 min 0.664612 mean 0.826845 max 1.169786\n",
            "799 loss q(w) -170.010330 p(w) -416.459717 p(y|xw) -478.156982 min 0.626008 mean 0.733768 max 0.930856\n",
            "799 loss q(w) -170.010330 p(w) -416.313934 p(y|xw) -465.117523 min 0.770041 mean 1.195348 max 1.615304\n",
            "iter: 799 loss: 729.160950 \n",
            "899 loss q(w) -170.811386 p(w) -416.290253 p(y|xw) -473.204437 min 0.625010 mean 0.746421 max 0.975947\n",
            "899 loss q(w) -170.811386 p(w) -416.132568 p(y|xw) -486.677887 min 0.666328 mean 0.724890 max 0.836481\n",
            "899 loss q(w) -170.811386 p(w) -416.191772 p(y|xw) -485.539978 min 0.978431 mean 1.258978 max 2.367450\n",
            "899 loss q(w) -170.811386 p(w) -416.208618 p(y|xw) -488.813965 min 1.140063 mean 1.399108 max 1.962566\n",
            "899 loss q(w) -170.811386 p(w) -416.329132 p(y|xw) -441.832672 min 0.987626 mean 1.425092 max 2.214502\n",
            "899 loss q(w) -170.811386 p(w) -416.414734 p(y|xw) -477.515411 min 0.740469 mean 0.895079 max 1.267800\n",
            "899 loss q(w) -170.811386 p(w) -416.336151 p(y|xw) -461.255341 min 0.740461 mean 1.103526 max 1.773960\n",
            "899 loss q(w) -170.811386 p(w) -416.288879 p(y|xw) -486.811157 min 0.809824 mean 0.815931 max 0.877770\n",
            "899 loss q(w) -170.811386 p(w) -416.295105 p(y|xw) -488.843567 min 0.686544 mean 0.713740 max 0.803020\n",
            "899 loss q(w) -170.811386 p(w) -416.246613 p(y|xw) -479.047363 min 0.779421 mean 1.154971 max 1.697605\n",
            "iter: 899 loss: 722.416138 \n",
            "999 loss q(w) -171.612854 p(w) -416.167145 p(y|xw) -456.059235 min 0.301731 mean 0.755853 max 1.436607\n",
            "999 loss q(w) -171.612854 p(w) -416.258850 p(y|xw) -470.055664 min 1.349267 mean 1.614724 max 2.029277\n",
            "999 loss q(w) -171.612854 p(w) -416.248413 p(y|xw) -495.924683 min 0.852646 mean 1.226164 max 2.111875\n",
            "999 loss q(w) -171.612854 p(w) -416.429108 p(y|xw) -468.804413 min 0.811079 mean 1.244943 max 2.270384\n",
            "999 loss q(w) -171.612854 p(w) -416.249023 p(y|xw) -467.007172 min 1.014204 mean 1.121653 max 1.447866\n",
            "999 loss q(w) -171.612854 p(w) -416.316681 p(y|xw) -487.911499 min 0.609986 mean 0.767285 max 1.079825\n",
            "999 loss q(w) -171.612854 p(w) -416.358521 p(y|xw) -424.863617 min 0.564177 mean 1.242904 max 2.395614\n",
            "999 loss q(w) -171.612854 p(w) -416.246490 p(y|xw) -482.794464 min 1.013696 mean 1.559704 max 3.196502\n",
            "999 loss q(w) -171.612854 p(w) -416.251038 p(y|xw) -449.044495 min 0.952630 mean 1.270530 max 2.076660\n",
            "999 loss q(w) -171.612854 p(w) -416.409546 p(y|xw) -447.080078 min 0.870607 mean 1.379087 max 2.387367\n",
            "iter: 999 loss: 709.635193 \n",
            "1099 loss q(w) -172.415939 p(w) -416.319061 p(y|xw) -468.065765 min 0.956880 mean 1.208629 max 1.709343\n",
            "1099 loss q(w) -172.415939 p(w) -416.335602 p(y|xw) -473.026520 min 0.865084 mean 1.058635 max 1.376552\n",
            "1099 loss q(w) -172.415939 p(w) -416.176544 p(y|xw) -476.867950 min 0.803715 mean 0.953675 max 1.431327\n",
            "1099 loss q(w) -172.415939 p(w) -416.258728 p(y|xw) -492.306824 min 0.655453 mean 0.821487 max 1.136808\n",
            "1099 loss q(w) -172.415939 p(w) -416.449646 p(y|xw) -480.878662 min 0.797863 mean 1.015361 max 1.702545\n",
            "1099 loss q(w) -172.415939 p(w) -416.233643 p(y|xw) -489.674713 min 1.033073 mean 1.196482 max 1.339825\n",
            "1099 loss q(w) -172.415939 p(w) -416.321777 p(y|xw) -492.985626 min 0.719646 mean 1.118101 max 2.749562\n",
            "1099 loss q(w) -172.415939 p(w) -416.437500 p(y|xw) -436.451599 min 0.723460 mean 1.298330 max 3.654344\n",
            "1099 loss q(w) -172.415939 p(w) -416.341766 p(y|xw) -511.689362 min 0.637482 mean 1.131385 max 1.525333\n",
            "1099 loss q(w) -172.415939 p(w) -416.197845 p(y|xw) -453.869476 min 0.975319 mean 1.243232 max 1.388257\n",
            "iter: 1099 loss: 721.472961 \n",
            "1199 loss q(w) -173.277435 p(w) -416.355255 p(y|xw) -499.324921 min 0.665257 mean 0.986083 max 2.028603\n",
            "1199 loss q(w) -173.277435 p(w) -416.208740 p(y|xw) -486.237854 min 0.679751 mean 0.848494 max 0.953781\n",
            "1199 loss q(w) -173.277435 p(w) -416.235565 p(y|xw) -505.251312 min 1.261009 mean 1.680551 max 3.078614\n",
            "1199 loss q(w) -173.277435 p(w) -416.207916 p(y|xw) -485.287201 min 0.653659 mean 0.825253 max 0.982355\n",
            "1199 loss q(w) -173.277435 p(w) -416.253296 p(y|xw) -491.413574 min 0.598761 mean 0.947934 max 1.132291\n",
            "1199 loss q(w) -173.277435 p(w) -416.411102 p(y|xw) -501.225250 min 0.902983 mean 1.133865 max 1.636647\n",
            "1199 loss q(w) -173.277435 p(w) -416.396179 p(y|xw) -470.463837 min 0.716050 mean 0.881336 max 1.083247\n",
            "1199 loss q(w) -173.277435 p(w) -416.214111 p(y|xw) -449.887207 min 1.071771 mean 1.668141 max 3.172465\n",
            "1199 loss q(w) -173.277435 p(w) -416.394501 p(y|xw) -486.829285 min 0.527760 mean 0.614162 max 0.714705\n",
            "1199 loss q(w) -173.277435 p(w) -416.201691 p(y|xw) -436.365265 min 0.524850 mean 1.131415 max 2.708679\n",
            "iter: 1199 loss: 724.239014 \n",
            "1299 loss q(w) -174.244308 p(w) -416.427856 p(y|xw) -503.004608 min 0.833425 mean 1.462543 max 3.400717\n",
            "1299 loss q(w) -174.244308 p(w) -416.352478 p(y|xw) -485.296478 min 0.750022 mean 0.831489 max 1.015338\n",
            "1299 loss q(w) -174.244308 p(w) -416.377747 p(y|xw) -454.145355 min 0.795648 mean 0.978023 max 1.934438\n",
            "1299 loss q(w) -174.244308 p(w) -416.267212 p(y|xw) -479.204926 min 0.856178 mean 1.011273 max 1.271622\n",
            "1299 loss q(w) -174.244308 p(w) -416.208923 p(y|xw) -465.618988 min 0.754440 mean 0.966161 max 1.261915\n",
            "1299 loss q(w) -174.244308 p(w) -416.486450 p(y|xw) -470.415894 min 0.926341 mean 1.110540 max 1.492265\n",
            "1299 loss q(w) -174.244308 p(w) -416.227722 p(y|xw) -488.617798 min 0.525204 mean 0.688859 max 0.864183\n",
            "1299 loss q(w) -174.244308 p(w) -416.220764 p(y|xw) -443.380615 min 0.793450 mean 1.128328 max 2.247938\n",
            "1299 loss q(w) -174.244308 p(w) -416.320496 p(y|xw) -489.980438 min 0.715449 mean 0.806767 max 0.969761\n",
            "1299 loss q(w) -174.244308 p(w) -416.232056 p(y|xw) -517.138489 min 0.889423 mean 1.079722 max 1.542435\n",
            "iter: 1299 loss: 721.748230 \n",
            "1399 loss q(w) -175.274918 p(w) -416.448364 p(y|xw) -493.690369 min 0.420490 mean 0.590288 max 0.850481\n",
            "1399 loss q(w) -175.274918 p(w) -416.252808 p(y|xw) -465.026642 min 0.909504 mean 1.124119 max 1.327691\n",
            "1399 loss q(w) -175.274918 p(w) -416.216919 p(y|xw) -493.685303 min 1.055682 mean 1.319818 max 2.023015\n",
            "1399 loss q(w) -175.274918 p(w) -416.382996 p(y|xw) -461.719818 min 0.843522 mean 1.002365 max 1.304152\n",
            "1399 loss q(w) -175.274918 p(w) -416.407135 p(y|xw) -486.200653 min 0.947370 mean 1.194967 max 2.080091\n",
            "1399 loss q(w) -175.274918 p(w) -416.112061 p(y|xw) -466.316376 min 1.095478 mean 1.327475 max 1.800993\n",
            "1399 loss q(w) -175.274918 p(w) -416.242218 p(y|xw) -457.777588 min 0.804122 mean 1.172797 max 2.006816\n",
            "1399 loss q(w) -175.274918 p(w) -416.488098 p(y|xw) -494.537109 min 0.826319 mean 1.140821 max 2.239934\n",
            "1399 loss q(w) -175.274918 p(w) -416.184204 p(y|xw) -479.350861 min 0.836728 mean 0.917609 max 1.422424\n",
            "1399 loss q(w) -175.274918 p(w) -416.335571 p(y|xw) -531.554688 min 0.833032 mean 1.034506 max 1.578120\n",
            "iter: 1399 loss: 724.018005 \n",
            "1499 loss q(w) -175.965378 p(w) -416.265411 p(y|xw) -509.420044 min 0.713158 mean 0.972457 max 1.247336\n",
            "1499 loss q(w) -175.965378 p(w) -416.256104 p(y|xw) -485.065582 min 0.454012 mean 0.688108 max 1.013632\n",
            "1499 loss q(w) -175.965378 p(w) -416.301544 p(y|xw) -481.735474 min 1.076334 mean 1.182568 max 1.502355\n",
            "1499 loss q(w) -175.965378 p(w) -416.224091 p(y|xw) -476.969971 min 1.041657 mean 1.119264 max 1.199294\n",
            "1499 loss q(w) -175.965378 p(w) -416.267517 p(y|xw) -484.833862 min 1.265815 mean 1.482873 max 1.752826\n",
            "1499 loss q(w) -175.965378 p(w) -416.450317 p(y|xw) -483.160797 min 1.056692 mean 1.207684 max 1.366887\n",
            "1499 loss q(w) -175.965378 p(w) -416.363342 p(y|xw) -481.163574 min 0.719918 mean 0.807110 max 1.119624\n",
            "1499 loss q(w) -175.965378 p(w) -416.135681 p(y|xw) -471.270752 min 0.954455 mean 1.136252 max 1.290529\n",
            "1499 loss q(w) -175.965378 p(w) -416.401337 p(y|xw) -471.088104 min 1.081975 mean 1.456750 max 2.378960\n",
            "1499 loss q(w) -175.965378 p(w) -416.215729 p(y|xw) -494.037842 min 0.843413 mean 0.987346 max 1.963087\n",
            "iter: 1499 loss: 724.197327 \n",
            "1599 loss q(w) -176.899155 p(w) -416.306213 p(y|xw) -476.996826 min 0.802078 mean 1.060928 max 1.742734\n",
            "1599 loss q(w) -176.899155 p(w) -416.419952 p(y|xw) -465.691193 min 0.716287 mean 0.903498 max 1.983684\n",
            "1599 loss q(w) -176.899155 p(w) -416.323639 p(y|xw) -523.745056 min 0.931773 mean 1.625139 max 4.076079\n",
            "1599 loss q(w) -176.899155 p(w) -416.291443 p(y|xw) -554.203796 min 0.803927 mean 1.727429 max 4.763055\n",
            "1599 loss q(w) -176.899155 p(w) -416.352814 p(y|xw) -481.239380 min 1.054151 mean 1.101593 max 1.282451\n",
            "1599 loss q(w) -176.899155 p(w) -416.223541 p(y|xw) -490.922394 min 0.731929 mean 0.989997 max 1.825529\n",
            "1599 loss q(w) -176.899155 p(w) -416.442200 p(y|xw) -476.249146 min 0.353966 mean 0.662567 max 1.047836\n",
            "1599 loss q(w) -176.899155 p(w) -416.352173 p(y|xw) -470.932068 min 0.802797 mean 0.925691 max 1.312522\n",
            "1599 loss q(w) -176.899155 p(w) -416.226746 p(y|xw) -497.936615 min 0.931375 mean 1.152844 max 1.461482\n",
            "1599 loss q(w) -176.899155 p(w) -416.354767 p(y|xw) -475.425934 min 0.265283 mean 0.925118 max 1.207736\n",
            "iter: 1599 loss: 730.764465 \n",
            "1699 loss q(w) -177.851181 p(w) -416.411041 p(y|xw) -448.587860 min 0.718729 mean 1.013250 max 2.606585\n",
            "1699 loss q(w) -177.851181 p(w) -416.262360 p(y|xw) -498.731934 min 1.042585 mean 1.461753 max 1.744137\n",
            "1699 loss q(w) -177.851181 p(w) -416.276123 p(y|xw) -488.343842 min 0.608663 mean 0.813652 max 0.871892\n",
            "1699 loss q(w) -177.851181 p(w) -416.355164 p(y|xw) -552.768616 min 1.442670 mean 1.755575 max 2.170761\n",
            "1699 loss q(w) -177.851181 p(w) -416.348969 p(y|xw) -506.476959 min 0.374369 mean 0.624885 max 0.821082\n",
            "1699 loss q(w) -177.851181 p(w) -416.257233 p(y|xw) -499.677948 min 0.743013 mean 0.954500 max 2.292558\n",
            "1699 loss q(w) -177.851181 p(w) -416.375244 p(y|xw) -432.941437 min 0.852043 mean 1.234919 max 1.829666\n",
            "1699 loss q(w) -177.851181 p(w) -416.417847 p(y|xw) -515.726074 min 0.811351 mean 1.028621 max 1.315906\n",
            "1699 loss q(w) -177.851181 p(w) -416.334076 p(y|xw) -504.477600 min 0.874777 mean 1.128276 max 1.360007\n",
            "1699 loss q(w) -177.851181 p(w) -416.341614 p(y|xw) -482.896820 min 0.737751 mean 0.859609 max 1.013144\n",
            "iter: 1699 loss: 731.549622 \n",
            "1799 loss q(w) -178.244446 p(w) -416.350220 p(y|xw) -460.803802 min 1.270823 mean 1.525834 max 2.250193\n",
            "1799 loss q(w) -178.244446 p(w) -416.178955 p(y|xw) -479.283478 min 0.725666 mean 1.179820 max 2.190577\n",
            "1799 loss q(w) -178.244446 p(w) -416.219666 p(y|xw) -477.355225 min 0.608942 mean 0.757425 max 1.164961\n",
            "1799 loss q(w) -178.244446 p(w) -416.358643 p(y|xw) -500.256317 min 0.584625 mean 0.815251 max 1.311936\n",
            "1799 loss q(w) -178.244446 p(w) -416.288147 p(y|xw) -515.709106 min 1.024955 mean 1.195879 max 1.472147\n",
            "1799 loss q(w) -178.244446 p(w) -416.553772 p(y|xw) -484.659363 min 0.926797 mean 1.019443 max 1.495951\n",
            "1799 loss q(w) -178.244446 p(w) -416.241455 p(y|xw) -473.270447 min 0.577918 mean 0.846151 max 1.000369\n",
            "1799 loss q(w) -178.244446 p(w) -416.353516 p(y|xw) -474.578461 min 0.403785 mean 0.637852 max 1.122335\n",
            "1799 loss q(w) -178.244446 p(w) -416.505035 p(y|xw) -480.036224 min 0.731116 mean 0.852221 max 1.130257\n",
            "1799 loss q(w) -178.244446 p(w) -416.457916 p(y|xw) -462.692505 min 0.543423 mean 0.874578 max 1.167253\n",
            "iter: 1799 loss: 718.970703 \n",
            "1899 loss q(w) -179.176743 p(w) -416.369934 p(y|xw) -510.595032 min 0.856901 mean 1.359334 max 1.825324\n",
            "1899 loss q(w) -179.176743 p(w) -416.234192 p(y|xw) -465.180206 min 0.962743 mean 1.084215 max 1.626860\n",
            "1899 loss q(w) -179.176743 p(w) -416.309631 p(y|xw) -481.677460 min 0.936536 mean 1.045357 max 1.249185\n",
            "1899 loss q(w) -179.176743 p(w) -416.418884 p(y|xw) -474.564026 min 0.831164 mean 0.947285 max 1.289073\n",
            "1899 loss q(w) -179.176743 p(w) -416.415161 p(y|xw) -431.155914 min 0.922431 mean 1.794651 max 3.540727\n",
            "1899 loss q(w) -179.176743 p(w) -416.140839 p(y|xw) -475.116791 min 0.862974 mean 1.095569 max 1.666108\n",
            "1899 loss q(w) -179.176743 p(w) -416.355652 p(y|xw) -463.961731 min 0.817772 mean 1.018137 max 1.273031\n",
            "1899 loss q(w) -179.176743 p(w) -416.301147 p(y|xw) -490.463959 min 0.946201 mean 1.251596 max 2.603163\n",
            "1899 loss q(w) -179.176743 p(w) -416.291748 p(y|xw) -472.409241 min 0.799603 mean 0.880252 max 1.142767\n",
            "1899 loss q(w) -179.176743 p(w) -416.379974 p(y|xw) -486.396454 min -0.001145 mean 0.311189 max 0.545491\n",
            "iter: 1899 loss: 712.297119 \n",
            "1999 loss q(w) -179.842316 p(w) -416.580658 p(y|xw) -494.359772 min 0.905111 mean 1.007731 max 1.191542\n",
            "1999 loss q(w) -179.842316 p(w) -416.416931 p(y|xw) -494.638916 min 0.363159 mean 0.718460 max 1.234826\n",
            "1999 loss q(w) -179.842316 p(w) -416.604889 p(y|xw) -488.016113 min 0.705317 mean 0.729885 max 0.835980\n",
            "1999 loss q(w) -179.842316 p(w) -416.323914 p(y|xw) -477.389069 min 0.742213 mean 1.045257 max 2.225042\n",
            "1999 loss q(w) -179.842316 p(w) -416.371857 p(y|xw) -452.266815 min 0.965996 mean 1.391331 max 2.417053\n",
            "1999 loss q(w) -179.842316 p(w) -416.463531 p(y|xw) -511.527435 min 0.947950 mean 1.364867 max 2.854030\n",
            "1999 loss q(w) -179.842316 p(w) -416.498840 p(y|xw) -505.671478 min 1.174579 mean 1.703574 max 3.233827\n",
            "1999 loss q(w) -179.842316 p(w) -416.412231 p(y|xw) -458.362732 min 0.694247 mean 0.930609 max 1.436458\n",
            "1999 loss q(w) -179.842316 p(w) -416.381439 p(y|xw) -478.774353 min 0.852881 mean 1.178875 max 2.649862\n",
            "1999 loss q(w) -179.842316 p(w) -416.415405 p(y|xw) -489.166290 min 0.706036 mean 0.914507 max 1.063411\n",
            "iter: 1999 loss: 721.622009 \n",
            "2099 loss q(w) -180.973938 p(w) -416.217957 p(y|xw) -494.699860 min 0.761565 mean 1.005059 max 1.850116\n",
            "2099 loss q(w) -180.973938 p(w) -416.390289 p(y|xw) -532.641724 min 0.086458 mean 0.757065 max 1.131592\n",
            "2099 loss q(w) -180.973938 p(w) -416.340942 p(y|xw) -471.025696 min 0.889999 mean 1.254158 max 2.164690\n",
            "2099 loss q(w) -180.973938 p(w) -416.363922 p(y|xw) -491.138550 min 0.795444 mean 1.056193 max 2.105918\n",
            "2099 loss q(w) -180.973938 p(w) -416.637115 p(y|xw) -474.845795 min 0.784841 mean 1.017122 max 1.471391\n",
            "2099 loss q(w) -180.973938 p(w) -416.315460 p(y|xw) -442.506805 min 0.895318 mean 1.365540 max 2.663504\n",
            "2099 loss q(w) -180.973938 p(w) -416.319519 p(y|xw) -443.843567 min 0.793199 mean 1.196795 max 2.370983\n",
            "2099 loss q(w) -180.973938 p(w) -416.264801 p(y|xw) -463.790161 min 0.658943 mean 1.139970 max 1.574398\n",
            "2099 loss q(w) -180.973938 p(w) -416.217346 p(y|xw) -486.625183 min 0.743432 mean 0.789264 max 0.950684\n",
            "2099 loss q(w) -180.973938 p(w) -416.282379 p(y|xw) -451.380737 min 0.833263 mean 1.190467 max 1.587056\n",
            "iter: 2099 loss: 710.610840 \n",
            "2199 loss q(w) -181.771652 p(w) -416.485931 p(y|xw) -494.670837 min 0.442074 mean 0.777565 max 1.049628\n",
            "2199 loss q(w) -181.771652 p(w) -416.296265 p(y|xw) -498.621094 min 0.863006 mean 1.542315 max 2.068045\n",
            "2199 loss q(w) -181.771652 p(w) -416.399933 p(y|xw) -496.822479 min 0.825363 mean 1.155915 max 2.350683\n",
            "2199 loss q(w) -181.771652 p(w) -416.488373 p(y|xw) -485.711517 min 0.905900 mean 1.334538 max 1.881184\n",
            "2199 loss q(w) -181.771652 p(w) -416.392639 p(y|xw) -486.885620 min 0.721382 mean 0.763014 max 0.896772\n",
            "2199 loss q(w) -181.771652 p(w) -416.519592 p(y|xw) -489.529449 min 0.668237 mean 0.819799 max 1.286516\n",
            "2199 loss q(w) -181.771652 p(w) -416.562958 p(y|xw) -525.999023 min -0.126421 mean 0.550878 max 0.875723\n",
            "2199 loss q(w) -181.771652 p(w) -416.365448 p(y|xw) -475.009979 min 0.735217 mean 0.869521 max 1.414580\n",
            "2199 loss q(w) -181.771652 p(w) -416.396240 p(y|xw) -485.659882 min 0.903742 mean 1.071564 max 1.344008\n",
            "2199 loss q(w) -181.771652 p(w) -416.439514 p(y|xw) -475.712097 min 1.271310 mean 1.549180 max 2.109517\n",
            "iter: 2199 loss: 726.125244 \n",
            "2299 loss q(w) -181.914017 p(w) -416.537109 p(y|xw) -483.512665 min 0.687331 mean 0.748334 max 1.167749\n",
            "2299 loss q(w) -181.914017 p(w) -416.362183 p(y|xw) -485.746399 min 0.748585 mean 1.156797 max 1.694028\n",
            "2299 loss q(w) -181.914017 p(w) -416.442444 p(y|xw) -492.858490 min 0.644415 mean 0.674474 max 0.768093\n",
            "2299 loss q(w) -181.914017 p(w) -416.294678 p(y|xw) -446.128693 min 0.686890 mean 0.990972 max 1.690187\n",
            "2299 loss q(w) -181.914017 p(w) -416.498199 p(y|xw) -473.644623 min 0.694517 mean 0.932823 max 1.288187\n",
            "2299 loss q(w) -181.914017 p(w) -416.356140 p(y|xw) -505.311218 min 0.871741 mean 1.318429 max 3.880683\n",
            "2299 loss q(w) -181.914017 p(w) -416.270386 p(y|xw) -502.518158 min 1.021471 mean 1.208127 max 1.469986\n",
            "2299 loss q(w) -181.914017 p(w) -416.298248 p(y|xw) -476.311584 min 0.913204 mean 0.977147 max 1.176842\n",
            "2299 loss q(w) -181.914017 p(w) -416.412689 p(y|xw) -522.036743 min 1.068187 mean 1.537589 max 2.512034\n",
            "2299 loss q(w) -181.914017 p(w) -416.453003 p(y|xw) -498.131287 min 0.707834 mean 0.891069 max 1.342745\n",
            "iter: 2299 loss: 723.098511 \n",
            "2399 loss q(w) -183.101822 p(w) -416.457947 p(y|xw) -495.044617 min 0.625395 mean 0.843534 max 1.040658\n",
            "2399 loss q(w) -183.101822 p(w) -416.532745 p(y|xw) -458.625061 min 0.903624 mean 1.070482 max 2.032783\n",
            "2399 loss q(w) -183.101822 p(w) -416.660217 p(y|xw) -453.322113 min 0.791840 mean 1.241954 max 1.974557\n",
            "2399 loss q(w) -183.101822 p(w) -416.344513 p(y|xw) -490.084045 min 0.696926 mean 0.732066 max 0.961853\n",
            "2399 loss q(w) -183.101822 p(w) -416.413208 p(y|xw) -490.297516 min 0.885671 mean 1.100535 max 1.691688\n",
            "2399 loss q(w) -183.101822 p(w) -416.580994 p(y|xw) -506.872772 min 0.988795 mean 1.122434 max 1.373303\n",
            "2399 loss q(w) -183.101822 p(w) -416.411774 p(y|xw) -486.107300 min 0.834319 mean 0.883178 max 1.096482\n",
            "2399 loss q(w) -183.101822 p(w) -416.538147 p(y|xw) -467.949738 min 0.863265 mean 1.066183 max 1.381808\n",
            "2399 loss q(w) -183.101822 p(w) -416.614929 p(y|xw) -483.866608 min 0.802288 mean 0.822330 max 0.850561\n",
            "2399 loss q(w) -183.101822 p(w) -416.657104 p(y|xw) -428.046570 min 0.694219 mean 1.102039 max 2.225193\n",
            "iter: 2399 loss: 709.441040 \n",
            "2499 loss q(w) -183.726517 p(w) -416.378174 p(y|xw) -483.831573 min 1.109337 mean 1.240195 max 1.642811\n",
            "2499 loss q(w) -183.726517 p(w) -416.668488 p(y|xw) -506.534637 min 0.729780 mean 1.306279 max 2.621714\n",
            "2499 loss q(w) -183.726517 p(w) -416.428894 p(y|xw) -481.088684 min 1.043673 mean 1.434266 max 1.968887\n",
            "2499 loss q(w) -183.726517 p(w) -416.554504 p(y|xw) -418.759949 min 0.846732 mean 1.601038 max 4.124916\n",
            "2499 loss q(w) -183.726517 p(w) -416.453918 p(y|xw) -482.077454 min 0.847755 mean 1.055321 max 1.868363\n",
            "2499 loss q(w) -183.726517 p(w) -416.698425 p(y|xw) -489.097534 min 0.826985 mean 0.952380 max 1.122574\n",
            "2499 loss q(w) -183.726517 p(w) -416.475342 p(y|xw) -482.663940 min 0.835666 mean 0.934366 max 1.046799\n",
            "2499 loss q(w) -183.726517 p(w) -416.279175 p(y|xw) -480.191986 min 0.896566 mean 0.945287 max 0.981295\n",
            "2499 loss q(w) -183.726517 p(w) -416.483337 p(y|xw) -470.401428 min 0.814049 mean 0.917445 max 1.187359\n",
            "2499 loss q(w) -183.726517 p(w) -416.414551 p(y|xw) -489.299530 min 0.692798 mean 0.882108 max 1.385767\n",
            "iter: 2499 loss: 711.151611 \n",
            "2599 loss q(w) -184.550095 p(w) -416.590057 p(y|xw) -495.042816 min 1.135376 mean 1.380414 max 2.575357\n",
            "2599 loss q(w) -184.550095 p(w) -416.303284 p(y|xw) -439.428711 min 0.881736 mean 1.275905 max 2.406953\n",
            "2599 loss q(w) -184.550095 p(w) -416.472626 p(y|xw) -503.838165 min 0.653483 mean 1.030854 max 2.276010\n",
            "2599 loss q(w) -184.550095 p(w) -416.566406 p(y|xw) -446.618988 min 0.504372 mean 0.877342 max 1.904613\n",
            "2599 loss q(w) -184.550095 p(w) -416.662781 p(y|xw) -468.573486 min 0.850095 mean 0.951632 max 1.325641\n",
            "2599 loss q(w) -184.550095 p(w) -416.606781 p(y|xw) -479.185791 min 0.939588 mean 1.017754 max 1.142009\n",
            "2599 loss q(w) -184.550095 p(w) -416.441010 p(y|xw) -436.849640 min 0.905402 mean 1.258339 max 1.997743\n",
            "2599 loss q(w) -184.550095 p(w) -416.500519 p(y|xw) -441.903595 min 0.785588 mean 1.107099 max 1.858347\n",
            "2599 loss q(w) -184.550095 p(w) -416.686218 p(y|xw) -485.948547 min 0.877280 mean 0.943976 max 1.040402\n",
            "2599 loss q(w) -184.550095 p(w) -416.709595 p(y|xw) -513.356079 min 0.778464 mean 1.097816 max 1.668419\n",
            "iter: 2599 loss: 703.078430 \n",
            "2699 loss q(w) -185.455505 p(w) -416.647278 p(y|xw) -456.784302 min 0.695133 mean 0.981812 max 1.249369\n",
            "2699 loss q(w) -185.455505 p(w) -416.704559 p(y|xw) -493.228760 min 0.462392 mean 0.901227 max 1.713627\n",
            "2699 loss q(w) -185.455505 p(w) -416.650513 p(y|xw) -482.891510 min 0.968347 mean 1.074827 max 1.282791\n",
            "2699 loss q(w) -185.455505 p(w) -416.476990 p(y|xw) -459.678589 min 0.891663 mean 1.045880 max 1.710830\n",
            "2699 loss q(w) -185.455505 p(w) -416.544739 p(y|xw) -493.866211 min 0.597185 mean 0.846519 max 1.880402\n",
            "2699 loss q(w) -185.455505 p(w) -416.788330 p(y|xw) -475.303680 min 0.899981 mean 1.113042 max 1.743457\n",
            "2699 loss q(w) -185.455505 p(w) -416.426147 p(y|xw) -470.920746 min 0.604353 mean 0.799723 max 0.980993\n",
            "2699 loss q(w) -185.455505 p(w) -416.398224 p(y|xw) -485.610748 min 0.532082 mean 0.717885 max 0.805189\n",
            "2699 loss q(w) -185.455505 p(w) -416.636871 p(y|xw) -460.569946 min 0.819418 mean 0.984009 max 1.526007\n",
            "2699 loss q(w) -185.455505 p(w) -416.705353 p(y|xw) -553.887756 min -0.155619 mean 0.676520 max 1.349000\n",
            "iter: 2699 loss: 714.416565 \n",
            "2799 loss q(w) -185.959412 p(w) -416.483643 p(y|xw) -454.556244 min 0.883296 mean 1.196757 max 1.921653\n",
            "2799 loss q(w) -185.959412 p(w) -416.424194 p(y|xw) -460.790771 min 0.867205 mean 1.338417 max 2.433936\n",
            "2799 loss q(w) -185.959412 p(w) -416.707764 p(y|xw) -524.113770 min 0.754227 mean 1.265765 max 2.082829\n",
            "2799 loss q(w) -185.959412 p(w) -416.905304 p(y|xw) -479.192780 min 0.924952 mean 1.112960 max 1.362421\n",
            "2799 loss q(w) -185.959412 p(w) -416.526306 p(y|xw) -479.489716 min 1.282965 mean 1.350538 max 1.528033\n",
            "2799 loss q(w) -185.959412 p(w) -416.542694 p(y|xw) -464.972290 min 0.720682 mean 0.858219 max 1.295313\n",
            "2799 loss q(w) -185.959412 p(w) -416.457489 p(y|xw) -489.534515 min 0.834874 mean 0.965662 max 1.309314\n",
            "2799 loss q(w) -185.959412 p(w) -416.732819 p(y|xw) -472.212433 min 0.912430 mean 1.139042 max 1.607684\n",
            "2799 loss q(w) -185.959412 p(w) -416.658264 p(y|xw) -484.661957 min 0.850760 mean 0.899973 max 1.164983\n",
            "2799 loss q(w) -185.959412 p(w) -416.512665 p(y|xw) -465.132233 min 0.855794 mean 1.043189 max 1.624723\n",
            "iter: 2799 loss: 708.101318 \n",
            "2899 loss q(w) -186.181915 p(w) -416.600098 p(y|xw) -449.522003 min 0.910018 mean 1.244758 max 1.883157\n",
            "2899 loss q(w) -186.181915 p(w) -416.607910 p(y|xw) -442.522430 min 0.825799 mean 1.348677 max 2.070964\n",
            "2899 loss q(w) -186.181915 p(w) -416.610657 p(y|xw) -470.439270 min 0.844522 mean 0.963359 max 1.843301\n",
            "2899 loss q(w) -186.181915 p(w) -416.441864 p(y|xw) -527.878967 min 0.756251 mean 1.020959 max 1.519351\n",
            "2899 loss q(w) -186.181915 p(w) -416.437073 p(y|xw) -463.163025 min 0.707566 mean 0.944291 max 1.400574\n",
            "2899 loss q(w) -186.181915 p(w) -416.564209 p(y|xw) -493.898834 min 0.673419 mean 1.099793 max 2.966538\n",
            "2899 loss q(w) -186.181915 p(w) -416.281830 p(y|xw) -504.141296 min 0.903151 mean 1.046694 max 1.553031\n",
            "2899 loss q(w) -186.181915 p(w) -416.538940 p(y|xw) -470.848969 min 0.983099 mean 1.101463 max 1.781452\n",
            "2899 loss q(w) -186.181915 p(w) -416.571686 p(y|xw) -529.052063 min -0.238538 mean 0.784499 max 1.319419\n",
            "2899 loss q(w) -186.181915 p(w) -416.516174 p(y|xw) -429.617737 min 0.952555 mean 1.945819 max 4.488419\n",
            "iter: 2899 loss: 708.443665 \n",
            "2999 loss q(w) -187.146790 p(w) -416.810547 p(y|xw) -485.928253 min 1.036457 mean 1.384187 max 2.414675\n",
            "2999 loss q(w) -187.146790 p(w) -416.687500 p(y|xw) -481.165741 min 0.932577 mean 1.068378 max 1.599524\n",
            "2999 loss q(w) -187.146790 p(w) -416.817200 p(y|xw) -535.066040 min 0.677477 mean 1.109598 max 4.011970\n",
            "2999 loss q(w) -187.146790 p(w) -416.577820 p(y|xw) -586.204529 min 0.950965 mean 1.559924 max 2.415839\n",
            "2999 loss q(w) -187.146790 p(w) -416.724457 p(y|xw) -640.392090 min 0.928425 mean 2.151452 max 4.744371\n",
            "2999 loss q(w) -187.146790 p(w) -416.639313 p(y|xw) -467.290436 min 0.616303 mean 0.915260 max 1.303797\n",
            "2999 loss q(w) -187.146790 p(w) -416.553406 p(y|xw) -440.219391 min 0.770473 mean 1.714352 max 3.481226\n",
            "2999 loss q(w) -187.146790 p(w) -416.288849 p(y|xw) -493.965607 min 0.723247 mean 0.962245 max 1.829431\n",
            "2999 loss q(w) -187.146790 p(w) -416.874786 p(y|xw) -488.024109 min 0.565271 mean 0.810338 max 1.499599\n",
            "2999 loss q(w) -187.146790 p(w) -416.607269 p(y|xw) -450.873566 min 0.734778 mean 1.025754 max 2.328293\n",
            "iter: 2999 loss: 736.424316 \n",
            "3099 loss q(w) -188.067963 p(w) -416.608978 p(y|xw) -489.268829 min 1.294830 mean 2.069920 max 3.573808\n",
            "3099 loss q(w) -188.067963 p(w) -416.569611 p(y|xw) -544.985657 min 1.012009 mean 1.273260 max 1.757853\n",
            "3099 loss q(w) -188.067963 p(w) -416.580811 p(y|xw) -486.934052 min 0.746876 mean 1.307795 max 2.996530\n",
            "3099 loss q(w) -188.067963 p(w) -416.683472 p(y|xw) -451.984863 min 0.733961 mean 1.192142 max 1.978408\n",
            "3099 loss q(w) -188.067963 p(w) -416.516571 p(y|xw) -468.936279 min 0.587522 mean 0.781347 max 1.224334\n",
            "3099 loss q(w) -188.067963 p(w) -416.483398 p(y|xw) -489.414337 min 0.742333 mean 0.781729 max 0.946593\n",
            "3099 loss q(w) -188.067963 p(w) -416.801727 p(y|xw) -490.309174 min 0.867946 mean 0.928165 max 1.376209\n",
            "3099 loss q(w) -188.067963 p(w) -416.411499 p(y|xw) -458.268494 min 0.821539 mean 1.029351 max 1.583339\n",
            "3099 loss q(w) -188.067963 p(w) -416.434204 p(y|xw) -487.383270 min 0.671921 mean 0.792488 max 1.318704\n",
            "3099 loss q(w) -188.067963 p(w) -416.663971 p(y|xw) -486.557831 min 0.666491 mean 0.714273 max 0.896803\n",
            "iter: 3099 loss: 713.911743 \n",
            "3199 loss q(w) -188.583954 p(w) -416.288239 p(y|xw) -461.860870 min 0.567201 mean 0.958055 max 1.579531\n",
            "3199 loss q(w) -188.583954 p(w) -416.422272 p(y|xw) -461.459106 min 0.776640 mean 1.021383 max 1.791301\n",
            "3199 loss q(w) -188.583954 p(w) -416.504822 p(y|xw) -474.688843 min 0.802256 mean 1.206874 max 2.306847\n",
            "3199 loss q(w) -188.583954 p(w) -416.789948 p(y|xw) -458.748199 min 0.815897 mean 1.322666 max 2.361668\n",
            "3199 loss q(w) -188.583954 p(w) -416.518677 p(y|xw) -475.306061 min 0.857402 mean 1.065045 max 1.592806\n",
            "3199 loss q(w) -188.583954 p(w) -416.357239 p(y|xw) -483.059082 min 1.172569 mean 1.232357 max 1.401052\n",
            "3199 loss q(w) -188.583954 p(w) -416.823059 p(y|xw) -522.003784 min 0.565084 mean 1.278733 max 2.662632\n",
            "3199 loss q(w) -188.583954 p(w) -416.608734 p(y|xw) -494.273315 min 0.716738 mean 1.076274 max 1.504425\n",
            "3199 loss q(w) -188.583954 p(w) -416.614380 p(y|xw) -480.492065 min 0.686724 mean 0.915328 max 1.718316\n",
            "3199 loss q(w) -188.583954 p(w) -416.609772 p(y|xw) -460.981995 min 0.662352 mean 0.913125 max 1.463104\n",
            "iter: 3199 loss: 705.257080 \n",
            "3299 loss q(w) -189.190948 p(w) -416.916443 p(y|xw) -479.003418 min 0.674902 mean 0.918696 max 1.641805\n",
            "3299 loss q(w) -189.190948 p(w) -416.500641 p(y|xw) -444.591217 min 0.685751 mean 0.959570 max 1.804694\n",
            "3299 loss q(w) -189.190948 p(w) -416.463409 p(y|xw) -475.734589 min 0.672301 mean 0.906524 max 1.120770\n",
            "3299 loss q(w) -189.190948 p(w) -416.524353 p(y|xw) -496.179688 min 0.587006 mean 0.629160 max 0.689725\n",
            "3299 loss q(w) -189.190948 p(w) -416.832642 p(y|xw) -517.231873 min 0.772294 mean 1.495839 max 3.816090\n",
            "3299 loss q(w) -189.190948 p(w) -416.808533 p(y|xw) -439.811615 min 1.014857 mean 1.550979 max 2.112420\n",
            "3299 loss q(w) -189.190948 p(w) -416.627777 p(y|xw) -482.782928 min 0.484368 mean 0.869305 max 1.868512\n",
            "3299 loss q(w) -189.190948 p(w) -416.707916 p(y|xw) -519.276062 min 0.848346 mean 0.957122 max 1.437880\n",
            "3299 loss q(w) -189.190948 p(w) -416.472717 p(y|xw) -483.803619 min 0.686464 mean 0.896964 max 1.719195\n",
            "3299 loss q(w) -189.190948 p(w) -416.341309 p(y|xw) -487.770142 min 0.918275 mean 1.157441 max 2.103223\n",
            "iter: 3299 loss: 710.047119 \n",
            "3399 loss q(w) -189.712479 p(w) -416.545715 p(y|xw) -505.306702 min -0.092176 mean 0.467484 max 0.709324\n",
            "3399 loss q(w) -189.712479 p(w) -416.539093 p(y|xw) -515.646484 min 0.696160 mean 1.199302 max 2.236501\n",
            "3399 loss q(w) -189.712479 p(w) -416.394470 p(y|xw) -497.379608 min 0.728355 mean 0.838861 max 1.234282\n",
            "3399 loss q(w) -189.712479 p(w) -416.664093 p(y|xw) -555.885742 min 0.861449 mean 1.246333 max 1.870543\n",
            "3399 loss q(w) -189.712479 p(w) -416.207672 p(y|xw) -488.688232 min 0.686896 mean 0.849188 max 1.324263\n",
            "3399 loss q(w) -189.712479 p(w) -416.712402 p(y|xw) -511.458099 min -0.030981 mean 0.670195 max 1.170981\n",
            "3399 loss q(w) -189.712479 p(w) -416.589844 p(y|xw) -481.629791 min 0.794408 mean 0.966239 max 1.497634\n",
            "3399 loss q(w) -189.712479 p(w) -416.670288 p(y|xw) -490.577728 min 0.660120 mean 0.799401 max 1.548490\n",
            "3399 loss q(w) -189.712479 p(w) -416.545898 p(y|xw) -478.891052 min 1.046211 mean 1.219583 max 1.652824\n",
            "3399 loss q(w) -189.712479 p(w) -416.555054 p(y|xw) -477.865112 min 1.086742 mean 1.217926 max 1.412153\n",
            "iter: 3399 loss: 727.162781 \n",
            "3499 loss q(w) -190.435089 p(w) -416.813019 p(y|xw) -468.429230 min 1.050053 mean 1.191851 max 1.388050\n",
            "3499 loss q(w) -190.435089 p(w) -416.689301 p(y|xw) -484.644287 min 0.671530 mean 0.793575 max 1.277361\n",
            "3499 loss q(w) -190.435089 p(w) -417.196411 p(y|xw) -439.377716 min 0.526704 mean 0.975659 max 1.814955\n",
            "3499 loss q(w) -190.435089 p(w) -416.429535 p(y|xw) -444.910583 min 0.623709 mean 1.143266 max 2.600175\n",
            "3499 loss q(w) -190.435089 p(w) -416.520630 p(y|xw) -475.269318 min 0.819456 mean 1.375812 max 2.853428\n",
            "3499 loss q(w) -190.435089 p(w) -416.621704 p(y|xw) -502.632996 min 0.845601 mean 0.978993 max 1.213808\n",
            "3499 loss q(w) -190.435089 p(w) -416.909790 p(y|xw) -463.961182 min 0.944553 mean 1.211176 max 1.514510\n",
            "3499 loss q(w) -190.435089 p(w) -416.854767 p(y|xw) -484.825531 min 0.856138 mean 0.858376 max 0.865858\n",
            "3499 loss q(w) -190.435089 p(w) -416.501831 p(y|xw) -468.083893 min 0.852320 mean 1.002717 max 1.312333\n",
            "3499 loss q(w) -190.435089 p(w) -416.805573 p(y|xw) -459.862671 min 0.829241 mean 1.277085 max 1.995800\n",
            "iter: 3499 loss: 695.498840 \n",
            "3599 loss q(w) -191.117172 p(w) -416.512604 p(y|xw) -485.224091 min 1.111200 mean 1.299030 max 1.974851\n",
            "3599 loss q(w) -191.117172 p(w) -416.666016 p(y|xw) -479.655670 min 0.921248 mean 1.158949 max 1.531258\n",
            "3599 loss q(w) -191.117172 p(w) -416.613037 p(y|xw) -496.401184 min 1.066607 mean 1.343775 max 1.873974\n",
            "3599 loss q(w) -191.117172 p(w) -417.013855 p(y|xw) -451.555267 min 0.881850 mean 1.281340 max 2.006392\n",
            "3599 loss q(w) -191.117172 p(w) -416.785675 p(y|xw) -451.604370 min 0.670522 mean 1.040018 max 1.583834\n",
            "3599 loss q(w) -191.117172 p(w) -416.555115 p(y|xw) -482.883545 min 0.831735 mean 1.076213 max 1.937594\n",
            "3599 loss q(w) -191.117172 p(w) -416.841217 p(y|xw) -499.874023 min 0.772286 mean 1.065398 max 1.458103\n",
            "3599 loss q(w) -191.117172 p(w) -416.663788 p(y|xw) -488.377319 min 0.733215 mean 0.739753 max 0.823582\n",
            "3599 loss q(w) -191.117172 p(w) -416.531342 p(y|xw) -469.252777 min 0.779961 mean 0.936630 max 1.108703\n",
            "3599 loss q(w) -191.117172 p(w) -416.748962 p(y|xw) -466.595856 min 0.813553 mean 1.215749 max 2.251285\n",
            "iter: 3599 loss: 702.718384 \n",
            "3699 loss q(w) -191.537643 p(w) -416.506836 p(y|xw) -461.969727 min 0.815385 mean 1.048745 max 1.683449\n",
            "3699 loss q(w) -191.537643 p(w) -416.933655 p(y|xw) -477.001923 min 0.810572 mean 1.103629 max 1.508272\n",
            "3699 loss q(w) -191.537643 p(w) -416.378998 p(y|xw) -486.548981 min 0.816579 mean 1.359639 max 2.322515\n",
            "3699 loss q(w) -191.537643 p(w) -416.747833 p(y|xw) -472.930786 min 0.649430 mean 1.023577 max 2.190660\n",
            "3699 loss q(w) -191.537643 p(w) -416.500122 p(y|xw) -478.600891 min 0.777868 mean 1.254335 max 1.435369\n",
            "3699 loss q(w) -191.537643 p(w) -416.643982 p(y|xw) -460.123932 min 0.819649 mean 1.136498 max 1.690372\n",
            "3699 loss q(w) -191.537643 p(w) -416.663757 p(y|xw) -468.754150 min 0.957949 mean 1.160458 max 1.821745\n",
            "3699 loss q(w) -191.537643 p(w) -416.505798 p(y|xw) -484.624695 min 0.837197 mean 1.085012 max 2.177603\n",
            "3699 loss q(w) -191.537643 p(w) -416.461914 p(y|xw) -483.936096 min 0.939327 mean 1.348406 max 2.884594\n",
            "3699 loss q(w) -191.537643 p(w) -416.603638 p(y|xw) -470.490326 min 0.805776 mean 1.183388 max 2.694025\n",
            "iter: 3699 loss: 699.555176 \n",
            "3799 loss q(w) -192.015961 p(w) -416.737976 p(y|xw) -498.488678 min 0.654187 mean 0.931722 max 1.210535\n",
            "3799 loss q(w) -192.015961 p(w) -416.789124 p(y|xw) -478.228180 min 0.657859 mean 0.947829 max 1.985906\n",
            "3799 loss q(w) -192.015961 p(w) -416.600342 p(y|xw) -472.210938 min 0.864085 mean 1.053037 max 1.393698\n",
            "3799 loss q(w) -192.015961 p(w) -416.540527 p(y|xw) -471.339203 min 0.887950 mean 0.973856 max 1.229185\n",
            "3799 loss q(w) -192.015961 p(w) -416.671509 p(y|xw) -464.769165 min 0.909030 mean 1.153895 max 1.600204\n",
            "3799 loss q(w) -192.015961 p(w) -416.836700 p(y|xw) -460.461182 min 0.671653 mean 0.907949 max 1.714951\n",
            "3799 loss q(w) -192.015961 p(w) -416.583984 p(y|xw) -426.285431 min 0.989287 mean 1.749669 max 3.949046\n",
            "3799 loss q(w) -192.015961 p(w) -416.702698 p(y|xw) -471.687836 min 0.585139 mean 1.377191 max 2.581777\n",
            "3799 loss q(w) -192.015961 p(w) -416.656036 p(y|xw) -472.104950 min 0.936346 mean 1.355366 max 2.230463\n",
            "3799 loss q(w) -192.015961 p(w) -416.577271 p(y|xw) -464.633362 min 0.799919 mean 0.935376 max 1.523651\n",
            "iter: 3799 loss: 692.674561 \n",
            "3899 loss q(w) -193.060715 p(w) -416.620361 p(y|xw) -490.947021 min 0.721339 mean 1.021438 max 1.756059\n",
            "3899 loss q(w) -193.060715 p(w) -416.658600 p(y|xw) -499.360565 min 0.750835 mean 1.144740 max 2.120981\n",
            "3899 loss q(w) -193.060715 p(w) -416.515106 p(y|xw) -505.759705 min 0.777956 mean 0.936194 max 1.143846\n",
            "3899 loss q(w) -193.060715 p(w) -416.641541 p(y|xw) -479.082397 min 0.876118 mean 0.956060 max 1.060156\n",
            "3899 loss q(w) -193.060715 p(w) -416.784912 p(y|xw) -489.543396 min 0.852117 mean 1.094963 max 1.534941\n",
            "3899 loss q(w) -193.060715 p(w) -416.470428 p(y|xw) -488.571503 min 1.006314 mean 1.303240 max 2.237370\n",
            "3899 loss q(w) -193.060715 p(w) -416.765137 p(y|xw) -504.411133 min 1.025733 mean 1.203378 max 1.453110\n",
            "3899 loss q(w) -193.060715 p(w) -416.706116 p(y|xw) -485.228424 min 0.787151 mean 1.082588 max 1.382022\n",
            "3899 loss q(w) -193.060715 p(w) -416.686584 p(y|xw) -485.097870 min 0.612416 mean 0.773082 max 0.840205\n",
            "3899 loss q(w) -193.060715 p(w) -416.287994 p(y|xw) -482.503876 min 0.367822 mean 0.737479 max 1.029837\n",
            "iter: 3899 loss: 714.603577 \n",
            "3999 loss q(w) -193.438797 p(w) -416.631775 p(y|xw) -479.428864 min 0.999121 mean 1.475645 max 2.486546\n",
            "3999 loss q(w) -193.438797 p(w) -416.725311 p(y|xw) -466.338013 min 0.980522 mean 1.569117 max 2.626894\n",
            "3999 loss q(w) -193.438797 p(w) -417.136627 p(y|xw) -457.951263 min 0.856703 mean 1.135980 max 1.522172\n",
            "3999 loss q(w) -193.438797 p(w) -416.646912 p(y|xw) -498.722748 min 0.694887 mean 1.046113 max 2.341753\n",
            "3999 loss q(w) -193.438797 p(w) -416.902435 p(y|xw) -467.350342 min 1.033765 mean 1.137789 max 1.450713\n",
            "3999 loss q(w) -193.438797 p(w) -416.895844 p(y|xw) -461.640869 min 0.777658 mean 1.164629 max 1.586972\n",
            "3999 loss q(w) -193.438797 p(w) -416.760437 p(y|xw) -481.524933 min 0.825569 mean 0.916994 max 1.090639\n",
            "3999 loss q(w) -193.438797 p(w) -416.444366 p(y|xw) -530.852905 min 0.700449 mean 0.975167 max 3.101974\n",
            "3999 loss q(w) -193.438797 p(w) -416.506897 p(y|xw) -466.554016 min 0.583896 mean 1.098968 max 1.690506\n",
            "3999 loss q(w) -193.438797 p(w) -416.815186 p(y|xw) -438.642883 min 0.601256 mean 1.529213 max 3.001888\n",
            "iter: 3999 loss: 698.208435 \n",
            "4099 loss q(w) -193.888794 p(w) -416.510437 p(y|xw) -581.200989 min 0.581952 mean 1.328975 max 3.102979\n",
            "4099 loss q(w) -193.888794 p(w) -417.007385 p(y|xw) -496.068817 min 0.585925 mean 0.699735 max 0.778199\n",
            "4099 loss q(w) -193.888794 p(w) -416.796295 p(y|xw) -470.907196 min 0.834846 mean 1.007876 max 1.224658\n",
            "4099 loss q(w) -193.888794 p(w) -416.608521 p(y|xw) -544.227661 min 0.636884 mean 1.449810 max 2.962326\n",
            "4099 loss q(w) -193.888794 p(w) -416.733490 p(y|xw) -463.202271 min 0.752387 mean 1.048826 max 1.776441\n",
            "4099 loss q(w) -193.888794 p(w) -416.956787 p(y|xw) -484.590790 min 0.810305 mean 0.888339 max 1.185020\n",
            "4099 loss q(w) -193.888794 p(w) -416.871094 p(y|xw) -470.744080 min 0.873007 mean 1.486901 max 2.835027\n",
            "4099 loss q(w) -193.888794 p(w) -417.085480 p(y|xw) -526.568481 min 0.861798 mean 1.608167 max 3.518286\n",
            "4099 loss q(w) -193.888794 p(w) -416.645477 p(y|xw) -530.963013 min 0.670209 mean 1.360434 max 2.697434\n",
            "4099 loss q(w) -193.888794 p(w) -416.978577 p(y|xw) -464.157593 min 0.938145 mean 1.071850 max 1.552867\n",
            "iter: 4099 loss: 726.193604 \n",
            "4199 loss q(w) -194.669220 p(w) -416.680298 p(y|xw) -490.187439 min 0.718441 mean 0.831317 max 1.192636\n",
            "4199 loss q(w) -194.669220 p(w) -416.933258 p(y|xw) -496.582550 min 0.815162 mean 0.997919 max 1.253232\n",
            "4199 loss q(w) -194.669220 p(w) -416.933319 p(y|xw) -521.969238 min 1.192087 mean 1.703944 max 2.277096\n",
            "4199 loss q(w) -194.669220 p(w) -416.556488 p(y|xw) -488.154480 min 0.751742 mean 0.858859 max 1.073421\n",
            "4199 loss q(w) -194.669220 p(w) -416.924194 p(y|xw) -469.447357 min 0.611410 mean 1.063007 max 3.101171\n",
            "4199 loss q(w) -194.669220 p(w) -416.578613 p(y|xw) -492.856812 min 0.804446 mean 0.987010 max 1.221669\n",
            "4199 loss q(w) -194.669220 p(w) -416.886932 p(y|xw) -439.223267 min 0.824599 mean 1.153379 max 1.938927\n",
            "4199 loss q(w) -194.669220 p(w) -416.733948 p(y|xw) -498.238800 min 0.884538 mean 1.259739 max 1.910375\n",
            "4199 loss q(w) -194.669220 p(w) -416.790039 p(y|xw) -452.344299 min 0.666729 mean 0.942776 max 1.314732\n",
            "4199 loss q(w) -194.669220 p(w) -416.931824 p(y|xw) -487.488678 min 0.876274 mean 1.051433 max 1.543527\n",
            "iter: 4199 loss: 705.775024 \n",
            "4299 loss q(w) -195.371338 p(w) -416.531097 p(y|xw) -543.066040 min 0.571594 mean 1.182439 max 1.792372\n",
            "4299 loss q(w) -195.371338 p(w) -416.500580 p(y|xw) -495.933380 min 0.671441 mean 1.056319 max 2.734086\n",
            "4299 loss q(w) -195.371338 p(w) -416.456543 p(y|xw) -448.837555 min 0.844272 mean 1.361576 max 2.472482\n",
            "4299 loss q(w) -195.371338 p(w) -417.050171 p(y|xw) -488.898132 min 0.695773 mean 0.761344 max 0.915654\n",
            "4299 loss q(w) -195.371338 p(w) -416.454163 p(y|xw) -470.297211 min 0.668384 mean 0.886129 max 1.393626\n",
            "4299 loss q(w) -195.371338 p(w) -416.604523 p(y|xw) -475.829620 min 0.797021 mean 1.057861 max 1.586218\n",
            "4299 loss q(w) -195.371338 p(w) -416.555786 p(y|xw) -482.694946 min 0.854338 mean 0.958467 max 1.263480\n",
            "4299 loss q(w) -195.371338 p(w) -416.696960 p(y|xw) -488.898743 min 0.806323 mean 1.063076 max 1.510583\n",
            "4299 loss q(w) -195.371338 p(w) -416.589081 p(y|xw) -505.123535 min 0.582153 mean 1.081281 max 2.080513\n",
            "4299 loss q(w) -195.371338 p(w) -416.962341 p(y|xw) -432.380157 min 0.751082 mean 1.251634 max 2.513690\n",
            "iter: 4299 loss: 704.464783 \n",
            "4399 loss q(w) -195.689163 p(w) -416.870300 p(y|xw) -493.794647 min 0.718328 mean 0.820352 max 1.219670\n",
            "4399 loss q(w) -195.689163 p(w) -416.585938 p(y|xw) -538.304810 min 0.884574 mean 1.308498 max 1.766248\n",
            "4399 loss q(w) -195.689163 p(w) -417.068268 p(y|xw) -485.138306 min 0.562675 mean 0.697531 max 0.781327\n",
            "4399 loss q(w) -195.689163 p(w) -417.011353 p(y|xw) -476.197937 min 0.234673 mean 0.754437 max 1.148899\n",
            "4399 loss q(w) -195.689163 p(w) -417.090485 p(y|xw) -468.827972 min 0.898713 mean 1.222397 max 1.974230\n",
            "4399 loss q(w) -195.689163 p(w) -416.720154 p(y|xw) -518.805176 min 1.202056 mean 1.583841 max 3.463427\n",
            "4399 loss q(w) -195.689163 p(w) -416.593567 p(y|xw) -488.603607 min 0.861396 mean 1.140985 max 1.932008\n",
            "4399 loss q(w) -195.689163 p(w) -416.646881 p(y|xw) -504.768494 min 0.714557 mean 0.984850 max 2.409718\n",
            "4399 loss q(w) -195.689163 p(w) -416.677887 p(y|xw) -489.413635 min 0.799954 mean 0.908825 max 1.591308\n",
            "4399 loss q(w) -195.689163 p(w) -416.661560 p(y|xw) -487.611542 min 0.652156 mean 0.699297 max 0.822136\n",
            "iter: 4399 loss: 716.250061 \n",
            "4499 loss q(w) -196.249191 p(w) -416.631989 p(y|xw) -452.052673 min 0.816644 mean 1.083439 max 1.675052\n",
            "4499 loss q(w) -196.249191 p(w) -416.791748 p(y|xw) -488.865540 min 0.613626 mean 0.800188 max 1.620265\n",
            "4499 loss q(w) -196.249191 p(w) -416.715302 p(y|xw) -492.804047 min 0.604544 mean 0.688262 max 1.173192\n",
            "4499 loss q(w) -196.249191 p(w) -416.744751 p(y|xw) -477.445465 min 0.577153 mean 0.751866 max 0.873942\n",
            "4499 loss q(w) -196.249191 p(w) -416.639526 p(y|xw) -489.646851 min 0.885550 mean 1.315665 max 2.876625\n",
            "4499 loss q(w) -196.249191 p(w) -416.755951 p(y|xw) -486.362457 min 0.914975 mean 1.151591 max 2.099855\n",
            "4499 loss q(w) -196.249191 p(w) -416.631866 p(y|xw) -478.372833 min 0.738626 mean 0.858522 max 1.262592\n",
            "4499 loss q(w) -196.249191 p(w) -416.633179 p(y|xw) -485.638916 min 0.652439 mean 0.872971 max 1.265667\n",
            "4499 loss q(w) -196.249191 p(w) -416.719757 p(y|xw) -472.053680 min 0.941344 mean 1.001441 max 1.145529\n",
            "4499 loss q(w) -196.249191 p(w) -416.891663 p(y|xw) -484.850128 min 0.808779 mean 0.956303 max 1.500590\n",
            "iter: 4499 loss: 701.275635 \n",
            "4599 loss q(w) -196.667755 p(w) -416.889099 p(y|xw) -459.132263 min 0.916059 mean 1.094182 max 1.661544\n",
            "4599 loss q(w) -196.667755 p(w) -416.653198 p(y|xw) -484.307220 min 1.007282 mean 1.204719 max 1.738515\n",
            "4599 loss q(w) -196.667755 p(w) -416.601379 p(y|xw) -478.527740 min 0.775325 mean 0.900841 max 1.182632\n",
            "4599 loss q(w) -196.667755 p(w) -416.930756 p(y|xw) -497.957672 min 0.730967 mean 1.070958 max 2.700018\n",
            "4599 loss q(w) -196.667755 p(w) -416.691528 p(y|xw) -541.629883 min 0.369037 mean 0.891591 max 1.624555\n",
            "4599 loss q(w) -196.667755 p(w) -416.942078 p(y|xw) -441.384766 min 0.435616 mean 0.908457 max 1.829479\n",
            "4599 loss q(w) -196.667755 p(w) -416.601318 p(y|xw) -470.683502 min 0.627834 mean 0.841979 max 1.098225\n",
            "4599 loss q(w) -196.667755 p(w) -416.735107 p(y|xw) -451.188629 min 0.834723 mean 1.108777 max 2.004108\n",
            "4599 loss q(w) -196.667755 p(w) -416.806427 p(y|xw) -501.591095 min 0.789109 mean 1.179781 max 2.443068\n",
            "4599 loss q(w) -196.667755 p(w) -416.717102 p(y|xw) -483.717896 min 0.843930 mean 0.928985 max 1.249865\n",
            "iter: 4599 loss: 701.101135 \n",
            "4699 loss q(w) -196.903870 p(w) -416.697174 p(y|xw) -492.691528 min 0.691831 mean 0.795535 max 0.901363\n",
            "4699 loss q(w) -196.903870 p(w) -416.816772 p(y|xw) -474.482666 min 0.946867 mean 1.440940 max 2.744433\n",
            "4699 loss q(w) -196.903870 p(w) -416.680023 p(y|xw) -454.693573 min 0.864850 mean 1.170811 max 2.841600\n",
            "4699 loss q(w) -196.903870 p(w) -416.589661 p(y|xw) -476.101013 min 0.752168 mean 0.813931 max 1.013187\n",
            "4699 loss q(w) -196.903870 p(w) -416.915955 p(y|xw) -478.614258 min 0.764076 mean 0.867243 max 1.027188\n",
            "4699 loss q(w) -196.903870 p(w) -416.721497 p(y|xw) -489.684082 min 0.831950 mean 1.057939 max 1.495726\n",
            "4699 loss q(w) -196.903870 p(w) -416.881592 p(y|xw) -473.682129 min 0.765428 mean 0.981547 max 1.454606\n",
            "4699 loss q(w) -196.903870 p(w) -417.016876 p(y|xw) -545.341675 min 1.427139 mean 1.741392 max 2.259989\n",
            "4699 loss q(w) -196.903870 p(w) -416.890442 p(y|xw) -531.828247 min 1.062044 mean 1.692200 max 3.993726\n",
            "4699 loss q(w) -196.903870 p(w) -416.542053 p(y|xw) -464.051025 min 0.650141 mean 0.873254 max 1.533059\n",
            "iter: 4699 loss: 707.988342 \n",
            "4799 loss q(w) -197.462646 p(w) -416.763702 p(y|xw) -484.124786 min 0.738843 mean 1.036823 max 1.963569\n",
            "4799 loss q(w) -197.462646 p(w) -416.788422 p(y|xw) -490.100433 min 0.688962 mean 0.796074 max 1.002733\n",
            "4799 loss q(w) -197.462646 p(w) -416.936157 p(y|xw) -475.898773 min 0.886231 mean 1.154932 max 1.599637\n",
            "4799 loss q(w) -197.462646 p(w) -416.758240 p(y|xw) -474.880524 min 0.882332 mean 1.588892 max 2.762374\n",
            "4799 loss q(w) -197.462646 p(w) -416.624603 p(y|xw) -492.041382 min 0.827136 mean 0.899803 max 1.516768\n",
            "4799 loss q(w) -197.462646 p(w) -416.650665 p(y|xw) -465.222107 min 0.774879 mean 0.927695 max 1.489572\n",
            "4799 loss q(w) -197.462646 p(w) -417.275360 p(y|xw) -464.545135 min 0.571181 mean 0.842926 max 1.245971\n",
            "4799 loss q(w) -197.462646 p(w) -416.569916 p(y|xw) -475.886658 min 0.553427 mean 0.721865 max 1.289865\n",
            "4799 loss q(w) -197.462646 p(w) -416.810883 p(y|xw) -495.367706 min 0.854716 mean 1.234537 max 2.822334\n",
            "4799 loss q(w) -197.462646 p(w) -416.777740 p(y|xw) -525.842163 min 0.348354 mean 0.757853 max 1.143777\n",
            "iter: 4799 loss: 703.723938 \n",
            "4899 loss q(w) -198.047028 p(w) -416.741394 p(y|xw) -464.067505 min 0.572924 mean 0.812867 max 1.140011\n",
            "4899 loss q(w) -198.047028 p(w) -416.987030 p(y|xw) -498.949219 min 0.882310 mean 1.246250 max 2.303153\n",
            "4899 loss q(w) -198.047028 p(w) -416.906891 p(y|xw) -508.014526 min 0.233452 mean 0.738500 max 1.067843\n",
            "4899 loss q(w) -198.047028 p(w) -416.771667 p(y|xw) -458.490997 min 0.878332 mean 1.290083 max 2.160186\n",
            "4899 loss q(w) -198.047028 p(w) -416.685913 p(y|xw) -454.267365 min 0.716544 mean 1.683329 max 4.133474\n",
            "4899 loss q(w) -198.047028 p(w) -416.978638 p(y|xw) -499.017212 min 0.808903 mean 1.571772 max 3.614356\n",
            "4899 loss q(w) -198.047028 p(w) -416.835327 p(y|xw) -475.952454 min 1.039090 mean 1.251384 max 1.459881\n",
            "4899 loss q(w) -198.047028 p(w) -416.912567 p(y|xw) -483.416199 min 0.456091 mean 0.597538 max 1.030025\n",
            "4899 loss q(w) -198.047028 p(w) -416.484680 p(y|xw) -450.685974 min 0.899277 mean 1.179609 max 2.043751\n",
            "4899 loss q(w) -198.047028 p(w) -416.751678 p(y|xw) -501.893433 min 0.598707 mean 0.894232 max 1.247374\n",
            "iter: 4899 loss: 698.234009 \n",
            "4999 loss q(w) -198.445847 p(w) -416.767334 p(y|xw) -484.866730 min 0.555954 mean 0.689465 max 1.123766\n",
            "4999 loss q(w) -198.445847 p(w) -416.563721 p(y|xw) -492.854736 min 0.711287 mean 0.765027 max 1.235928\n",
            "4999 loss q(w) -198.445847 p(w) -416.469788 p(y|xw) -468.495087 min 0.752584 mean 0.875907 max 1.193092\n",
            "4999 loss q(w) -198.445847 p(w) -416.741730 p(y|xw) -481.761108 min 0.748144 mean 0.976315 max 1.663422\n",
            "4999 loss q(w) -198.445847 p(w) -416.938202 p(y|xw) -504.011230 min 0.611094 mean 0.848740 max 1.983140\n",
            "4999 loss q(w) -198.445847 p(w) -417.100769 p(y|xw) -464.185425 min 0.794430 mean 1.337626 max 3.091651\n",
            "4999 loss q(w) -198.445847 p(w) -416.723694 p(y|xw) -421.902954 min 0.486021 mean 1.128818 max 3.027284\n",
            "4999 loss q(w) -198.445847 p(w) -416.415100 p(y|xw) -487.851898 min 0.982450 mean 1.344638 max 2.864026\n",
            "4999 loss q(w) -198.445847 p(w) -416.666931 p(y|xw) -477.362457 min 0.747032 mean 1.100538 max 1.748699\n",
            "4999 loss q(w) -198.445847 p(w) -416.811981 p(y|xw) -479.372620 min 0.610643 mean 0.865175 max 1.776017\n",
            "iter: 4999 loss: 694.540466 \n",
            "5099 loss q(w) -199.280838 p(w) -416.772614 p(y|xw) -464.575104 min 0.834340 mean 1.193627 max 1.907904\n",
            "5099 loss q(w) -199.280838 p(w) -417.107056 p(y|xw) -434.980225 min 0.806019 mean 1.320468 max 2.311806\n",
            "5099 loss q(w) -199.280838 p(w) -416.916107 p(y|xw) -472.298767 min 0.666389 mean 0.994898 max 1.772542\n",
            "5099 loss q(w) -199.280838 p(w) -416.757324 p(y|xw) -489.557648 min 0.609283 mean 1.696298 max 2.566878\n",
            "5099 loss q(w) -199.280838 p(w) -416.925568 p(y|xw) -500.952179 min 0.607372 mean 0.817139 max 1.040991\n",
            "5099 loss q(w) -199.280838 p(w) -416.930969 p(y|xw) -461.609100 min 0.928462 mean 1.188536 max 2.020287\n",
            "5099 loss q(w) -199.280838 p(w) -416.622009 p(y|xw) -475.896576 min 0.815460 mean 0.991031 max 1.355071\n",
            "5099 loss q(w) -199.280838 p(w) -417.008759 p(y|xw) -466.866638 min 0.877192 mean 1.223021 max 1.551824\n",
            "5099 loss q(w) -199.280838 p(w) -416.870178 p(y|xw) -467.887878 min 0.769760 mean 1.491443 max 2.714815\n",
            "5099 loss q(w) -199.280838 p(w) -417.030090 p(y|xw) -499.935425 min 0.542843 mean 0.773954 max 0.869566\n",
            "iter: 5099 loss: 691.069214 \n",
            "5199 loss q(w) -199.613205 p(w) -416.672485 p(y|xw) -483.458557 min 0.903307 mean 1.041553 max 1.417344\n",
            "5199 loss q(w) -199.613205 p(w) -416.396667 p(y|xw) -450.301971 min 0.601807 mean 0.870746 max 1.956698\n",
            "5199 loss q(w) -199.613205 p(w) -417.047821 p(y|xw) -455.966919 min 0.685051 mean 0.897051 max 1.563138\n",
            "5199 loss q(w) -199.613205 p(w) -417.138489 p(y|xw) -487.332458 min 0.578107 mean 1.054625 max 2.200945\n",
            "5199 loss q(w) -199.613205 p(w) -417.115540 p(y|xw) -472.289703 min 0.737729 mean 0.885370 max 1.132379\n",
            "5199 loss q(w) -199.613205 p(w) -416.583069 p(y|xw) -489.788422 min 0.696520 mean 0.737034 max 0.941019\n",
            "5199 loss q(w) -199.613205 p(w) -416.869080 p(y|xw) -468.451935 min 0.562070 mean 0.708236 max 1.185965\n",
            "5199 loss q(w) -199.613205 p(w) -416.819489 p(y|xw) -454.184235 min 1.026289 mean 1.379626 max 1.900684\n",
            "5199 loss q(w) -199.613205 p(w) -416.888245 p(y|xw) -482.589844 min 0.458706 mean 0.757432 max 0.911296\n",
            "5199 loss q(w) -199.613205 p(w) -416.406982 p(y|xw) -505.954254 min 0.377234 mean 1.040394 max 1.825881\n",
            "iter: 5199 loss: 692.212402 \n",
            "5299 loss q(w) -199.994934 p(w) -416.856232 p(y|xw) -461.701843 min 0.812786 mean 1.039411 max 1.457098\n",
            "5299 loss q(w) -199.994934 p(w) -416.760712 p(y|xw) -498.074188 min 0.728565 mean 1.026890 max 1.904947\n",
            "5299 loss q(w) -199.994934 p(w) -416.747101 p(y|xw) -474.179291 min 0.934892 mean 1.162602 max 1.695347\n",
            "5299 loss q(w) -199.994934 p(w) -416.735168 p(y|xw) -513.788940 min 0.787404 mean 0.975916 max 1.374715\n",
            "5299 loss q(w) -199.994934 p(w) -416.800354 p(y|xw) -498.896454 min 0.723780 mean 1.253519 max 2.383169\n",
            "5299 loss q(w) -199.994934 p(w) -416.534271 p(y|xw) -494.559723 min 0.738881 mean 1.077981 max 1.424456\n",
            "5299 loss q(w) -199.994934 p(w) -416.899902 p(y|xw) -491.574463 min 0.682158 mean 1.092576 max 1.804643\n",
            "5299 loss q(w) -199.994934 p(w) -416.808289 p(y|xw) -494.326324 min 0.742230 mean 1.090122 max 2.273414\n",
            "5299 loss q(w) -199.994934 p(w) -416.827209 p(y|xw) -432.661499 min 0.870634 mean 1.413182 max 2.486763\n",
            "5299 loss q(w) -199.994934 p(w) -416.627716 p(y|xw) -486.632080 min 0.532152 mean 0.739948 max 1.376073\n",
            "iter: 5299 loss: 701.404236 \n",
            "5399 loss q(w) -200.561447 p(w) -416.776398 p(y|xw) -486.212585 min 0.602270 mean 0.894998 max 2.053837\n",
            "5399 loss q(w) -200.561447 p(w) -416.656128 p(y|xw) -519.446899 min 0.676177 mean 1.266196 max 2.102320\n",
            "5399 loss q(w) -200.561447 p(w) -416.814514 p(y|xw) -505.807434 min 1.048569 mean 1.405150 max 3.038674\n",
            "5399 loss q(w) -200.561447 p(w) -416.672302 p(y|xw) -499.719330 min 0.943924 mean 1.180473 max 1.634567\n",
            "5399 loss q(w) -200.561447 p(w) -416.666687 p(y|xw) -479.248199 min 0.678983 mean 1.164543 max 2.161999\n",
            "5399 loss q(w) -200.561447 p(w) -416.599030 p(y|xw) -487.087311 min 0.716560 mean 1.186652 max 2.749913\n",
            "5399 loss q(w) -200.561447 p(w) -416.772003 p(y|xw) -468.035217 min 0.847211 mean 1.284252 max 1.949918\n",
            "5399 loss q(w) -200.561447 p(w) -416.683411 p(y|xw) -506.768677 min 0.857590 mean 1.082019 max 1.487263\n",
            "5399 loss q(w) -200.561447 p(w) -416.732391 p(y|xw) -456.361847 min 0.772873 mean 1.043770 max 2.262429\n",
            "5399 loss q(w) -200.561447 p(w) -416.980835 p(y|xw) -467.214508 min 0.991632 mean 1.447543 max 2.333559\n",
            "iter: 5399 loss: 703.764160 \n",
            "5499 loss q(w) -200.817368 p(w) -416.629028 p(y|xw) -481.416168 min 0.722130 mean 1.137428 max 2.310325\n",
            "5499 loss q(w) -200.817368 p(w) -416.972107 p(y|xw) -447.533386 min 0.659810 mean 1.134679 max 2.022725\n",
            "5499 loss q(w) -200.817368 p(w) -416.860016 p(y|xw) -447.614258 min 0.494964 mean 0.830132 max 2.718318\n",
            "5499 loss q(w) -200.817368 p(w) -416.940979 p(y|xw) -488.458282 min 0.728860 mean 0.733403 max 0.826112\n",
            "5499 loss q(w) -200.817368 p(w) -416.799866 p(y|xw) -459.633667 min 0.689766 mean 0.976991 max 1.482936\n",
            "5499 loss q(w) -200.817368 p(w) -416.983307 p(y|xw) -488.515594 min 0.599759 mean 1.047183 max 1.566353\n",
            "5499 loss q(w) -200.817368 p(w) -416.862244 p(y|xw) -437.739044 min -0.288574 mean 0.808268 max 2.051078\n",
            "5499 loss q(w) -200.817368 p(w) -416.872681 p(y|xw) -470.931396 min 0.695469 mean 0.895514 max 1.998460\n",
            "5499 loss q(w) -200.817368 p(w) -416.758820 p(y|xw) -433.563934 min 0.674633 mean 1.186389 max 3.422900\n",
            "5499 loss q(w) -200.817368 p(w) -416.819214 p(y|xw) -464.437378 min 0.697583 mean 0.889295 max 1.460376\n",
            "iter: 5499 loss: 678.016846 \n",
            "5599 loss q(w) -201.242065 p(w) -416.504425 p(y|xw) -446.628998 min 0.727809 mean 1.037330 max 1.796348\n",
            "5599 loss q(w) -201.242065 p(w) -416.722839 p(y|xw) -428.584991 min 0.709829 mean 1.345949 max 3.294742\n",
            "5599 loss q(w) -201.242065 p(w) -416.854065 p(y|xw) -488.010284 min 1.032893 mean 1.214798 max 1.872074\n",
            "5599 loss q(w) -201.242065 p(w) -417.040222 p(y|xw) -483.046051 min 1.026232 mean 1.303502 max 2.328613\n",
            "5599 loss q(w) -201.242065 p(w) -416.653809 p(y|xw) -491.369171 min 0.924311 mean 1.208203 max 2.571244\n",
            "5599 loss q(w) -201.242065 p(w) -417.284607 p(y|xw) -482.376770 min 0.866995 mean 1.132691 max 2.068464\n",
            "5599 loss q(w) -201.242065 p(w) -417.102936 p(y|xw) -466.338593 min 0.286431 mean 0.794053 max 1.971435\n",
            "5599 loss q(w) -201.242065 p(w) -416.827454 p(y|xw) -494.564392 min 0.693234 mean 0.770014 max 1.235870\n",
            "5599 loss q(w) -201.242065 p(w) -417.074036 p(y|xw) -482.569611 min 1.110403 mean 1.398281 max 2.011951\n",
            "5599 loss q(w) -201.242065 p(w) -416.977722 p(y|xw) -546.528809 min 0.812043 mean 1.313893 max 2.018964\n",
            "iter: 5599 loss: 696.663879 \n",
            "5699 loss q(w) -201.708862 p(w) -416.742523 p(y|xw) -473.014069 min 0.883148 mean 1.205017 max 1.810198\n",
            "5699 loss q(w) -201.708862 p(w) -416.948730 p(y|xw) -474.161621 min 0.933860 mean 1.116493 max 1.592379\n",
            "5699 loss q(w) -201.708862 p(w) -416.551788 p(y|xw) -485.451569 min 0.944872 mean 1.208806 max 1.723121\n",
            "5699 loss q(w) -201.708862 p(w) -416.932770 p(y|xw) -485.797424 min 0.693987 mean 0.834943 max 1.465683\n",
            "5699 loss q(w) -201.708862 p(w) -416.959686 p(y|xw) -487.684418 min 0.682910 mean 0.974824 max 1.611125\n",
            "5699 loss q(w) -201.708862 p(w) -416.834717 p(y|xw) -524.092834 min 1.038648 mean 1.624372 max 2.264581\n",
            "5699 loss q(w) -201.708862 p(w) -416.796265 p(y|xw) -478.394409 min 0.666117 mean 0.809281 max 1.491430\n",
            "5699 loss q(w) -201.708862 p(w) -417.195068 p(y|xw) -563.924011 min 0.720178 mean 1.061707 max 1.877337\n",
            "5699 loss q(w) -201.708862 p(w) -416.892792 p(y|xw) -471.023560 min 0.759960 mean 0.944818 max 1.349959\n",
            "5699 loss q(w) -201.708862 p(w) -416.943207 p(y|xw) -454.198181 min 0.993873 mean 1.499558 max 2.935545\n",
            "iter: 5699 loss: 704.945068 \n",
            "5799 loss q(w) -202.412430 p(w) -416.852814 p(y|xw) -504.051575 min 0.627714 mean 1.068894 max 2.790915\n",
            "5799 loss q(w) -202.412430 p(w) -416.677826 p(y|xw) -471.221527 min 0.737371 mean 1.182052 max 4.449739\n",
            "5799 loss q(w) -202.412430 p(w) -417.012939 p(y|xw) -593.318115 min 0.184341 mean 1.381148 max 4.446249\n",
            "5799 loss q(w) -202.412430 p(w) -416.886444 p(y|xw) -490.908600 min 0.840620 mean 0.980312 max 1.436607\n",
            "5799 loss q(w) -202.412430 p(w) -417.061676 p(y|xw) -458.670563 min 0.625775 mean 1.193663 max 2.837695\n",
            "5799 loss q(w) -202.412430 p(w) -416.829712 p(y|xw) -483.660675 min 0.490442 mean 0.659608 max 0.791928\n",
            "5799 loss q(w) -202.412430 p(w) -416.890076 p(y|xw) -461.216003 min 0.908169 mean 1.368279 max 2.249626\n",
            "5799 loss q(w) -202.412430 p(w) -416.802795 p(y|xw) -518.233948 min 0.794533 mean 0.907089 max 1.181433\n",
            "5799 loss q(w) -202.412430 p(w) -416.630127 p(y|xw) -496.023804 min 0.738457 mean 1.111473 max 1.666528\n",
            "5799 loss q(w) -202.412430 p(w) -416.890839 p(y|xw) -473.686462 min 0.913247 mean 1.141104 max 1.714302\n",
            "iter: 5799 loss: 709.540222 \n",
            "5899 loss q(w) -202.784424 p(w) -416.769470 p(y|xw) -483.196320 min 0.804308 mean 0.957816 max 1.546839\n",
            "5899 loss q(w) -202.784424 p(w) -416.753113 p(y|xw) -519.260803 min 0.523031 mean 0.963256 max 1.699044\n",
            "5899 loss q(w) -202.784424 p(w) -416.538757 p(y|xw) -477.724243 min 0.622657 mean 0.960833 max 1.991921\n",
            "5899 loss q(w) -202.784424 p(w) -416.757568 p(y|xw) -444.516785 min 0.604185 mean 1.102374 max 2.396572\n",
            "5899 loss q(w) -202.784424 p(w) -417.066803 p(y|xw) -445.220032 min 0.922311 mean 1.603531 max 3.401728\n",
            "5899 loss q(w) -202.784424 p(w) -416.928772 p(y|xw) -437.878296 min 0.758155 mean 1.493206 max 2.559387\n",
            "5899 loss q(w) -202.784424 p(w) -416.927246 p(y|xw) -488.324097 min 0.535894 mean 0.797457 max 1.857678\n",
            "5899 loss q(w) -202.784424 p(w) -416.898438 p(y|xw) -440.871552 min 0.729813 mean 1.053724 max 2.245965\n",
            "5899 loss q(w) -202.784424 p(w) -416.935608 p(y|xw) -515.425110 min 0.639279 mean 0.902491 max 2.537219\n",
            "5899 loss q(w) -202.784424 p(w) -416.597107 p(y|xw) -475.823303 min 0.569178 mean 1.109320 max 2.259365\n",
            "iter: 5899 loss: 686.856934 \n",
            "5999 loss q(w) -203.293777 p(w) -416.908966 p(y|xw) -429.645081 min 0.712048 mean 1.257033 max 2.891356\n",
            "5999 loss q(w) -203.293777 p(w) -416.938782 p(y|xw) -469.357666 min 0.796591 mean 1.271409 max 2.409911\n",
            "5999 loss q(w) -203.293777 p(w) -416.641754 p(y|xw) -428.985992 min 0.773939 mean 1.206021 max 2.454174\n",
            "5999 loss q(w) -203.293777 p(w) -416.793030 p(y|xw) -454.822113 min 0.822573 mean 1.057819 max 1.882205\n",
            "5999 loss q(w) -203.293777 p(w) -417.023193 p(y|xw) -491.677917 min 0.657857 mean 0.803402 max 1.540222\n",
            "5999 loss q(w) -203.293777 p(w) -417.056000 p(y|xw) -471.583435 min 0.415088 mean 1.316319 max 3.411370\n",
            "5999 loss q(w) -203.293777 p(w) -416.678497 p(y|xw) -431.481079 min 0.769073 mean 1.302893 max 2.500475\n",
            "5999 loss q(w) -203.293777 p(w) -416.954590 p(y|xw) -432.694672 min 0.854745 mean 1.558144 max 3.525697\n",
            "5999 loss q(w) -203.293777 p(w) -416.930206 p(y|xw) -484.182068 min 0.795307 mean 0.951809 max 1.769283\n",
            "5999 loss q(w) -203.293777 p(w) -416.936462 p(y|xw) -408.206787 min 0.668710 mean 1.300014 max 2.518927\n",
            "iter: 5999 loss: 663.856079 \n",
            "6099 loss q(w) -204.208771 p(w) -416.823883 p(y|xw) -464.351135 min 0.788367 mean 1.217081 max 1.977782\n",
            "6099 loss q(w) -204.208771 p(w) -416.934357 p(y|xw) -469.705353 min 1.006561 mean 1.185290 max 1.585508\n",
            "6099 loss q(w) -204.208771 p(w) -417.203217 p(y|xw) -468.772125 min 1.083667 mean 1.675719 max 3.046804\n",
            "6099 loss q(w) -204.208771 p(w) -416.937286 p(y|xw) -525.005066 min 0.621863 mean 0.876304 max 1.228566\n",
            "6099 loss q(w) -204.208771 p(w) -417.191193 p(y|xw) -441.322266 min 0.643493 mean 1.572581 max 3.064679\n",
            "6099 loss q(w) -204.208771 p(w) -416.738770 p(y|xw) -461.707550 min 0.750030 mean 1.020892 max 2.154151\n",
            "6099 loss q(w) -204.208771 p(w) -417.133545 p(y|xw) -511.484619 min 0.757709 mean 1.123464 max 1.443721\n",
            "6099 loss q(w) -204.208771 p(w) -417.298218 p(y|xw) -467.231354 min 0.788193 mean 1.051654 max 1.439218\n",
            "6099 loss q(w) -204.208771 p(w) -417.100708 p(y|xw) -499.305847 min 0.787876 mean 0.936987 max 1.477127\n",
            "6099 loss q(w) -204.208771 p(w) -416.856598 p(y|xw) -522.257446 min 0.870081 mean 1.403615 max 4.062820\n",
            "iter: 6099 loss: 695.927307 \n",
            "6199 loss q(w) -204.290512 p(w) -417.071442 p(y|xw) -439.105072 min 0.832092 mean 1.368584 max 1.948207\n",
            "6199 loss q(w) -204.290512 p(w) -416.974152 p(y|xw) -473.885223 min 0.673375 mean 0.783783 max 1.307339\n",
            "6199 loss q(w) -204.290512 p(w) -417.297272 p(y|xw) -471.726959 min 0.644067 mean 0.964793 max 2.011613\n",
            "6199 loss q(w) -204.290512 p(w) -416.954468 p(y|xw) -518.532166 min 0.792797 mean 1.230798 max 3.353332\n",
            "6199 loss q(w) -204.290512 p(w) -416.916382 p(y|xw) -476.417236 min 0.770850 mean 1.463361 max 3.259755\n",
            "6199 loss q(w) -204.290512 p(w) -416.846436 p(y|xw) -484.717468 min 0.541639 mean 0.624430 max 0.732546\n",
            "6199 loss q(w) -204.290512 p(w) -417.287262 p(y|xw) -494.514252 min 0.724744 mean 1.400395 max 3.228906\n",
            "6199 loss q(w) -204.290512 p(w) -416.827332 p(y|xw) -515.405151 min 0.717928 mean 1.435106 max 2.500546\n",
            "6199 loss q(w) -204.290512 p(w) -416.960754 p(y|xw) -455.783600 min 0.551475 mean 0.958473 max 1.858828\n",
            "6199 loss q(w) -204.290512 p(w) -416.903015 p(y|xw) -443.185638 min 0.706924 mean 1.024308 max 1.797713\n",
            "iter: 6199 loss: 690.040649 \n",
            "6299 loss q(w) -204.810181 p(w) -416.978455 p(y|xw) -482.594604 min 0.597256 mean 0.763630 max 1.038748\n",
            "6299 loss q(w) -204.810181 p(w) -416.820740 p(y|xw) -492.531250 min 0.840943 mean 0.987711 max 1.239227\n",
            "6299 loss q(w) -204.810181 p(w) -416.441895 p(y|xw) -479.001617 min 0.682342 mean 0.758320 max 0.939183\n",
            "6299 loss q(w) -204.810181 p(w) -416.813721 p(y|xw) -505.908783 min 0.545515 mean 0.754624 max 1.090870\n",
            "6299 loss q(w) -204.810181 p(w) -416.691956 p(y|xw) -469.651764 min 0.644226 mean 0.825719 max 1.084253\n",
            "6299 loss q(w) -204.810181 p(w) -416.784058 p(y|xw) -462.820557 min 0.738664 mean 0.996187 max 1.555679\n",
            "6299 loss q(w) -204.810181 p(w) -416.899353 p(y|xw) -435.713257 min 0.718342 mean 1.225026 max 1.950759\n",
            "6299 loss q(w) -204.810181 p(w) -416.869385 p(y|xw) -493.413055 min 0.603634 mean 0.659646 max 0.710115\n",
            "6299 loss q(w) -204.810181 p(w) -416.995361 p(y|xw) -525.422974 min 0.600521 mean 1.365975 max 2.968333\n",
            "6299 loss q(w) -204.810181 p(w) -417.190308 p(y|xw) -456.808075 min 0.709994 mean 1.116020 max 1.782187\n",
            "iter: 6299 loss: 692.424927 \n",
            "6399 loss q(w) -205.436783 p(w) -416.725372 p(y|xw) -475.386047 min 0.630489 mean 0.856635 max 1.415704\n",
            "6399 loss q(w) -205.436783 p(w) -416.869049 p(y|xw) -487.605530 min 0.757223 mean 1.048829 max 1.285631\n",
            "6399 loss q(w) -205.436783 p(w) -416.971069 p(y|xw) -466.660645 min 0.880314 mean 1.267115 max 1.948967\n",
            "6399 loss q(w) -205.436783 p(w) -416.815247 p(y|xw) -480.174591 min 0.785535 mean 1.117865 max 2.192185\n",
            "6399 loss q(w) -205.436783 p(w) -416.793213 p(y|xw) -479.664032 min 0.793035 mean 0.886696 max 1.114706\n",
            "6399 loss q(w) -205.436783 p(w) -416.714996 p(y|xw) -425.489258 min 0.675671 mean 1.611884 max 4.018412\n",
            "6399 loss q(w) -205.436783 p(w) -416.693054 p(y|xw) -465.346436 min 0.781408 mean 1.089301 max 1.604846\n",
            "6399 loss q(w) -205.436783 p(w) -417.022949 p(y|xw) -470.909546 min 1.019508 mean 1.213082 max 1.515069\n",
            "6399 loss q(w) -205.436783 p(w) -417.069214 p(y|xw) -519.207886 min 0.873218 mean 1.180522 max 1.587041\n",
            "6399 loss q(w) -205.436783 p(w) -417.355621 p(y|xw) -476.661438 min 0.836825 mean 0.969731 max 1.344056\n",
            "iter: 6399 loss: 686.176819 \n",
            "6499 loss q(w) -205.373596 p(w) -416.874573 p(y|xw) -486.544525 min 0.794364 mean 0.994009 max 1.218099\n",
            "6499 loss q(w) -205.373596 p(w) -416.999817 p(y|xw) -421.982727 min 0.736001 mean 1.564802 max 4.833871\n",
            "6499 loss q(w) -205.373596 p(w) -416.875366 p(y|xw) -459.713318 min 0.873879 mean 1.025382 max 1.587812\n",
            "6499 loss q(w) -205.373596 p(w) -417.098602 p(y|xw) -469.705750 min 0.548673 mean 0.701502 max 1.008195\n",
            "6499 loss q(w) -205.373596 p(w) -417.301453 p(y|xw) -482.552582 min 0.594847 mean 1.181666 max 3.058296\n",
            "6499 loss q(w) -205.373596 p(w) -417.475739 p(y|xw) -542.225464 min 0.909720 mean 2.196824 max 5.283901\n",
            "6499 loss q(w) -205.373596 p(w) -417.076172 p(y|xw) -489.693115 min 0.661085 mean 1.157175 max 2.835485\n",
            "6499 loss q(w) -205.373596 p(w) -416.929565 p(y|xw) -474.171692 min 0.731989 mean 1.028271 max 1.734602\n",
            "6499 loss q(w) -205.373596 p(w) -417.294556 p(y|xw) -462.121979 min 0.777822 mean 0.961366 max 1.864035\n",
            "6499 loss q(w) -205.373596 p(w) -416.826202 p(y|xw) -432.580536 min 0.654182 mean 1.644119 max 2.723676\n",
            "iter: 6499 loss: 683.830750 \n",
            "6599 loss q(w) -205.913712 p(w) -417.179626 p(y|xw) -417.925568 min 0.791225 mean 1.432075 max 2.833054\n",
            "6599 loss q(w) -205.913712 p(w) -416.917603 p(y|xw) -480.205719 min 0.860279 mean 0.988247 max 1.466088\n",
            "6599 loss q(w) -205.913712 p(w) -417.062103 p(y|xw) -547.450623 min 0.625007 mean 1.492493 max 2.924365\n",
            "6599 loss q(w) -205.913712 p(w) -416.859802 p(y|xw) -469.351501 min 0.792978 mean 0.965062 max 1.175124\n",
            "6599 loss q(w) -205.913712 p(w) -417.045227 p(y|xw) -503.348724 min 0.488781 mean 0.677784 max 0.856993\n",
            "6599 loss q(w) -205.913712 p(w) -416.800415 p(y|xw) -472.907654 min 0.678190 mean 0.859780 max 1.155663\n",
            "6599 loss q(w) -205.913712 p(w) -416.975433 p(y|xw) -496.761108 min 0.640045 mean 0.783265 max 1.070144\n",
            "6599 loss q(w) -205.913712 p(w) -417.073792 p(y|xw) -509.800934 min 0.822453 mean 1.317943 max 1.628327\n",
            "6599 loss q(w) -205.913712 p(w) -417.081329 p(y|xw) -491.133514 min 0.578580 mean 0.609077 max 0.745476\n",
            "6599 loss q(w) -205.913712 p(w) -416.939667 p(y|xw) -496.114899 min 0.812741 mean 0.961051 max 1.704267\n",
            "iter: 6599 loss: 699.579834 \n",
            "6699 loss q(w) -206.240723 p(w) -416.697815 p(y|xw) -493.123291 min 0.704627 mean 1.046315 max 2.117132\n",
            "6699 loss q(w) -206.240723 p(w) -417.395386 p(y|xw) -488.779968 min 0.713493 mean 1.586571 max 4.418992\n",
            "6699 loss q(w) -206.240723 p(w) -417.242706 p(y|xw) -468.243835 min 0.885964 mean 1.048812 max 1.481292\n",
            "6699 loss q(w) -206.240723 p(w) -416.805542 p(y|xw) -470.188507 min 0.633862 mean 0.916295 max 1.214083\n",
            "6699 loss q(w) -206.240723 p(w) -417.021027 p(y|xw) -490.501740 min 0.682026 mean 1.385774 max 2.953356\n",
            "6699 loss q(w) -206.240723 p(w) -416.735840 p(y|xw) -459.919678 min 0.651575 mean 0.916879 max 1.329160\n",
            "6699 loss q(w) -206.240723 p(w) -416.718567 p(y|xw) -476.653259 min 0.626100 mean 0.933080 max 1.363500\n",
            "6699 loss q(w) -206.240723 p(w) -417.018677 p(y|xw) -469.223389 min 0.648067 mean 1.120894 max 2.520449\n",
            "6699 loss q(w) -206.240723 p(w) -416.939453 p(y|xw) -503.494965 min 0.585555 mean 1.340800 max 3.490551\n",
            "6699 loss q(w) -206.240723 p(w) -416.762390 p(y|xw) -448.446503 min 0.907018 mean 1.341517 max 1.877695\n",
            "iter: 6699 loss: 687.550537 \n",
            "6799 loss q(w) -206.748734 p(w) -417.111755 p(y|xw) -440.172424 min 0.635709 mean 1.198145 max 2.191493\n",
            "6799 loss q(w) -206.748734 p(w) -416.854401 p(y|xw) -443.016144 min 0.628208 mean 0.878591 max 1.386945\n",
            "6799 loss q(w) -206.748734 p(w) -417.489136 p(y|xw) -508.302734 min -0.392557 mean 0.784642 max 2.095351\n",
            "6799 loss q(w) -206.748734 p(w) -416.953003 p(y|xw) -477.590637 min 0.666563 mean 0.948186 max 1.674827\n",
            "6799 loss q(w) -206.748734 p(w) -417.018616 p(y|xw) -447.459717 min 0.867860 mean 1.299134 max 2.141391\n",
            "6799 loss q(w) -206.748734 p(w) -417.027466 p(y|xw) -580.905029 min 0.836044 mean 1.726345 max 6.001688\n",
            "6799 loss q(w) -206.748734 p(w) -417.322418 p(y|xw) -486.651489 min 0.699648 mean 1.098303 max 1.333709\n",
            "6799 loss q(w) -206.748734 p(w) -416.712433 p(y|xw) -427.730225 min 0.599361 mean 1.012749 max 1.752033\n",
            "6799 loss q(w) -206.748734 p(w) -417.274902 p(y|xw) -453.219238 min 0.805673 mean 1.095500 max 2.422082\n",
            "6799 loss q(w) -206.748734 p(w) -416.996429 p(y|xw) -519.016113 min 0.826078 mean 1.075713 max 3.231968\n",
            "iter: 6799 loss: 688.733765 \n",
            "6899 loss q(w) -207.371048 p(w) -417.109863 p(y|xw) -511.390045 min 0.857649 mean 1.312418 max 3.290298\n",
            "6899 loss q(w) -207.371048 p(w) -417.182404 p(y|xw) -494.766632 min 0.573511 mean 0.644566 max 0.761014\n",
            "6899 loss q(w) -207.371048 p(w) -416.947144 p(y|xw) -473.618134 min 0.972656 mean 1.343814 max 2.454420\n",
            "6899 loss q(w) -207.371048 p(w) -417.203033 p(y|xw) -441.733795 min 0.599024 mean 0.904710 max 1.931381\n",
            "6899 loss q(w) -207.371048 p(w) -417.106873 p(y|xw) -495.784576 min 1.210796 mean 2.084955 max 3.719542\n",
            "6899 loss q(w) -207.371048 p(w) -417.031097 p(y|xw) -515.723450 min 0.761607 mean 1.233336 max 2.611615\n",
            "6899 loss q(w) -207.371048 p(w) -417.022949 p(y|xw) -418.953522 min 0.826996 mean 1.386744 max 3.504705\n",
            "6899 loss q(w) -207.371048 p(w) -417.270020 p(y|xw) -460.580780 min 0.758217 mean 1.229157 max 2.187508\n",
            "6899 loss q(w) -207.371048 p(w) -417.414093 p(y|xw) -471.374146 min 0.678589 mean 0.917287 max 1.373631\n",
            "6899 loss q(w) -207.371048 p(w) -416.917664 p(y|xw) -476.051178 min 0.921751 mean 1.171634 max 1.940197\n",
            "iter: 6899 loss: 685.747070 \n",
            "6999 loss q(w) -207.693344 p(w) -417.352783 p(y|xw) -456.443573 min 0.866481 mean 1.277874 max 2.063354\n",
            "6999 loss q(w) -207.693344 p(w) -417.005615 p(y|xw) -493.408112 min 0.955933 mean 1.221956 max 1.952239\n",
            "6999 loss q(w) -207.693344 p(w) -417.104919 p(y|xw) -493.366455 min 0.780504 mean 1.062745 max 1.444675\n",
            "6999 loss q(w) -207.693344 p(w) -417.029053 p(y|xw) -457.935394 min 0.928591 mean 1.415061 max 2.171266\n",
            "6999 loss q(w) -207.693344 p(w) -416.947388 p(y|xw) -499.216888 min 0.558235 mean 0.877517 max 2.392695\n",
            "6999 loss q(w) -207.693344 p(w) -417.181702 p(y|xw) -449.676666 min 0.837573 mean 1.181357 max 1.891544\n",
            "6999 loss q(w) -207.693344 p(w) -417.174835 p(y|xw) -487.522400 min 0.517151 mean 0.786563 max 1.106585\n",
            "6999 loss q(w) -207.693344 p(w) -417.097595 p(y|xw) -466.969299 min 0.803567 mean 1.398958 max 3.098828\n",
            "6999 loss q(w) -207.693344 p(w) -417.092834 p(y|xw) -460.735809 min 0.592746 mean 1.556822 max 3.759476\n",
            "6999 loss q(w) -207.693344 p(w) -416.636810 p(y|xw) -468.596802 min 0.638368 mean 0.829110 max 1.019527\n",
            "iter: 6999 loss: 682.756165 \n",
            "7099 loss q(w) -207.691513 p(w) -416.630676 p(y|xw) -443.987549 min 0.715707 mean 1.035772 max 2.009554\n",
            "7099 loss q(w) -207.691513 p(w) -417.064056 p(y|xw) -476.972626 min 0.958152 mean 1.093533 max 1.253280\n",
            "7099 loss q(w) -207.691513 p(w) -416.892059 p(y|xw) -484.047607 min 1.235044 mean 1.408091 max 1.768085\n",
            "7099 loss q(w) -207.691513 p(w) -417.167419 p(y|xw) -440.769989 min 0.479383 mean 1.184591 max 2.743642\n",
            "7099 loss q(w) -207.691513 p(w) -417.066528 p(y|xw) -473.047272 min 0.620677 mean 0.950134 max 1.645036\n",
            "7099 loss q(w) -207.691513 p(w) -417.215149 p(y|xw) -443.268982 min 0.613595 mean 0.906129 max 1.853551\n",
            "7099 loss q(w) -207.691513 p(w) -417.068176 p(y|xw) -474.018646 min 0.758780 mean 1.152836 max 1.986989\n",
            "7099 loss q(w) -207.691513 p(w) -416.896301 p(y|xw) -533.703613 min 1.122265 mean 1.514765 max 2.501476\n",
            "7099 loss q(w) -207.691513 p(w) -416.533417 p(y|xw) -469.018127 min 0.669606 mean 0.804332 max 1.317604\n",
            "7099 loss q(w) -207.691513 p(w) -417.144348 p(y|xw) -497.792023 min 0.902389 mean 1.088789 max 1.336578\n",
            "iter: 7099 loss: 682.938965 \n",
            "7199 loss q(w) -207.654358 p(w) -417.285461 p(y|xw) -501.497009 min 0.682286 mean 0.867947 max 0.993005\n",
            "7199 loss q(w) -207.654358 p(w) -416.966217 p(y|xw) -442.244049 min 0.763563 mean 1.257712 max 2.409693\n",
            "7199 loss q(w) -207.654358 p(w) -417.738281 p(y|xw) -440.136719 min 0.649105 mean 1.270063 max 2.284346\n",
            "7199 loss q(w) -207.654358 p(w) -416.923523 p(y|xw) -491.137207 min 0.712654 mean 1.473154 max 2.957661\n",
            "7199 loss q(w) -207.654358 p(w) -417.062805 p(y|xw) -455.736176 min 0.528113 mean 0.783109 max 1.497652\n",
            "7199 loss q(w) -207.654358 p(w) -416.805481 p(y|xw) -468.411469 min 0.917311 mean 1.268005 max 1.797954\n",
            "7199 loss q(w) -207.654358 p(w) -417.032074 p(y|xw) -495.170135 min 1.176000 mean 1.538327 max 2.089787\n",
            "7199 loss q(w) -207.654358 p(w) -416.999695 p(y|xw) -479.019714 min 0.881607 mean 1.324186 max 2.623256\n",
            "7199 loss q(w) -207.654358 p(w) -417.153625 p(y|xw) -450.062561 min 0.797225 mean 1.093913 max 1.623668\n",
            "7199 loss q(w) -207.654358 p(w) -417.056854 p(y|xw) -477.342285 min 0.645850 mean 0.932287 max 1.150897\n",
            "iter: 7199 loss: 679.523804 \n",
            "7299 loss q(w) -208.364426 p(w) -417.390991 p(y|xw) -490.409515 min 0.728492 mean 1.285475 max 2.299572\n",
            "7299 loss q(w) -208.364426 p(w) -417.189087 p(y|xw) -500.613190 min 0.767719 mean 1.126507 max 1.964001\n",
            "7299 loss q(w) -208.364426 p(w) -416.791412 p(y|xw) -462.473450 min 0.654400 mean 0.947654 max 1.415566\n",
            "7299 loss q(w) -208.364426 p(w) -416.958130 p(y|xw) -460.348907 min 0.826006 mean 1.106217 max 1.726238\n",
            "7299 loss q(w) -208.364426 p(w) -417.315521 p(y|xw) -484.364471 min 0.762593 mean 0.883464 max 0.994408\n",
            "7299 loss q(w) -208.364426 p(w) -417.171570 p(y|xw) -485.377228 min 0.555665 mean 0.872243 max 2.069937\n",
            "7299 loss q(w) -208.364426 p(w) -417.019592 p(y|xw) -477.924530 min 0.818842 mean 1.007885 max 1.453267\n",
            "7299 loss q(w) -208.364426 p(w) -416.948120 p(y|xw) -451.779022 min 0.933605 mean 1.182156 max 1.729214\n",
            "7299 loss q(w) -208.364426 p(w) -416.968781 p(y|xw) -490.887543 min 0.669778 mean 0.708211 max 0.852055\n",
            "7299 loss q(w) -208.364426 p(w) -417.308105 p(y|xw) -514.365784 min 0.665811 mean 0.998896 max 1.777811\n",
            "iter: 7299 loss: 690.596069 \n",
            "7399 loss q(w) -209.022232 p(w) -417.323547 p(y|xw) -523.596069 min 0.645763 mean 1.118714 max 3.343504\n",
            "7399 loss q(w) -209.022232 p(w) -417.013855 p(y|xw) -469.525299 min 0.822947 mean 0.951459 max 1.332631\n",
            "7399 loss q(w) -209.022232 p(w) -416.869812 p(y|xw) -485.706604 min 0.666296 mean 0.886430 max 1.081383\n",
            "7399 loss q(w) -209.022232 p(w) -416.976837 p(y|xw) -450.324036 min 0.978537 mean 1.306013 max 2.062929\n",
            "7399 loss q(w) -209.022232 p(w) -417.133087 p(y|xw) -478.897827 min 0.475915 mean 1.315752 max 2.949710\n",
            "7399 loss q(w) -209.022232 p(w) -417.054260 p(y|xw) -473.084869 min 0.640821 mean 0.992478 max 1.935510\n",
            "7399 loss q(w) -209.022232 p(w) -416.855225 p(y|xw) -456.818817 min 0.859626 mean 1.156855 max 1.807979\n",
            "7399 loss q(w) -209.022232 p(w) -417.128174 p(y|xw) -767.952271 min 0.634533 mean 1.606652 max 3.971040\n",
            "7399 loss q(w) -209.022232 p(w) -416.840393 p(y|xw) -462.386139 min 0.585986 mean 0.854278 max 1.352914\n",
            "7399 loss q(w) -209.022232 p(w) -416.939728 p(y|xw) -495.432709 min -0.465584 mean 0.630716 max 1.022845\n",
            "iter: 7399 loss: 714.363770 \n",
            "7499 loss q(w) -209.057678 p(w) -416.955902 p(y|xw) -481.134399 min 0.732408 mean 0.920184 max 1.456790\n",
            "7499 loss q(w) -209.057678 p(w) -416.941864 p(y|xw) -505.395569 min 0.554951 mean 1.043079 max 2.925113\n",
            "7499 loss q(w) -209.057678 p(w) -417.073608 p(y|xw) -537.293030 min 0.329890 mean 0.799958 max 1.498694\n",
            "7499 loss q(w) -209.057678 p(w) -417.265564 p(y|xw) -519.848022 min 0.127729 mean 0.537277 max 0.722442\n",
            "7499 loss q(w) -209.057678 p(w) -416.941162 p(y|xw) -469.750641 min 0.748705 mean 1.415998 max 2.392719\n",
            "7499 loss q(w) -209.057678 p(w) -417.141693 p(y|xw) -472.150421 min 0.711404 mean 0.814627 max 1.011674\n",
            "7499 loss q(w) -209.057678 p(w) -417.173523 p(y|xw) -472.156860 min 0.557096 mean 0.677402 max 0.911181\n",
            "7499 loss q(w) -209.057678 p(w) -416.918396 p(y|xw) -436.928619 min 0.812210 mean 1.545351 max 2.568827\n",
            "7499 loss q(w) -209.057678 p(w) -417.348267 p(y|xw) -449.037903 min 0.695921 mean 1.275239 max 2.783305\n",
            "7499 loss q(w) -209.057678 p(w) -417.064575 p(y|xw) -446.101227 min 0.676862 mean 1.026464 max 1.917160\n",
            "iter: 7499 loss: 687.004456 \n",
            "7599 loss q(w) -209.833084 p(w) -417.174988 p(y|xw) -485.519897 min 0.552162 mean 0.940213 max 1.121665\n",
            "7599 loss q(w) -209.833084 p(w) -417.134552 p(y|xw) -462.173462 min 0.759496 mean 1.162427 max 3.162650\n",
            "7599 loss q(w) -209.833084 p(w) -417.241150 p(y|xw) -455.469360 min 0.736627 mean 0.971680 max 1.520325\n",
            "7599 loss q(w) -209.833084 p(w) -417.136993 p(y|xw) -444.858093 min 0.693072 mean 1.238473 max 2.031260\n",
            "7599 loss q(w) -209.833084 p(w) -417.439514 p(y|xw) -442.672333 min 0.596545 mean 0.863089 max 1.467937\n",
            "7599 loss q(w) -209.833084 p(w) -416.968262 p(y|xw) -471.776520 min 0.583041 mean 0.787018 max 1.091403\n",
            "7599 loss q(w) -209.833084 p(w) -416.982666 p(y|xw) -475.982910 min 0.943362 mean 1.107822 max 1.251078\n",
            "7599 loss q(w) -209.833084 p(w) -417.116058 p(y|xw) -473.468781 min 0.668868 mean 1.016586 max 1.876836\n",
            "7599 loss q(w) -209.833084 p(w) -417.147736 p(y|xw) -482.012329 min 0.878102 mean 0.923963 max 1.050559\n",
            "7599 loss q(w) -209.833084 p(w) -417.355652 p(y|xw) -544.867798 min 0.600826 mean 1.352575 max 3.423070\n",
            "iter: 7599 loss: 681.216797 \n",
            "7699 loss q(w) -210.284576 p(w) -417.058807 p(y|xw) -477.272797 min 0.746993 mean 0.860709 max 0.975904\n",
            "7699 loss q(w) -210.284576 p(w) -417.022614 p(y|xw) -452.848969 min 0.653095 mean 0.944657 max 1.803208\n",
            "7699 loss q(w) -210.284576 p(w) -416.876526 p(y|xw) -487.950897 min 1.155291 mean 1.407437 max 2.063378\n",
            "7699 loss q(w) -210.284576 p(w) -417.125488 p(y|xw) -465.315033 min 0.884566 mean 0.994262 max 1.464282\n",
            "7699 loss q(w) -210.284576 p(w) -417.197937 p(y|xw) -466.700989 min 0.756904 mean 0.998212 max 1.497449\n",
            "7699 loss q(w) -210.284576 p(w) -417.047577 p(y|xw) -472.475677 min 0.590383 mean 0.699669 max 1.105040\n",
            "7699 loss q(w) -210.284576 p(w) -416.621155 p(y|xw) -482.119659 min 1.133723 mean 1.492029 max 2.506733\n",
            "7699 loss q(w) -210.284576 p(w) -417.326904 p(y|xw) -410.847626 min 0.718071 mean 1.416806 max 3.854277\n",
            "7699 loss q(w) -210.284576 p(w) -417.231018 p(y|xw) -452.756470 min 0.712877 mean 1.209626 max 1.622916\n",
            "7699 loss q(w) -210.284576 p(w) -417.242676 p(y|xw) -491.090210 min 0.792405 mean 1.256272 max 3.142774\n",
            "iter: 7699 loss: 672.728271 \n",
            "7799 loss q(w) -210.089706 p(w) -416.913086 p(y|xw) -495.405975 min 0.859159 mean 1.345076 max 1.914383\n",
            "7799 loss q(w) -210.089706 p(w) -417.492493 p(y|xw) -517.920837 min 0.849066 mean 2.105782 max 4.946956\n",
            "7799 loss q(w) -210.089706 p(w) -417.139954 p(y|xw) -481.289520 min 0.533131 mean 0.689453 max 1.110244\n",
            "7799 loss q(w) -210.089706 p(w) -417.211548 p(y|xw) -452.667145 min 0.592605 mean 0.863742 max 1.526965\n",
            "7799 loss q(w) -210.089706 p(w) -417.339050 p(y|xw) -473.720215 min 0.684918 mean 0.757107 max 1.008195\n",
            "7799 loss q(w) -210.089706 p(w) -417.038544 p(y|xw) -507.975006 min 0.651747 mean 0.750865 max 1.095330\n",
            "7799 loss q(w) -210.089706 p(w) -417.433533 p(y|xw) -467.344666 min 0.857836 mean 1.109340 max 1.618350\n",
            "7799 loss q(w) -210.089706 p(w) -417.305969 p(y|xw) -477.608276 min 0.795971 mean 1.072274 max 1.613951\n",
            "7799 loss q(w) -210.089706 p(w) -417.082916 p(y|xw) -512.429993 min 1.019460 mean 1.524014 max 2.072117\n",
            "7799 loss q(w) -210.089706 p(w) -416.997559 p(y|xw) -456.157318 min 0.752032 mean 1.027611 max 1.433053\n",
            "iter: 7799 loss: 691.357666 \n",
            "7899 loss q(w) -210.453796 p(w) -417.388275 p(y|xw) -509.602295 min 0.777865 mean 1.394416 max 2.737061\n",
            "7899 loss q(w) -210.453796 p(w) -417.031708 p(y|xw) -488.567749 min 0.709942 mean 0.808188 max 1.112665\n",
            "7899 loss q(w) -210.453796 p(w) -417.454803 p(y|xw) -489.259735 min 0.698944 mean 0.807303 max 1.085849\n",
            "7899 loss q(w) -210.453796 p(w) -417.338074 p(y|xw) -482.184021 min 0.801281 mean 0.868867 max 0.950107\n",
            "7899 loss q(w) -210.453796 p(w) -417.186523 p(y|xw) -482.591705 min 0.737143 mean 1.159168 max 2.049875\n",
            "7899 loss q(w) -210.453796 p(w) -417.277924 p(y|xw) -488.898071 min 0.603565 mean 0.762623 max 1.011134\n",
            "7899 loss q(w) -210.453796 p(w) -417.246033 p(y|xw) -490.881836 min 0.623841 mean 0.854833 max 1.973624\n",
            "7899 loss q(w) -210.453796 p(w) -416.956482 p(y|xw) -476.957428 min 0.547588 mean 1.281911 max 2.379622\n",
            "7899 loss q(w) -210.453796 p(w) -417.828583 p(y|xw) -440.064026 min 0.761938 mean 1.553352 max 3.121631\n",
            "7899 loss q(w) -210.453796 p(w) -417.185730 p(y|xw) -453.933868 min 0.672328 mean 1.065019 max 1.399529\n",
            "iter: 7899 loss: 687.129700 \n",
            "7999 loss q(w) -211.202057 p(w) -417.185211 p(y|xw) -460.017456 min 0.577881 mean 0.860854 max 1.428071\n",
            "7999 loss q(w) -211.202057 p(w) -416.968628 p(y|xw) -461.134094 min 0.755566 mean 0.995486 max 2.365525\n",
            "7999 loss q(w) -211.202057 p(w) -417.258789 p(y|xw) -477.447723 min 0.771607 mean 0.939540 max 1.207657\n",
            "7999 loss q(w) -211.202057 p(w) -417.191345 p(y|xw) -510.321899 min 1.059440 mean 1.550403 max 2.635192\n",
            "7999 loss q(w) -211.202057 p(w) -417.265594 p(y|xw) -454.707458 min 0.465252 mean 1.079440 max 2.776070\n",
            "7999 loss q(w) -211.202057 p(w) -417.165039 p(y|xw) -509.526642 min 1.167561 mean 1.535592 max 3.012634\n",
            "7999 loss q(w) -211.202057 p(w) -417.191162 p(y|xw) -457.055481 min 0.788066 mean 1.099536 max 2.239765\n",
            "7999 loss q(w) -211.202057 p(w) -417.246948 p(y|xw) -439.714081 min 0.570332 mean 0.989952 max 1.996884\n",
            "7999 loss q(w) -211.202057 p(w) -416.742798 p(y|xw) -503.175171 min 0.886891 mean 1.214961 max 1.581048\n",
            "7999 loss q(w) -211.202057 p(w) -417.046509 p(y|xw) -514.377625 min 0.689695 mean 1.055133 max 1.670627\n",
            "iter: 7999 loss: 684.671875 \n",
            "8099 loss q(w) -211.259064 p(w) -416.974579 p(y|xw) -444.898102 min 0.723232 mean 1.035007 max 1.780262\n",
            "8099 loss q(w) -211.259064 p(w) -417.186798 p(y|xw) -534.105042 min 0.703868 mean 1.386320 max 2.487673\n",
            "8099 loss q(w) -211.259064 p(w) -417.237793 p(y|xw) -481.428986 min 0.332104 mean 0.627244 max 1.402208\n",
            "8099 loss q(w) -211.259064 p(w) -417.157166 p(y|xw) -453.613342 min 0.864809 mean 1.209512 max 1.891665\n",
            "8099 loss q(w) -211.259064 p(w) -417.073303 p(y|xw) -484.937469 min 0.712837 mean 0.883135 max 1.614350\n",
            "8099 loss q(w) -211.259064 p(w) -417.079010 p(y|xw) -431.193665 min 0.390161 mean 0.857664 max 1.746736\n",
            "8099 loss q(w) -211.259064 p(w) -416.887115 p(y|xw) -475.438263 min 0.759736 mean 1.185724 max 2.574392\n",
            "8099 loss q(w) -211.259064 p(w) -417.601318 p(y|xw) -438.379761 min 0.540005 mean 1.087770 max 2.119433\n",
            "8099 loss q(w) -211.259064 p(w) -417.367432 p(y|xw) -523.824890 min 0.767668 mean 1.279195 max 2.346467\n",
            "8099 loss q(w) -211.259064 p(w) -416.978088 p(y|xw) -517.942810 min 0.416223 mean 0.876594 max 3.121808\n",
            "iter: 8099 loss: 684.471497 \n",
            "8199 loss q(w) -211.986694 p(w) -417.095947 p(y|xw) -446.337585 min 0.537258 mean 1.176711 max 4.256149\n",
            "8199 loss q(w) -211.986694 p(w) -417.391541 p(y|xw) -528.638550 min 0.564917 mean 1.093045 max 1.854253\n",
            "8199 loss q(w) -211.986694 p(w) -417.134064 p(y|xw) -469.513855 min 0.812456 mean 1.199730 max 2.326828\n",
            "8199 loss q(w) -211.986694 p(w) -417.345947 p(y|xw) -454.082001 min 0.827842 mean 1.259779 max 2.222906\n",
            "8199 loss q(w) -211.986694 p(w) -417.209534 p(y|xw) -479.204834 min 0.754578 mean 1.049612 max 1.263591\n",
            "8199 loss q(w) -211.986694 p(w) -417.223755 p(y|xw) -517.865601 min 0.734692 mean 1.099170 max 1.777170\n",
            "8199 loss q(w) -211.986694 p(w) -417.636017 p(y|xw) -418.076691 min 0.774855 mean 1.821768 max 3.105738\n",
            "8199 loss q(w) -211.986694 p(w) -417.073883 p(y|xw) -473.661499 min 0.767575 mean 0.898743 max 1.089317\n",
            "8199 loss q(w) -211.986694 p(w) -417.229004 p(y|xw) -471.876587 min 0.784740 mean 1.030218 max 1.661056\n",
            "8199 loss q(w) -211.986694 p(w) -417.052521 p(y|xw) -468.349762 min 0.721598 mean 1.151839 max 2.118783\n",
            "iter: 8199 loss: 678.013245 \n",
            "8299 loss q(w) -212.632889 p(w) -417.391724 p(y|xw) -467.736328 min 0.686792 mean 1.213184 max 2.524103\n",
            "8299 loss q(w) -212.632889 p(w) -417.147064 p(y|xw) -471.214264 min 0.538435 mean 1.086704 max 2.290307\n",
            "8299 loss q(w) -212.632889 p(w) -416.859283 p(y|xw) -511.855957 min 0.294840 mean 0.514743 max 0.676729\n",
            "8299 loss q(w) -212.632889 p(w) -417.303436 p(y|xw) -483.393524 min 0.600041 mean 1.027741 max 2.271425\n",
            "8299 loss q(w) -212.632889 p(w) -417.222504 p(y|xw) -448.596466 min 0.748345 mean 1.231220 max 1.952006\n",
            "8299 loss q(w) -212.632889 p(w) -416.857910 p(y|xw) -464.742126 min 0.499720 mean 0.780319 max 1.027510\n",
            "8299 loss q(w) -212.632889 p(w) -417.071655 p(y|xw) -489.710571 min 0.813552 mean 1.147613 max 2.692207\n",
            "8299 loss q(w) -212.632889 p(w) -417.122192 p(y|xw) -458.231750 min 0.750345 mean 1.079975 max 1.655720\n",
            "8299 loss q(w) -212.632889 p(w) -416.829895 p(y|xw) -471.785767 min 0.437277 mean 0.708644 max 1.347453\n",
            "8299 loss q(w) -212.632889 p(w) -417.154297 p(y|xw) -435.702148 min 0.517930 mean 1.174580 max 2.442744\n",
            "iter: 8299 loss: 674.759949 \n",
            "8399 loss q(w) -212.811234 p(w) -417.233948 p(y|xw) -494.795837 min 0.591555 mean 1.148301 max 2.407287\n",
            "8399 loss q(w) -212.811234 p(w) -417.129883 p(y|xw) -457.238647 min 0.502200 mean 0.815196 max 1.540828\n",
            "8399 loss q(w) -212.811234 p(w) -417.206665 p(y|xw) -517.439026 min 0.807067 mean 1.123157 max 1.658252\n",
            "8399 loss q(w) -212.811234 p(w) -417.159821 p(y|xw) -480.547119 min 0.702242 mean 1.121175 max 1.576024\n",
            "8399 loss q(w) -212.811234 p(w) -417.184692 p(y|xw) -467.491943 min 0.728854 mean 1.049044 max 1.832145\n",
            "8399 loss q(w) -212.811234 p(w) -417.067200 p(y|xw) -469.591125 min 0.679235 mean 0.874032 max 1.308395\n",
            "8399 loss q(w) -212.811234 p(w) -416.915894 p(y|xw) -469.184570 min 0.845892 mean 1.089224 max 1.729473\n",
            "8399 loss q(w) -212.811234 p(w) -417.229187 p(y|xw) -466.028229 min 0.637463 mean 0.825663 max 1.232062\n",
            "8399 loss q(w) -212.811234 p(w) -417.157959 p(y|xw) -503.636353 min 0.550095 mean 0.845186 max 1.470702\n",
            "8399 loss q(w) -212.811234 p(w) -417.050598 p(y|xw) -533.319336 min 0.689960 mean 1.337489 max 3.139215\n",
            "iter: 8399 loss: 690.249512 \n",
            "8499 loss q(w) -213.184448 p(w) -416.888306 p(y|xw) -518.491516 min 0.583318 mean 0.972876 max 2.114556\n",
            "8499 loss q(w) -213.184448 p(w) -416.863770 p(y|xw) -451.295990 min 0.870795 mean 1.428310 max 2.050577\n",
            "8499 loss q(w) -213.184448 p(w) -417.006378 p(y|xw) -478.339325 min 0.665830 mean 0.814525 max 1.038075\n",
            "8499 loss q(w) -213.184448 p(w) -417.246704 p(y|xw) -442.160400 min 0.770866 mean 1.181006 max 2.398831\n",
            "8499 loss q(w) -213.184448 p(w) -417.174377 p(y|xw) -460.327728 min 0.398483 mean 0.663025 max 1.157512\n",
            "8499 loss q(w) -213.184448 p(w) -417.284058 p(y|xw) -434.801544 min 0.618509 mean 1.220228 max 2.511437\n",
            "8499 loss q(w) -213.184448 p(w) -417.488922 p(y|xw) -515.962158 min 0.661499 mean 1.201467 max 2.228926\n",
            "8499 loss q(w) -213.184448 p(w) -417.165131 p(y|xw) -471.534607 min 0.658931 mean 0.832222 max 1.012059\n",
            "8499 loss q(w) -213.184448 p(w) -417.267578 p(y|xw) -455.479492 min 0.683065 mean 1.379472 max 2.278279\n",
            "8499 loss q(w) -213.184448 p(w) -417.210083 p(y|xw) -492.697479 min 0.602223 mean 1.054779 max 2.558084\n",
            "iter: 8499 loss: 676.084045 \n",
            "8599 loss q(w) -214.012955 p(w) -417.446167 p(y|xw) -476.999451 min 0.705352 mean 0.858477 max 1.040660\n",
            "8599 loss q(w) -214.012955 p(w) -416.896667 p(y|xw) -417.984314 min 0.536625 mean 1.059966 max 3.310267\n",
            "8599 loss q(w) -214.012955 p(w) -417.206268 p(y|xw) -486.670898 min 0.846074 mean 1.044840 max 1.378538\n",
            "8599 loss q(w) -214.012955 p(w) -416.899567 p(y|xw) -506.239960 min 0.887393 mean 1.464822 max 2.605469\n",
            "8599 loss q(w) -214.012955 p(w) -417.669769 p(y|xw) -505.090179 min 0.752958 mean 1.180580 max 3.236449\n",
            "8599 loss q(w) -214.012955 p(w) -417.212769 p(y|xw) -475.923004 min 0.734710 mean 0.953072 max 1.228679\n",
            "8599 loss q(w) -214.012955 p(w) -417.576843 p(y|xw) -609.557556 min 0.358728 mean 1.208266 max 2.686205\n",
            "8599 loss q(w) -214.012955 p(w) -416.996857 p(y|xw) -473.795563 min 0.762822 mean 1.200267 max 3.161956\n",
            "8599 loss q(w) -214.012955 p(w) -417.292175 p(y|xw) -467.190338 min 0.501439 mean 0.757859 max 1.123934\n",
            "8599 loss q(w) -214.012955 p(w) -417.187469 p(y|xw) -496.328400 min 0.506901 mean 0.556170 max 0.627650\n",
            "iter: 8599 loss: 694.803406 \n",
            "8699 loss q(w) -214.053818 p(w) -417.271240 p(y|xw) -444.485291 min 0.788932 mean 1.181019 max 3.093282\n",
            "8699 loss q(w) -214.053818 p(w) -417.466736 p(y|xw) -422.868744 min 0.690489 mean 1.298803 max 2.492744\n",
            "8699 loss q(w) -214.053818 p(w) -417.426270 p(y|xw) -430.884369 min 0.570342 mean 1.218638 max 2.887706\n",
            "8699 loss q(w) -214.053818 p(w) -417.079285 p(y|xw) -493.155853 min 0.448298 mean 0.792513 max 1.203372\n",
            "8699 loss q(w) -214.053818 p(w) -416.972076 p(y|xw) -434.770050 min 0.978641 mean 1.422170 max 2.496851\n",
            "8699 loss q(w) -214.053818 p(w) -417.201324 p(y|xw) -478.032227 min 0.487027 mean 0.687190 max 1.670992\n",
            "8699 loss q(w) -214.053818 p(w) -417.530762 p(y|xw) -566.884949 min 0.596332 mean 0.959628 max 1.836074\n",
            "8699 loss q(w) -214.053818 p(w) -416.824463 p(y|xw) -468.915436 min 0.525156 mean 0.816428 max 1.216722\n",
            "8699 loss q(w) -214.053818 p(w) -417.446869 p(y|xw) -424.807343 min 0.580179 mean 1.201187 max 2.829386\n",
            "8699 loss q(w) -214.053818 p(w) -417.046509 p(y|xw) -676.350159 min 0.959488 mean 2.064914 max 4.057650\n",
            "iter: 8699 loss: 687.288147 \n",
            "8799 loss q(w) -214.111313 p(w) -417.258240 p(y|xw) -460.801453 min 0.043801 mean 0.660989 max 1.865240\n",
            "8799 loss q(w) -214.111313 p(w) -417.202179 p(y|xw) -460.459991 min 0.567183 mean 1.018085 max 2.010994\n",
            "8799 loss q(w) -214.111313 p(w) -417.423096 p(y|xw) -466.063141 min 0.629320 mean 1.006536 max 1.917923\n",
            "8799 loss q(w) -214.111313 p(w) -417.014587 p(y|xw) -482.804260 min 0.752961 mean 1.071704 max 1.959373\n",
            "8799 loss q(w) -214.111313 p(w) -417.354431 p(y|xw) -484.343445 min 0.813004 mean 1.041999 max 1.358769\n",
            "8799 loss q(w) -214.111313 p(w) -416.973907 p(y|xw) -435.192200 min 0.829915 mean 1.425913 max 4.067845\n",
            "8799 loss q(w) -214.111313 p(w) -417.107300 p(y|xw) -495.172028 min 0.614600 mean 0.952076 max 1.282228\n",
            "8799 loss q(w) -214.111313 p(w) -417.389282 p(y|xw) -426.031891 min 0.662225 mean 1.253570 max 2.629228\n",
            "8799 loss q(w) -214.111313 p(w) -417.135071 p(y|xw) -487.459503 min 0.651959 mean 0.971611 max 2.076879\n",
            "8799 loss q(w) -214.111313 p(w) -416.974304 p(y|xw) -486.866394 min 0.710982 mean 0.812947 max 1.031994\n",
            "iter: 8799 loss: 671.591431 \n",
            "8899 loss q(w) -213.960281 p(w) -416.958252 p(y|xw) -488.651947 min 0.661969 mean 0.908059 max 1.366131\n",
            "8899 loss q(w) -213.960281 p(w) -417.088806 p(y|xw) -454.714935 min 0.950398 mean 1.378549 max 2.025137\n",
            "8899 loss q(w) -213.960281 p(w) -417.130829 p(y|xw) -549.935242 min 0.498636 mean 1.226949 max 4.417970\n",
            "8899 loss q(w) -213.960281 p(w) -417.355621 p(y|xw) -493.399567 min 0.904312 mean 1.551644 max 2.231175\n",
            "8899 loss q(w) -213.960281 p(w) -417.434387 p(y|xw) -438.617645 min 1.017008 mean 1.515291 max 2.119242\n",
            "8899 loss q(w) -213.960281 p(w) -417.484558 p(y|xw) -434.630829 min 0.817115 mean 1.431834 max 3.201944\n",
            "8899 loss q(w) -213.960281 p(w) -417.160248 p(y|xw) -466.770905 min 0.527769 mean 0.935942 max 1.847494\n",
            "8899 loss q(w) -213.960281 p(w) -417.361847 p(y|xw) -461.644989 min 0.671974 mean 1.099774 max 1.631745\n",
            "8899 loss q(w) -213.960281 p(w) -417.081757 p(y|xw) -443.110748 min 0.684831 mean 1.149234 max 2.018810\n",
            "8899 loss q(w) -213.960281 p(w) -417.502380 p(y|xw) -423.465515 min 0.594769 mean 1.318188 max 3.127856\n",
            "iter: 8899 loss: 668.789795 \n",
            "8999 loss q(w) -214.602615 p(w) -417.007141 p(y|xw) -465.902222 min 0.766937 mean 1.099434 max 2.525595\n",
            "8999 loss q(w) -214.602615 p(w) -417.423584 p(y|xw) -521.881714 min 0.756527 mean 1.207299 max 2.532065\n",
            "8999 loss q(w) -214.602615 p(w) -417.236908 p(y|xw) -425.870667 min 0.708666 mean 1.245974 max 2.304248\n",
            "8999 loss q(w) -214.602615 p(w) -416.855682 p(y|xw) -434.943512 min 0.708026 mean 1.205392 max 2.143344\n",
            "8999 loss q(w) -214.602615 p(w) -417.007111 p(y|xw) -497.961609 min 0.730553 mean 1.162765 max 2.083448\n",
            "8999 loss q(w) -214.602615 p(w) -416.938843 p(y|xw) -524.838623 min 0.679248 mean 1.213017 max 2.894625\n",
            "8999 loss q(w) -214.602615 p(w) -417.278595 p(y|xw) -474.690765 min 0.773753 mean 1.235444 max 2.440215\n",
            "8999 loss q(w) -214.602615 p(w) -417.081818 p(y|xw) -516.506592 min 0.660392 mean 0.916336 max 1.304099\n",
            "8999 loss q(w) -214.602615 p(w) -416.879211 p(y|xw) -482.294098 min 0.953002 mean 1.568415 max 1.861549\n",
            "8999 loss q(w) -214.602615 p(w) -417.934296 p(y|xw) -419.671906 min 0.673800 mean 1.329313 max 2.063390\n",
            "iter: 8999 loss: 679.017883 \n",
            "9099 loss q(w) -215.153595 p(w) -417.202148 p(y|xw) -429.947418 min 0.595255 mean 1.321025 max 2.190013\n",
            "9099 loss q(w) -215.153595 p(w) -417.209106 p(y|xw) -500.628723 min 0.653708 mean 1.468667 max 3.997455\n",
            "9099 loss q(w) -215.153595 p(w) -417.331146 p(y|xw) -487.672668 min 0.600024 mean 1.122427 max 2.335911\n",
            "9099 loss q(w) -215.153595 p(w) -417.140442 p(y|xw) -476.137024 min 0.576061 mean 0.951024 max 1.832544\n",
            "9099 loss q(w) -215.153595 p(w) -416.956909 p(y|xw) -454.318756 min 0.559909 mean 0.844999 max 1.699269\n",
            "9099 loss q(w) -215.153595 p(w) -417.751251 p(y|xw) -445.968292 min 0.621294 mean 1.048800 max 2.725664\n",
            "9099 loss q(w) -215.153595 p(w) -417.233887 p(y|xw) -392.607697 min 0.589486 mean 1.328928 max 2.396303\n",
            "9099 loss q(w) -215.153595 p(w) -417.094208 p(y|xw) -467.766998 min 0.719876 mean 0.867594 max 1.271193\n",
            "9099 loss q(w) -215.153595 p(w) -417.406952 p(y|xw) -454.613220 min 0.614874 mean 1.222426 max 2.513605\n",
            "9099 loss q(w) -215.153595 p(w) -417.381836 p(y|xw) -438.669189 min 0.594755 mean 0.940579 max 2.128095\n",
            "iter: 9099 loss: 656.950195 \n",
            "9199 loss q(w) -214.684540 p(w) -417.099121 p(y|xw) -481.889313 min 0.526780 mean 0.668581 max 0.799159\n",
            "9199 loss q(w) -214.684540 p(w) -417.068939 p(y|xw) -494.918457 min 0.822654 mean 0.988774 max 1.717525\n",
            "9199 loss q(w) -214.684540 p(w) -417.327545 p(y|xw) -453.640045 min 0.952554 mean 1.412708 max 2.073715\n",
            "9199 loss q(w) -214.684540 p(w) -417.005737 p(y|xw) -488.033844 min 0.729311 mean 0.789969 max 0.865818\n",
            "9199 loss q(w) -214.684540 p(w) -417.200531 p(y|xw) -476.964050 min 0.926509 mean 1.116901 max 1.790837\n",
            "9199 loss q(w) -214.684540 p(w) -416.808899 p(y|xw) -449.381470 min 0.750389 mean 1.097885 max 1.761581\n",
            "9199 loss q(w) -214.684540 p(w) -417.071350 p(y|xw) -480.446533 min 0.846010 mean 1.025923 max 1.544908\n",
            "9199 loss q(w) -214.684540 p(w) -417.402863 p(y|xw) -436.246918 min 0.515443 mean 1.132436 max 1.462887\n",
            "9199 loss q(w) -214.684540 p(w) -417.417114 p(y|xw) -464.141907 min 0.836494 mean 1.274511 max 1.868801\n",
            "9199 loss q(w) -214.684540 p(w) -417.023682 p(y|xw) -484.743225 min 0.668816 mean 1.091619 max 3.154631\n",
            "iter: 9199 loss: 673.498657 \n",
            "9299 loss q(w) -215.573792 p(w) -417.406128 p(y|xw) -453.365723 min 0.512851 mean 0.820313 max 1.906004\n",
            "9299 loss q(w) -215.573792 p(w) -417.645294 p(y|xw) -570.861206 min 0.638052 mean 1.502861 max 4.112952\n",
            "9299 loss q(w) -215.573792 p(w) -417.280273 p(y|xw) -518.512085 min 0.759699 mean 1.090550 max 3.423987\n",
            "9299 loss q(w) -215.573792 p(w) -417.449005 p(y|xw) -494.563477 min 0.750456 mean 1.166055 max 2.856255\n",
            "9299 loss q(w) -215.573792 p(w) -417.311035 p(y|xw) -479.415283 min 0.380436 mean 0.620819 max 1.208034\n",
            "9299 loss q(w) -215.573792 p(w) -417.017914 p(y|xw) -487.740387 min 0.472209 mean 1.014068 max 1.691741\n",
            "9299 loss q(w) -215.573792 p(w) -417.641602 p(y|xw) -459.112305 min 0.859142 mean 1.136787 max 1.634401\n",
            "9299 loss q(w) -215.573792 p(w) -417.500824 p(y|xw) -476.671661 min 0.556803 mean 0.800131 max 1.564699\n",
            "9299 loss q(w) -215.573792 p(w) -417.216125 p(y|xw) -531.554932 min 0.614542 mean 1.434555 max 5.017160\n",
            "9299 loss q(w) -215.573792 p(w) -417.175171 p(y|xw) -490.009003 min 0.449994 mean 0.742409 max 1.378275\n",
            "iter: 9299 loss: 697.971130 \n",
            "9399 loss q(w) -215.990845 p(w) -417.443268 p(y|xw) -448.146942 min 0.767109 mean 1.049348 max 2.586664\n",
            "9399 loss q(w) -215.990845 p(w) -417.333801 p(y|xw) -465.856079 min 0.786032 mean 0.915443 max 1.078690\n",
            "9399 loss q(w) -215.990845 p(w) -417.410217 p(y|xw) -485.812897 min 0.654614 mean 1.143754 max 1.896627\n",
            "9399 loss q(w) -215.990845 p(w) -417.345337 p(y|xw) -509.023956 min 0.742334 mean 1.351823 max 3.461865\n",
            "9399 loss q(w) -215.990845 p(w) -417.460938 p(y|xw) -444.827850 min 0.819386 mean 1.574532 max 2.536059\n",
            "9399 loss q(w) -215.990845 p(w) -417.026215 p(y|xw) -459.141876 min 0.528397 mean 0.829900 max 1.603928\n",
            "9399 loss q(w) -215.990845 p(w) -417.529785 p(y|xw) -574.472168 min 0.790447 mean 1.473113 max 2.986076\n",
            "9399 loss q(w) -215.990845 p(w) -417.119873 p(y|xw) -486.782471 min 0.647876 mean 0.749064 max 1.147790\n",
            "9399 loss q(w) -215.990845 p(w) -417.732880 p(y|xw) -478.707336 min 0.550454 mean 0.807638 max 1.458053\n",
            "9399 loss q(w) -215.990845 p(w) -417.239624 p(y|xw) -425.992249 min 0.890405 mean 1.491167 max 2.545382\n",
            "iter: 9399 loss: 679.249756 \n",
            "9499 loss q(w) -216.697617 p(w) -416.991089 p(y|xw) -478.331696 min 0.764973 mean 0.953516 max 1.578847\n",
            "9499 loss q(w) -216.697617 p(w) -417.521362 p(y|xw) -487.415192 min 0.583482 mean 0.931559 max 1.846476\n",
            "9499 loss q(w) -216.697617 p(w) -417.576080 p(y|xw) -406.171814 min 0.583423 mean 1.599485 max 4.108423\n",
            "9499 loss q(w) -216.697617 p(w) -417.020996 p(y|xw) -476.441467 min 0.677266 mean 0.842405 max 1.189442\n",
            "9499 loss q(w) -216.697617 p(w) -417.427338 p(y|xw) -467.004272 min 0.738897 mean 1.135868 max 1.898557\n",
            "9499 loss q(w) -216.697617 p(w) -417.373291 p(y|xw) -477.382935 min 0.522828 mean 0.665685 max 0.832772\n",
            "9499 loss q(w) -216.697617 p(w) -417.260345 p(y|xw) -558.267639 min 0.694840 mean 1.005270 max 4.448120\n",
            "9499 loss q(w) -216.697617 p(w) -417.074524 p(y|xw) -501.485413 min 0.772658 mean 0.859506 max 1.226886\n",
            "9499 loss q(w) -216.697617 p(w) -416.988708 p(y|xw) -460.789337 min 0.506680 mean 0.951991 max 2.056290\n",
            "9499 loss q(w) -216.697617 p(w) -417.689667 p(y|xw) -431.944641 min 0.649635 mean 1.130495 max 1.963670\n",
            "iter: 9499 loss: 675.118164 \n",
            "9599 loss q(w) -216.859634 p(w) -417.439880 p(y|xw) -479.818176 min 0.417202 mean 0.833050 max 1.897398\n",
            "9599 loss q(w) -216.859634 p(w) -416.982544 p(y|xw) -487.722443 min 0.527162 mean 0.708690 max 1.027655\n",
            "9599 loss q(w) -216.859634 p(w) -417.054749 p(y|xw) -484.231720 min 0.625753 mean 0.775311 max 1.137684\n",
            "9599 loss q(w) -216.859634 p(w) -417.482819 p(y|xw) -484.156708 min 0.678732 mean 0.843809 max 1.224244\n",
            "9599 loss q(w) -216.859634 p(w) -416.870758 p(y|xw) -491.166565 min 0.598109 mean 0.784186 max 1.230642\n",
            "9599 loss q(w) -216.859634 p(w) -417.278168 p(y|xw) -482.583466 min 0.796603 mean 1.501047 max 2.150895\n",
            "9599 loss q(w) -216.859634 p(w) -417.405273 p(y|xw) -457.068085 min 0.706052 mean 0.946498 max 1.676911\n",
            "9599 loss q(w) -216.859634 p(w) -417.298218 p(y|xw) -466.547821 min 0.706732 mean 0.952893 max 1.352040\n",
            "9599 loss q(w) -216.859634 p(w) -417.268250 p(y|xw) -480.711945 min 0.712109 mean 0.953565 max 1.585546\n",
            "9599 loss q(w) -216.859634 p(w) -417.693573 p(y|xw) -503.081116 min 0.578615 mean 0.853340 max 2.520468\n",
            "iter: 9599 loss: 682.126587 \n",
            "9699 loss q(w) -216.932266 p(w) -417.269379 p(y|xw) -486.224030 min 0.745370 mean 0.843380 max 1.239891\n",
            "9699 loss q(w) -216.932266 p(w) -417.307617 p(y|xw) -468.954010 min 0.503364 mean 0.926283 max 3.137312\n",
            "9699 loss q(w) -216.932266 p(w) -417.159698 p(y|xw) -475.236176 min 0.638070 mean 0.790001 max 1.571019\n",
            "9699 loss q(w) -216.932266 p(w) -417.352264 p(y|xw) -460.810181 min 0.720160 mean 0.976998 max 1.481460\n",
            "9699 loss q(w) -216.932266 p(w) -416.966248 p(y|xw) -490.680237 min 0.780180 mean 0.980964 max 1.497683\n",
            "9699 loss q(w) -216.932266 p(w) -417.508636 p(y|xw) -480.086792 min 0.663501 mean 1.391053 max 2.586859\n",
            "9699 loss q(w) -216.932266 p(w) -417.130005 p(y|xw) -480.761322 min 0.749586 mean 0.970549 max 1.729883\n",
            "9699 loss q(w) -216.932266 p(w) -417.374878 p(y|xw) -487.975403 min 0.751544 mean 0.948392 max 1.740067\n",
            "9699 loss q(w) -216.932266 p(w) -417.561035 p(y|xw) -496.762543 min 0.588574 mean 0.962154 max 1.360049\n",
            "9699 loss q(w) -216.932266 p(w) -417.421448 p(y|xw) -491.271606 min 0.447029 mean 0.793210 max 2.252822\n",
            "iter: 9699 loss: 682.249084 \n",
            "9799 loss q(w) -217.269028 p(w) -417.323669 p(y|xw) -501.425476 min 0.681495 mean 0.886962 max 1.191971\n",
            "9799 loss q(w) -217.269028 p(w) -417.205200 p(y|xw) -452.747253 min 0.570900 mean 0.930542 max 2.542141\n",
            "9799 loss q(w) -217.269028 p(w) -417.356567 p(y|xw) -452.353241 min 0.566430 mean 0.808623 max 1.773878\n",
            "9799 loss q(w) -217.269028 p(w) -417.266479 p(y|xw) -638.491272 min 0.669521 mean 1.336391 max 3.208186\n",
            "9799 loss q(w) -217.269028 p(w) -417.223877 p(y|xw) -428.218781 min 0.549478 mean 1.144206 max 3.075565\n",
            "9799 loss q(w) -217.269028 p(w) -417.079559 p(y|xw) -488.323486 min 0.439331 mean 0.913754 max 1.977045\n",
            "9799 loss q(w) -217.269028 p(w) -417.383362 p(y|xw) -483.839264 min 0.591415 mean 0.871270 max 1.746928\n",
            "9799 loss q(w) -217.269028 p(w) -417.747925 p(y|xw) -488.280090 min 0.722115 mean 0.725411 max 0.746939\n",
            "9799 loss q(w) -217.269028 p(w) -417.043213 p(y|xw) -515.424255 min 0.511185 mean 0.971837 max 1.366511\n",
            "9799 loss q(w) -217.269028 p(w) -417.210236 p(y|xw) -482.090637 min 0.451327 mean 0.870850 max 2.482196\n",
            "iter: 9799 loss: 693.134338 \n",
            "9899 loss q(w) -217.634644 p(w) -417.552216 p(y|xw) -455.500488 min 0.407934 mean 1.012443 max 2.300368\n",
            "9899 loss q(w) -217.634644 p(w) -417.112213 p(y|xw) -476.302338 min 0.744767 mean 1.254883 max 2.185231\n",
            "9899 loss q(w) -217.634644 p(w) -416.879852 p(y|xw) -560.941711 min 0.694955 mean 1.317949 max 2.077714\n",
            "9899 loss q(w) -217.634644 p(w) -417.413666 p(y|xw) -465.641327 min 0.701078 mean 1.098390 max 2.235080\n",
            "9899 loss q(w) -217.634644 p(w) -417.086273 p(y|xw) -492.424927 min 0.594699 mean 1.117439 max 2.607347\n",
            "9899 loss q(w) -217.634644 p(w) -417.505524 p(y|xw) -443.602264 min 0.752618 mean 1.283649 max 2.929607\n",
            "9899 loss q(w) -217.634644 p(w) -417.771454 p(y|xw) -484.881866 min 0.560499 mean 0.868350 max 1.538960\n",
            "9899 loss q(w) -217.634644 p(w) -417.721222 p(y|xw) -480.342560 min 0.591983 mean 1.219064 max 2.685925\n",
            "9899 loss q(w) -217.634644 p(w) -417.227081 p(y|xw) -462.472717 min 0.544684 mean 0.864004 max 1.465460\n",
            "9899 loss q(w) -217.634644 p(w) -417.352478 p(y|xw) -440.134583 min 0.564489 mean 1.009111 max 1.674944\n",
            "iter: 9899 loss: 675.952087 \n",
            "9999 loss q(w) -218.208176 p(w) -417.434631 p(y|xw) -451.714600 min 0.530650 mean 0.797371 max 1.552057\n",
            "9999 loss q(w) -218.208176 p(w) -417.357300 p(y|xw) -490.528717 min 0.580701 mean 0.774983 max 0.925317\n",
            "9999 loss q(w) -218.208176 p(w) -417.576294 p(y|xw) -456.428711 min 0.556386 mean 1.008484 max 2.158417\n",
            "9999 loss q(w) -218.208176 p(w) -417.199005 p(y|xw) -457.759308 min 0.511591 mean 1.584511 max 5.414493\n",
            "9999 loss q(w) -218.208176 p(w) -417.177979 p(y|xw) -425.454468 min 0.767327 mean 1.413276 max 3.086779\n",
            "9999 loss q(w) -218.208176 p(w) -417.341064 p(y|xw) -471.492645 min 0.906484 mean 1.262638 max 2.195846\n",
            "9999 loss q(w) -218.208176 p(w) -417.251221 p(y|xw) -503.664795 min 0.590088 mean 0.905733 max 2.650242\n",
            "9999 loss q(w) -218.208176 p(w) -417.377167 p(y|xw) -524.597839 min 0.554783 mean 1.253133 max 3.179958\n",
            "9999 loss q(w) -218.208176 p(w) -417.603577 p(y|xw) -519.392273 min 0.796039 mean 1.308262 max 1.792216\n",
            "9999 loss q(w) -218.208176 p(w) -417.663757 p(y|xw) -439.648987 min 0.622519 mean 1.255501 max 2.295572\n",
            "iter: 9999 loss: 673.258301 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRu7Nbrn2gFl",
        "colab_type": "code",
        "outputId": "3abcf68e-fad9-4435-88f7-bc68543af506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "for n, p in vimodel.named_parameters():\n",
        "    print(n, p)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mu Parameter containing:\n",
            "tensor([-2.1741e+00, -1.7299e+00,  6.3600e-01,  3.7746e+00,  1.7561e+00,\n",
            "        -6.1776e-01,  1.1017e+00,  1.5583e+00, -8.0886e-05,  9.1630e-05,\n",
            "        -5.7420e-05, -7.9344e-06, -4.4439e-05,  3.7608e-05, -5.0530e-05,\n",
            "        -3.3642e-05,  5.5129e-02, -2.1228e-02, -3.6699e-02, -2.7252e-02,\n",
            "        -3.3028e-02, -5.8130e-02, -1.8172e-02, -9.8003e-03,  2.2906e-02,\n",
            "         3.6961e-02, -4.0465e-02,  3.9633e-02, -2.8441e-02,  7.9354e-03,\n",
            "        -4.1824e-02,  1.0194e-02, -3.4751e-03, -6.4742e-02,  8.7381e-02,\n",
            "        -3.9801e-02,  2.0867e-02,  5.9676e-03,  3.1620e-03,  3.3781e-02,\n",
            "         4.2896e-02, -3.4522e-02, -3.6323e-03, -2.4273e-02, -6.2451e-02,\n",
            "        -2.9428e-02, -1.0666e-02, -1.1324e-02, -1.7919e-02,  4.0886e-02,\n",
            "         3.0650e-02,  1.8477e-02,  1.8708e-02, -5.1553e-02, -4.2382e-02,\n",
            "         3.8981e-02,  3.3446e-02,  3.0206e-03,  5.5313e-02,  1.1010e-02,\n",
            "         2.5643e-02,  4.4561e-03, -1.9356e-02,  4.0031e-02,  7.2665e-02,\n",
            "         6.7236e-03,  7.4508e-03,  4.3699e-02,  1.4978e-02,  4.1375e-02,\n",
            "         2.1830e-02, -1.8702e-02,  5.4679e-02,  1.5408e-02, -4.8515e-02,\n",
            "         1.4326e-02, -4.6787e-03,  2.4486e-02, -1.2447e-04,  2.1599e-02,\n",
            "         1.0161e-04, -3.8774e-05, -3.4226e-05, -8.0720e-05,  6.9143e-05,\n",
            "         3.4533e-05,  1.3251e-05, -3.3629e-05,  1.6398e-01,  1.7551e-01,\n",
            "         1.8598e-01,  1.7925e-01,  1.8791e-01,  1.7750e-01,  1.9580e-01,\n",
            "         2.1428e-01,  5.7989e-01,  1.0914e-01,  2.7682e-01, -3.4098e-01,\n",
            "        -4.6866e-01, -4.8856e-01,  1.6714e-01, -1.9407e-01, -3.6968e-01,\n",
            "         4.4659e-01,  5.9473e-01,  5.1279e-01,  3.7210e-01,  3.9204e-01,\n",
            "         2.9436e-01,  3.9000e-01,  4.2732e-01, -9.3688e-02,  6.7323e-02,\n",
            "         2.6360e-02, -4.7779e-03,  3.6166e-02,  7.6862e-02,  4.4362e-02,\n",
            "        -6.7031e-02, -5.8666e-01, -6.5583e-01, -6.6268e-01, -6.3809e-01,\n",
            "        -6.7166e-01, -6.0342e-01, -6.3388e-01, -6.3535e-01],\n",
            "       requires_grad=True)\n",
            "sigma Parameter containing:\n",
            "tensor([[ 1.5294e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-2.4234e-07,  1.1065e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-1.8457e-05, -2.4349e-05,  1.8824e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [-1.9549e-02, -6.9992e-03, -1.0912e-03,  ...,  6.2026e-01,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-1.4401e-02, -4.6896e-03, -2.1019e-03,  ...,  1.0000e-08,\n",
            "          6.3212e-01,  0.0000e+00],\n",
            "        [-4.2384e-03, -1.8270e-02, -1.6072e-03,  ...,  1.0000e-08,\n",
            "          1.0000e-08,  6.4692e-01]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9mOfcn24Kdg",
        "colab_type": "text"
      },
      "source": [
        "## prediction\n",
        "\n",
        "Calculate prediction distribution\n",
        "$$\n",
        "\\begin{align}\n",
        "p(y_*| x_*, X, Y) &= \\int p(y_*| x_*, W) p(W| X, Y) dW \\\\\n",
        "&\\approx \\int p(y_*| x_*, W) q(W; \\eta) dW \n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skswvUkj4Kdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(q_w, loc_dict, model, x, n_samples):    \n",
        "    \n",
        "    approx_y = 0  \n",
        "    model.eval()  \n",
        "    with torch.no_grad():\n",
        "        for i in range(n_samples):\n",
        "            # sampling from q(w)\n",
        "            w_sample = q_w.sample()\n",
        "\n",
        "            param_dict = transform_param(w_sample, loc_dict)\n",
        "            model.set_params(param_dict)\n",
        "            # calculate f(x)\n",
        "            out1, out2 = model(x)\n",
        "\n",
        "            # p(y|x,w) = N(f(x; w), 1)\n",
        "            p_y_xw = torchdist.Normal(out1, torch.ones_like(out1))\n",
        "            # p_y_xw = torchdist.Normal(out1, out2)\n",
        "\n",
        "            # sampling from p(y, w)\n",
        "            y_sample = p_y_xw.sample()\n",
        "\n",
        "            approx_y += y_sample / n_samples\n",
        "    \n",
        "    return approx_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-T_EbsM4Kdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_data(q_w, loc_dict, model):\n",
        "    n_samples = 1000\n",
        "    x_pred = 5 * torch.rand(100, 1)\n",
        "    x_pred = torch.tensor(scaler.transform(x_pred), dtype=torch.float32)\n",
        "    y_pred = predict(q_w, loc_dict, model, x_pred, n_samples)\n",
        "    \n",
        "    return x_pred, y_pred\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF8MgxlM4Kdl",
        "colab_type": "code",
        "outputId": "52b9a538-2474-40eb-d9d0-a2da32065e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "x_pred, y_pred = predict_data(q_w, vimodel.loc_dict, model)\n",
        "y_pred_train = predict(q_w, vimodel.loc_dict, model, x_train_norm, 1000)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "print(len(axes))\n",
        "axes[0].plot(x_train_norm.numpy(), y_train.numpy(), 'o')\n",
        "axes[1].plot(x_train_norm.numpy(), y_pred_train.numpy(), 'o')\n",
        "axes[2].plot(x_pred.numpy(), y_pred.numpy(), 'o')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb2963fe400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04oj1yPC4Kdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPwyJ8S-4Kd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}