{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "py36",
      "language": "python",
      "name": "py36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "probability_programing_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FHS5gW_4KcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.distributions as torchdist\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHXusc_94Kce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normal_dist = torchdist.Normal(loc=torch.tensor(0.), scale=torch.tensor(1.))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arqd0dwN4Kcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = normal_dist.sample()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRUN8aC74Kcn",
        "colab_type": "code",
        "outputId": "f079ef65-ec07-49d9-9b11-4c740787a899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9751)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHfTqG-_4Kcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = normal_dist.sample([100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUcBotC74Kcw",
        "colab_type": "code",
        "outputId": "c4606ceb-564f-4090-baa5-09c6bf043b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2297, -1.4699, -0.9743,  1.4647,  1.2115, -1.1523, -1.0646, -0.2574,\n",
              "        -0.1789, -1.0827, -0.4084,  0.2708,  0.8100, -0.3153, -0.3835,  0.9930,\n",
              "        -0.1224,  1.7591, -0.7908,  1.1788, -0.9725,  1.3558,  1.2006,  0.2354,\n",
              "         1.3564, -0.5836, -0.7023, -2.4646, -0.1629,  1.3149, -1.2432,  0.2330,\n",
              "         0.5294, -0.5055,  1.3809,  0.1236, -0.2933, -0.1012,  0.5671, -1.0663,\n",
              "        -0.5349,  0.5125, -0.2929,  0.0641,  0.1939,  0.9018, -2.3981,  0.6396,\n",
              "         0.8196,  1.1254,  1.3049,  1.6517,  0.6842, -0.9109, -0.5889, -1.3594,\n",
              "         1.1598, -0.4645, -0.3729,  0.4805, -1.0582, -1.5714, -0.7112,  1.5706,\n",
              "         0.6616, -1.0496,  0.0435,  0.9069, -1.0480, -0.0199, -0.8753,  2.0985,\n",
              "        -2.7476,  0.0074,  0.6425, -0.8499,  0.8746,  1.2590,  0.1568,  0.7747,\n",
              "        -0.0616, -0.0844, -0.5466, -0.2322,  1.0783, -1.2464,  0.9450,  0.1424,\n",
              "         2.4970,  0.5442, -0.0945,  0.6857,  1.3560, -0.7441,  1.5916,  2.0834,\n",
              "        -0.6256,  1.7943,  2.6379, -0.7257])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vqfszqY4Kc0",
        "colab_type": "code",
        "outputId": "ad149a51-2b79-48ba-be8f-d3a4cdb5bb98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "plt.hist(x.detach().numpy())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 3.,  0.,  6., 17., 22., 12., 17., 14.,  7.,  2.]),\n",
              " array([-2.7476368 , -2.2090864 , -1.6705363 , -1.1319859 , -0.59343565,\n",
              "        -0.05488539,  0.4836649 ,  1.0222151 ,  1.5607655 ,  2.0993156 ,\n",
              "         2.637866  ], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T29uQgj4Kc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toy_poly():\n",
        "    x = 5 * torch.rand(100, 1)\n",
        "    linear_op = -3 - 4*x + x**2\n",
        "    y = torchdist.Normal(linear_op, 1).sample()\n",
        "    return x, y\n",
        "\n",
        "x_train, y_train = toy_poly()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uBU48pX4Kc9",
        "colab_type": "code",
        "outputId": "e3ac50d7-0868-48ef-c96b-90ac580e8342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(x_train.numpy(), y_train.numpy(), 'o')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fabf813bdd8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAY90lEQVR4nO3df4xldXnH8c+zy7UM/mBooEUG6GKq24hURqbEZPsjrpRFMTAB22qradOmm5jaKLVjltIYSGzYuEZr0ibNRv3DSArq4hSL7QrZbRtIUWaYXXGBtcYfyMWGITooZZDZ3ad/zNzd2TvnnHvOPT+/575fCWHn3pl7v/fOned8z/N9vs8xdxcAIFyb6h4AACAfAjkABI5ADgCBI5ADQOAI5AAQuDPqeNJzzz3Xt2zZUsdTA0Cw5ufnn3X38/pvryWQb9myRXNzc3U8NQAEy8x+EHU7qRUACByBHAACRyAHgMARyAEgcARyAAhcLVUrANAGswtd7dl/VE8vLeuC8THN7Niq6cmJysdBIAeAIcwudHXz3Y9qeeW4JKm7tKyb735UkioP5qRWAGAIe/YfPRnEe5ZXjmvP/qOVj4VADgBDeHppOdPtZSKQA8AQLhgfy3R7mQjkADCEmR1bNdbZfNptY53NmtmxtfKxsNgJAEPoLWhStQIAAZuenKglcPcjtQIAgSOQA0DgCOQAEDgCOQAEjkAOAIEjkANA4Cg/BICc6u6CSCAHgBya0AWR1AoA5NCELogEcgDIoQldEAnkAJBDE7og5g7kZnaRmR00s8fM7IiZfaCIgQFACJrQBbGIxc5jkj7k7o+Y2SslzZvZfe7+WAGPDQCN1oQuiLkDubv/SNKP1v79MzN7XNKEJAI5gJFQdxfEQssPzWyLpElJX4+4b6eknZJ08cUXF/m0ANBIVdWXFxbIzewVkvZJ+qC7/7T/fnffK2mvJE1NTXlRzwsAdYsK2JIqqy8vJJCbWUerQfwOd7+7iMcEgBDEbQg6s7Mptr68cYHczEzSZyQ97u6fyD8kAAhH3Iag/tt6yqgvL6KOfJuk90rabmaH1v57ewGPCwCNlzUwl1FfXkTVygOSrICxAEBwLhgfUzcimI+PdfTzYydOm5mXVV/Ozk4AyCFuQ9Ct112q22+4TBPjYzJJ55zV0S+csUk33XVI23Yf0OxCt7Ax0P0QAHIYtCFoenKi9A6JBHIAyGnQhqCkDolFBHJSKwBQsrI7JBLIAaBkZXdIJJADQMnK7pBIjhwASlZ2h0QCOQBUoMwOiaRWACBwBHIACByBHAACRyAHgMARyAEgcARyAAgcgRwAAkcgB4DAEcgBIHDs7ASAjGYXuqVttx8GgRwAMsh6kYgqgj6pFQDIIOkiEf16Qb+7tCzXqaBf5GXeJAI5AGSS5SIRWYJ+HgRyAMggy0Uiyr4yUA+BHAAizC50tW33AV2y697Trnqf5SIRZV8ZqIdADgB9knLb05MTuv2GyzQxPiaTNDE+pttvuCxyAbPsKwP1ULUCAH0GXfU+7UUiyr4yUE8hgdzMrpH0KUmbJX3a3XcX8bgAUIe4HHZ3iNx2mVcG6smdWjGzzZL+UdLbJL1e0rvN7PV5HxcA6hKXwzap8NLBIhSRI79S0nfc/bvu/pKkOyVdX8DjAkAtZnZslUXc7lLhpYNFKCKQT0j64bqvn1q77TRmttPM5sxsbnFxsYCnBYByTE9OyGPuK7p0sAiVVa24+153n3L3qfPOO6+qpwWAoUxUVDpYhCICeVfSReu+vnDtNgBovCLqxetWRNXKw5Jea2aXaDWAv0vSHxbwuABQqjQNsJrU5TBO7kDu7sfM7P2S9mu1/PCz7n4k98gAoGRF1YvXrZA6cnf/qqSvFvFYAFCVpHrxbbsPNH4m3sMWfQAjK6levOzWs0UikAMYWVELmiZtKD0so/VskQjkAEZWVAOskOrHe2iaBWCk9S9obtt9ILKnShPrx3uYkQPAOiHVj/cwIweAdUKqH+8hkANAn1Dqx3tIrQBA4AjkABA4AjkABI5ADgCBI5ADQOCoWgHQOrML3aDKB/MikANolTQ9xtuGQA6gVZJ6jPfub9tMnUAOoFWSeoy3dabOYieAVolrbrXZLHGmHjICOYBWiWt6ddyjG9Q2uT1tWgRyAK0S1WO893WUJrenTYscOYDWiWt6tT5HLjW/PW1aBHIAIyHE9rRpEcgBjIzQ2tOmRY4cAAJHIAeAwBHIASBwuQK5me0xsyfM7Jtm9mUzGy9qYACAdPLOyO+T9AZ3/3VJ35Z0c/4hAQjd7EJX23Yf0CW77tW23Qc0u9Cte0itlqtqxd2/tu7LhyS9M99wAISu7u6Do9bCVio2R/6nkv4t7k4z22lmc2Y2t7i4WODTAmiSQd0Hy9Q7iHSXluU6dRBp+xnBwBm5md0v6fyIu25x939Z+55bJB2TdEfc47j7Xkl7JWlqaiq66QGAYMTNfON6l1TR0yTpINLmWfnAQO7uVyXdb2Z/Iukdkt7qHtOVBkCrJKVPLhgfUzciaFfR06TOg0id8latXCPpw5Kuc/cXihkSgKZLmvnGdR+soqdJ3MGiDY2xkuTNkf+DpFdKus/MDpnZPxUwJgANlzTzjes+WEVqo86DSJ3yVq38alEDyWIUV6WBJhmUPqmyp0l/PLjxigkdfGJxpOJDUE2zZhe6uvWeI1paXjl5W5su1wSEYmbH1ka0hI3K1e+b71Z2BtAUwWzR7/3C1gfxnrZcrgkIRZ3pk/XqLHVskmBm5FG/sPXavioNNE0TWsKOapVKv2Bm5IN+MW1flQaw0ahWqfQLZkYet7gijcaqNBCCpEKEMooUmpKrr1swgTzqF9ZzZieYEwugtZI2CUkqpf9Kmy/floXVsRlzamrK5+bmMv9c74jeXVqWSVo/8rHO5pFbqQaaZNvuA5Fnzb2r18fd9+Cu7aWPrS3MbN7dp/pvD2oqOz05oQd3bdfE+Jj6Dz+juFINNEnSwiOLkuUKJrWyHh8KoDzD5rIHbRIqqv8KGwI3CmpG3lPESjWN74GN8rSBTdoeX9TW+VFtUztIkIE874eCDwMQLc8Gm/5NQuNjHZ3Z2aSb7jqkPfuP6sYrJnJvIGIDULQgUyt5V6pHtWcxMEjetGVvk1BZW+dJq0YLMpBL+XaV8WEAohXVS/y2rxwpZbJUZ6/zJgsytZIXu8GAaEXksmcXuvrJCxt7IknpJktJ61ej2qZ2kJEM5HwYgGhFNMNKylcPmiwNWr9qSrOupgk2tZIHu8GAeHmbYSXNugdNltKsXzWhWVfTjGQgl/gwAGWJy2OPj3UG/s2xfjWckUytAEhnmP0WcanLW6+7dODPsn41HAI5gEjD7rfIk8dm/Wo4I5ta6Zld6Oq2rxw5uco+PtbRrdddStoFIy/PfothU5esXw1npAP57EJXM186rJXjp1pwLS2vaOaLhyVxDVCMtrry1axfZdf6QJ7UYGfP/qOnBfGelRPOLk+MnP6/lbPHOpHXyCVf3TytDuRJje6nJycSZxaskmOU/O3so7rjoSdPtofuLi2rs9nU2WRaOXFqskO+upmCCeTDtK4clONLunxc1KyD9ploo9mF7mlBvGfluOucszo662Vn8JlvuCAC+aCZdZxBOb6ZHVs35MglqbPJNsw6hh0D0HR79h/dEMR7ll5Y0cJHrs70eEx4qldI+aGZfcjM3MzOLeLx+g3bunJQTer05IT2vPONOueszsn7xsc62vN7b9zwwaN9JtoqKY2YNR9Oi+h65J6Rm9lFkq6W9GT+4UQbdvU8zRW2066Qs+MMbRWXYjQN3lLfjxbR9ShiRv5JSR+WYs/Ocht2t1fUxoQbr5jQnv1HM18ZiB1nCFGanZlRm3BM0h+9+eLMwZcJTz1yBXIzu15S190Pp/jenWY2Z2Zzi4uLmZ4nz26v3gWbv7f7Ws3s2Kp9893CL2MFNFHaNEfUhOeTf3C5Pjp9WebnZMJTD3NPnkib2f2Szo+46xZJfyPpand/zsy+L2nK3Z8d9KRTU1M+NzeXaaBFLKBs230gtkplIsVj9sbQXVrWZjMdd0/1c0AZBv1NxH3eJ8bH9OCu7aWNKSqdSavZYpjZvLtP9d8+MEfu7lfFPOBlki6RdNjMJOlCSY+Y2ZXu/r85x7tBEbu9kk7v0lSh9G6negV1S1NFVUeagy329Rh6sdPdH5X0S72vs8zI65JUNy6lW5RhMQdNkOZzWNVl0aLODMqa8SPaSHU/jMpz9xs0W2ExB02Q5nNYxboO5YbNUFggd/ctTZ6NS6cv6sQZNFthMQdNkOZzWMVl0bLsrximtznSCWJnZ5F6ufa4RZlBs5U0telA2dJ+DsvuJJj2DJWd0eUaqdTKesPOVrj4K5qgKZ/DtGeo7Iwu18DywzIMU34IoHnSlhtesuveyB2DJul7u68tf6AtMXT5IYDT0RTqlLTlhlVV0IwqAjmQQYi53rIPPGny8KwtlYvUCpBBHbsl84hKfZhWGyNVvSuZM5n8SK0ABQhtH0HUIuP6qwBVeTbBtTjLM7JVK8Aw4nK6Z491Im+v26ADDJUj7UAgBzKY2bFVnU224fb/e+lYIze4pFlMTHs2wYae5iK1AmQwPTmh275yRD954fSry68c90r67azPM5891pHZ6uXY4nLOUYuM/dIE+xAXeUcJgbwGLPqEbakviPeUnSfvD6ZLy6fGERdY15cHdpeWTy509qStHKFZXLMRyCvGzCZ8ddVERwXT9eIC6/pFxmEnEaEt8o4aAnnFmNmEr66a6DRBc9D3DFs5woaeZmOxs2LMbMJXV5+TNEGzrMDKpQ6bjRl5xZjZtEMdNdGDFi7LDKxc+afZCOQVY6syhtUfTNNUrRT9/ATuZiKQVyxuZiOtbv9mtnNKmdU9oVYOEUwRhUBeg/4/RipZNirzPeH9Rtuw2NkANN3fqMz3JJT3m52USIsZeQNQybJRme9JCO83Zw3IgkC+Tpq8aRm5VSpZNirzPQnh/c6y3yDUfD+KQ2plTW8G1F1aluvUDGj96Wya7xkGNbobDfOepE1F1PF+Z02TZL2ocdGfSYSFQL4mTd60rNxqUy6k2yRZ35MsAa3q93uYYBt3drDJ7LSfCyXfj3KRWlmTZgZUZm6VsrKNsrwnWVsfJD120amKYdoyxG3+Oe5+Wq48hHw/yseMfE3cDGj97Wm+B/kNU61RVEArI1UxzNh6Zw2bbWPv8/Uzbj6TkAoI5Gb2l2b2hJkdMbOPFTGoOqTJm5LLLt+wgbSogFZGqmLYsU1PTuhEzDV1ewcBPpOQcgZyM3uLpOslvdHdL5X08UJGVYM0edOm5LLbXF88bCAtKqCVkarIM7ZBB4GmfCZRr7w58vdJ2u3uP5ckd38m/5DqkyYnW3cuu+31xcMG0qKaOpVRmphnbGl689T9mUT98gby10n6LTP7O0kvSvprd3846hvNbKeknZJ08cUX53za0RVaP/OsC4d5AmkRAS1vU7O41zvs2Og6iDQGBnIzu1/S+RF33bL2878o6c2SfkPSF8zsNe4bE3vuvlfSXkmampqKTvxhoLiZaVTwq9swZw9VdodMOsgMEzjLOltixo1BBgZyd78q7j4ze5+ku9cC9zfM7ISkcyUtFjfEZppd6J52Ed7xsY5uve7STH9ww5S5xc1Ybe3xmvQHP8zZQ1Uz0LigO/eDH+vgE4tDPXdoZ0toj7yplVlJb5F00MxeJ+llkp7NPaqGm13oauZLh7Vy/NSJxdLyima+eFhSutlXVCCZ+dJh3XrPET23nHxV9JvuOqT+UxqXagkYSQejPPnusl9HXND9/ENPnvw664yamm7UJW/54WclvcbMviXpTkl/HJVWaZs9+4+eFsR7Vk546jK1qECycty1tLySWHY3PTmxIYj3VB0wBpUKNrnGOe17laX0sMmvF+2WK5C7+0vu/h53f4O7v8ndDxQ1sCZLCgJpA0Sa74sLIhNDBIwyShYHlQo2ucY5S3BN+ztt8utFu7GzcwhJQSBtgEj7fVFBJGvAyLrJJm3QH5RKaHKNc5bgmvZ31eTXi3aj18oQZnZs3ZAjl6TOJksdIAZdSLcnKohkXRDM2hI17SJgmlLBplZcTE9O6KYvHNKgRGDWGXVTXy/ajUA+hN4fap6qlf5gPH5WR8+/eEwrJ05FlqQgkiVgZFmEiwv6dzz05MncfC+433jFhPbNd2NLBZveJzspiJvUyDEDUQjkQypi5hV17c4yAl+WTTZxQb8/5i2vHNfBJxZ1+w2XRY656TtQZxe6Mm18XdJqSuTBXdsH/nyTD1IYLQTyBinrtDzLJpu4oB/l6aXl2DE3vaZ6z/6jkUHcNDh/3vSDFEYPi50VqLvJVZZFuKiF1I2NVFclLQI2vaY66cxjUDDO0yGx7s8C2okZecmaMntLO9uPWkh9y6+dl5gLj9L062LGjS+utFM6lU6JO2NJOkjNLnR16z1HtLS8cvI2ZvIoCjPykoV4Ka7pyQk9uGu7vrf7Wj24a7s+On1Z5rK6ptdU5ynhjBN3kOr97Pog3tP0zwLCwIy8ZE1PMaSVNX/f9K59RZRwrpd0EBj0s6F9FtA8BPKSxZ3Cj5/VqWE01Wp6TXURJZyStNlMN14R/1iDAnVT0k0IF6mVks3s2KrO5o3Lhc+/eIyFroAkBdvj7to33439fSb9bJPSTQgXgbwkveqEm+46pGM5G2yhflE59fWSct1xP3vOWR228KMQpFZK0F+pEofcaLP1b/q58YoJHXxiMXPVStPXCxA+AnkJBi1u9ZAbba6ostF9892TO1mzllY2fb0AYSO1UoI0M+0yc6NsOskvqWy06aWVGD3MyEsQV6my2Uwn3Es9tW7KBqTQJZWNNj1VQh+Y0UMgL0Fcb5MqFraa3uMkFIN2pjY1VcKBfDSRWilBnRcYaMsGpLqFmj4JcScx8mNGXpK6ZmxN73ESiqanT+JwIB9NBPKWydKyFsmamj5JwoF8NJFaqVjZFSVcN3K0hZoSQj7MyCtU1UJUiDNJFCPUlBDyIZBXiIoS5JG2rJAD+eghkFcopIWopKBBnXL1KCtEEgJ5hUJZiEoKGpJKDygcKDbibA5Jci12mtnlZvaQmR0yszkzu7KogbVRKAtRSUGj7Drl9VficZ06UIx6m4GQzuZQvbxVKx+TdJu7Xy7pI2tfI0YoFSVJQaPsgMKGlmhxZ21NO5tDPfKmVlzSq9b+fbakp3M+XuuFsBA1KAVUZnqImWc09gcgSd4Z+Qcl7TGzH0r6uKSb477RzHaupV/mFhcXcz4typSUAio7PcTMM1ooZ3Ooh7lvvHrNad9gdr+k8yPuukXSWyX9p7vvM7Pfl7TT3a8a9KRTU1M+Nzc3zHhRkbqqVqIuylFVwzGg6cxs3t2nNtw+KJAPeNDnJI27u5uZSXrO3V816OcI5EhC1QoQLS6Q582RPy3pdyT9h6Ttkv4n5+MBpa0jcIBAW+UN5H8u6VNmdoakFyXtzD8koHhsqEGb5Qrk7v6ApCsKGgtQGjbUoM3Y2YlYbUpFUNaINqONLSK1bYclZY1oMwI5IrVth2Uo7RGAYZBaQaS2pSLo0402I5AjUiidGrMIoT0CMAxSK4hEKgIIBzNyRCIVAYSDQI5YpCKAMJBaAYDAEcgBIHAEcgAIHIEcAAJHIAeAwOW6sMTQT2q2KOkHA77tXEnPVjCcpuF1j55Rfe287ux+xd3P67+xlkCehpnNRV0Jo+143aNnVF87r7s4pFYAIHAEcgAIXJMD+d66B1ATXvfoGdXXzusuSGNz5ACAdJo8IwcApEAgB4DANS6Qm9k1ZnbUzL5jZrvqHk9VzOyzZvaMmX2r7rFUycwuMrODZvaYmR0xsw/UPaYqmNmZZvYNMzu89rpvq3tMVTKzzWa2YGb/WvdYqmRm3zezR83skJnNFfa4TcqRm9lmSd+W9LuSnpL0sKR3u/tjtQ6sAmb225Kel/Q5d39D3eOpipm9WtKr3f0RM3ulpHlJ023/nZuZSXq5uz9vZh1JD0j6gLs/VPPQKmFmfyVpStKr3P0ddY+nKmb2fUlT7l7oRqimzcivlPQdd/+uu78k6U5J19c8pkq4+39J+nHd46iau//I3R9Z+/fPJD0uqfVN0H3V82tfdtb+a86sqkRmdqGkayV9uu6xtEXTAvmEpB+u+/opjcAfNVaZ2RZJk5K+Xu9IqrGWXjgk6RlJ97n7SLxuSX8v6cOSTtQ9kBq4pK+Z2byZ7SzqQZsWyDGizOwVkvZJ+qC7/7Tu8VTB3Y+7++WSLpR0pZm1PqVmZu+Q9Iy7z9c9lpr8pru/SdLbJP3FWko1t6YF8q6ki9Z9feHabWixtRzxPkl3uPvddY+nau6+JOmgpGvqHksFtkm6bi1XfKek7Wb2+XqHVB137679/xlJX9ZqOjm3pgXyhyW91swuMbOXSXqXpHtqHhNKtLbo9xlJj7v7J+oeT1XM7DwzG1/795hWF/ifqHdU5XP3m939QnffotW/7wPu/p6ah1UJM3v52oK+zOzlkq6WVEiVWqMCubsfk/R+Sfu1uuj1BXc/Uu+oqmFm/yzpvyVtNbOnzOzP6h5TRbZJeq9WZ2aH1v57e92DqsCrJR00s29qdQJzn7uPVCneCPplSQ+Y2WFJ35B0r7v/exEP3KjyQwBAdo2akQMAsiOQA0DgCOQAEDgCOQAEjkAOAIEjkANA4AjkABC4/wfuTNfLwnrHOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1o0zKSIvJGJ",
        "colab_type": "text"
      },
      "source": [
        "## module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrX5D9WaOSut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8bfcae2f-5c47-41ae-8bc5-13860dcd9dd5"
      },
      "source": [
        "var_mu = torch.tensor([0., 0.], requires_grad=True)\n",
        "var_sigma = torch.tensor([1., 1.], requires_grad=True)\n",
        "var_mu = nn.Parameter(var_mu)\n",
        "var_sigma = nn.Parameter(var_sigma)\n",
        "\n",
        "normal_dist = torchdist.Normal(loc=var_mu, scale=var_sigma)\n",
        "\n",
        "normal_dist.rsample()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.7757,  1.3155], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIV6kKqELcbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.tensor([1.0], requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD(params=[a], lr=1e-2)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "\n",
        "a_dash = a + torch.tensor([2.0])\n",
        "b = torch.tensor([1.0], requires_grad=False)\n",
        "c = a_dash * b\n",
        "loss = c.mean()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "optimizer.zero_grad()\n",
        "c = a_dash * b\n",
        "loss = c.mean()\n",
        "loss.backward()\n",
        "optimizer.step()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB0z4xOQRLmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var_mu = torch.tensor([0., 0.], requires_grad=True)\n",
        "var_sigma = torch.tensor([1., 1.], requires_grad=True)\n",
        "var_mu = nn.Parameter(var_mu)\n",
        "var_sigma = nn.Parameter(var_sigma)\n",
        "\n",
        "normal_dist = torchdist.Normal(loc=var_mu, scale=var_sigma)\n",
        "\n",
        "# a_dash = a + torch.tensor([2.0])\n",
        "w_sample = normal_dist.rsample()\n",
        "b = torch.tensor([1.0], requires_grad=False)\n",
        "c1 = w_sample * b\n",
        "c1.mean().backward()\n",
        "\n",
        "w_sample = normal_dist.rsample()\n",
        "c2 = w_sample * b\n",
        "c2.mean().backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHSGmEYg94QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomNormal(torch.distributions.Normal):\n",
        "    def __init__(self, loc, scale, validate_args=None):        \n",
        "        super(CustomNormal, self).__init__(loc, scale, validate_args)                \n",
        "\n",
        "    def __getattribute__(self, name):        \n",
        "        if name == 'scale':            \n",
        "            return torch.exp(object.__getattribute__(self, name))\n",
        "        else:            \n",
        "            return object.__getattribute__(self, name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPME2DFCasPt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ad5b6486-434d-473a-d725-035a56127cc3"
      },
      "source": [
        "var_mu = torch.tensor([0., 0.], requires_grad=True)\n",
        "var_sigma = torch.tensor([1., 1.], requires_grad=True)\n",
        "var_mu = nn.Parameter(var_mu)\n",
        "var_sigma = nn.Parameter(var_sigma)\n",
        "# var_sigma_pos = torch.distributions.transforms.ExpTransform()(var_sigma)\n",
        "# var_sigma_pos = torch.exp(var_sigma)\n",
        "\n",
        "# normal_dist = torchdist.Normal(loc=var_mu, scale=var_sigma_pos)\n",
        "normal_dist = CustomNormal(loc=var_mu, scale=var_sigma)\n",
        "\n",
        "optimizer = torch.optim.SGD(params=[var_mu, var_sigma], lr=1e-2)\n",
        "\n",
        "class MyClass:\n",
        "    def __init__(self):\n",
        "        self.param = torch.Tensor([0., 0.])\n",
        "\n",
        "obj = MyClass()\n",
        "# param = torch.Tensor([0., 0.])\n",
        "\n",
        "print(obj.param)\n",
        "\n",
        "for i in range(2):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    \n",
        "    w_sample = normal_dist.rsample()\n",
        "    print('w_sample', w_sample)\n",
        "    # param.copy_(w_sample)\n",
        "    # obj.param = w_sample\n",
        "    \n",
        "    setattr(obj, 'param', w_sample)\n",
        "\n",
        "    x = torch.Tensor([2.])\n",
        "\n",
        "    y = obj.param * x\n",
        "    print(y)\n",
        "\n",
        "    loss = y.mean()\n",
        "    print(loss.detach().numpy())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(var_mu.detach(), var_sigma.detach())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0.])\n",
            "w_sample tensor([-3.1503,  2.5689], grad_fn=<AddBackward0>)\n",
            "tensor([-6.3006,  5.1378], grad_fn=<MulBackward0>)\n",
            "-0.5814147\n",
            "tensor([-0.0100, -0.0100]) tensor([1.0315, 0.9743])\n",
            "w_sample tensor([2.3903, 1.5684], grad_fn=<AddBackward0>)\n",
            "tensor([4.7806, 3.1368], grad_fn=<MulBackward0>)\n",
            "3.958694\n",
            "tensor([-0.0200, -0.0200]) tensor([1.0075, 0.9585])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTV0IcEsvItt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TensorModule:\n",
        "    def __init__(self):\n",
        "        self.training = True\n",
        "        self._parameters = OrderedDict()\n",
        "        self._modules = OrderedDict()\n",
        "        self._buffers = OrderedDict()\n",
        "\n",
        "    def __call__(self, *input, **kwargs):\n",
        "        result = self.forward(*input, **kwargs)\n",
        "        return result\n",
        "    \n",
        "    def forward(self, *input):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __setattr__(self, name, value):\n",
        "        def remove_from(*dicts):\n",
        "            for d in dicts:\n",
        "                if name in d:\n",
        "                    del d[name]\n",
        "\n",
        "        params = self.__dict__.get('_parameters')\n",
        "        if name.startswith('p_') and isinstance(value, torch.Tensor):\n",
        "            if params is None:\n",
        "                raise AttributeError\n",
        "            remove_from(self.__dict__, self._buffers, self._modules)\n",
        "            self.register_parameter(name, value)\n",
        "        elif params is not None and name in params:\n",
        "            if value is not None:\n",
        "                raise TypeError\n",
        "            self.register_parameter(name, value)\n",
        "        else:\n",
        "            modules = self.__dict__.get('_modules')\n",
        "            if isinstance(value, TensorModule):\n",
        "                if modules is None:\n",
        "                    raise AttributeError\n",
        "                remove_from(self.__dict__, self._parameters, self._buffers)\n",
        "                modules[name] = value\n",
        "            elif modules is not None and name in modules:\n",
        "                if value is not None:\n",
        "                    raise TypeError\n",
        "                modules[name] = value\n",
        "            else:\n",
        "                buffers = self.__dict__.get('_buffers')\n",
        "                if buffers is not None and name in buffers:\n",
        "                    if value is not None and not isinstance(value, torch.Tensor):\n",
        "                        raise TypeError\n",
        "                    buffers[name] = value\n",
        "                else:\n",
        "                    object.__setattr__(self, name, value)\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        if '_parameters' in self.__dict__:\n",
        "            _parameters = self.__dict__['_parameters']\n",
        "            if name in _parameters:\n",
        "                return _parameters[name]\n",
        "\n",
        "        if '_buffers' in self.__dict__:\n",
        "            _buffers = self.__dict__['_buffers']\n",
        "            if name in _buffers:\n",
        "                return _buffers[name]\n",
        "        \n",
        "        if '_modules' in self.__dict__:\n",
        "            _modules = self.__dict__['_modules']\n",
        "            if name in _modules:\n",
        "                return _modules[name]\n",
        "\n",
        "    def register_parameter(self, name, param):\n",
        "        # debug\n",
        "        if name in self._parameters:\n",
        "            prev_param = self._parameters[name]\n",
        "        else:\n",
        "            prev_param = None\n",
        "        # print('%s: %s -> %s' % (name, str(prev_param), str(param)))\n",
        "\n",
        "        if '.' in name:\n",
        "            raise KeyError\n",
        "\n",
        "        if param is None:\n",
        "            self._parameters[name] = None\n",
        "        elif not isinstance(param, torch.Tensor):\n",
        "            raise TypeError\n",
        "        else:\n",
        "            self._parameters[name] = param\n",
        "\n",
        "    def named_modules(self, memo=None, prefix=''):\n",
        "        if memo is None:\n",
        "            memo = set()\n",
        "        if self not in memo:\n",
        "            memo.add(self)\n",
        "            yield prefix, self\n",
        "            for name, module in self._modules.items():\n",
        "                if module is None:\n",
        "                    continue\n",
        "                submodule_prefix = prefix + ('.' if prefix else '') + name\n",
        "                for m in module.named_modules(memo, submodule_prefix):\n",
        "                    yield m   \n",
        "\n",
        "    def _named_members(self, get_members_fn, prefix='', recurse=True):\n",
        "        memo = set()\n",
        "        modules = self.named_modules(prefix=prefix) if recurse else [(prefix, self)]\n",
        "        for module_prefix, module in modules:\n",
        "            members = get_members_fn(module)\n",
        "            for k, v in members:\n",
        "                if v is None or v in memo:\n",
        "                    continue\n",
        "                memo.add(v)\n",
        "                name = module_prefix + ('.' if module_prefix else '') + k\n",
        "                yield name, v\n",
        "\n",
        "    def named_parameters(self, prefix='', recurse=True):\n",
        "        gen = self._named_members(\n",
        "            lambda module: module._parameters.items(),\n",
        "            prefix=prefix, recurse=True\n",
        "        )\n",
        "        for elem in gen:\n",
        "            yield elem\n",
        "\n",
        "    def _load_from_state_dict(self, state_dict, prefix):\n",
        "        local_name_params = itertools.chain(self._parameters.items(), self._buffers.items())\n",
        "        local_state = {k: v for k, v in local_name_params if v is not None}\n",
        "\n",
        "        for name, param in local_state.items():\n",
        "            key = prefix + name\n",
        "            if key in state_dict:\n",
        "                input_param = state_dict[key]\n",
        "                setattr(self, name, input_param)\n",
        "                # with torch.no_grad():                        \n",
        "                # param.copy_(input_param)\n",
        "            else:\n",
        "                print('miss key: %s' % key)\n",
        "\n",
        "\n",
        "    def set_params(self, state_dict):\n",
        "        def load(module, prefix=''):\n",
        "            module._load_from_state_dict(state_dict, prefix)\n",
        "        \n",
        "            for name, child in module._modules.items():\n",
        "                if child is not None:\n",
        "                    load(child, prefix + name + '.')\n",
        "        load(self)\n",
        "        load = None\n",
        "        \n",
        "    def train(self, mode=True):\n",
        "        self.training =  mode\n",
        "        for module in self.children():\n",
        "            module.train(mode)\n",
        "        return self\n",
        "\n",
        "    def eval(self):\n",
        "        return self.train(False)\n",
        "\n",
        "    def children(self):\n",
        "        for name, module in self.named_children():\n",
        "            yield module\n",
        "\n",
        "    def named_children(self):\n",
        "        memo = set()\n",
        "        for name, module in self._modules.items():\n",
        "            if module is not None and module not in memo:\n",
        "                memo.add(module)\n",
        "                yield name, module\n",
        "\n",
        "class TensorLinear(TensorModule):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(TensorLinear, self).__init__()\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        # self.weight = TensorParameter((out_features, in_features))\n",
        "        self.p_weight = torch.zeros((out_features, in_features), dtype=torch.float32)\n",
        "        if bias:\n",
        "            self.p_bias = torch.zeros((out_features, ), dtype=torch.float32)\n",
        "        else:\n",
        "            # original self.register_parameter('bias', None)\n",
        "            self.p_bias = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.linear(input, self.p_weight, self.p_bias)\n",
        "\n",
        "class TensorLinearNet(TensorModule):\n",
        "    def __init__(self):\n",
        "        super(TensorLinearNet, self).__init__()\n",
        "        self.linear1 = TensorLinear(1, 16)\n",
        "        self.linear2 = TensorLinear(16, 1)\n",
        "        self.linear3 = TensorLinear(16, 1)\n",
        "        self.relu = nn.ReLU()        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        # x = self.relu(x)\n",
        "        # x = self.linear3(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezTSw0Np4KdA",
        "colab_type": "text"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_vkvU5W4KdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearNet, self).__init__()\n",
        "        \n",
        "    def forward(self, w, x):\n",
        "        \"\"\"\n",
        "        w: shape of (3,)\n",
        "        x: shape of (batch,)\n",
        "        \"\"\"\n",
        "        #         phi_x = torch.tensor([])\n",
        "        y = w[0] + w[1]*x + w[2]*x**2\n",
        "        return y\n",
        "\n",
        "class LinearNet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearNet2, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(1, 8)\n",
        "        self.linear2 = nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7fdgqQI4KdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VImodel_org(nn.Module):\n",
        "    \"\"\"\n",
        "    q(w; eta)\n",
        "    \"\"\"\n",
        "    def __init__(self, model):\n",
        "        super(VImodel, self).__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.eta_mu = nn.Parameter(torch.tensor([0., 0., 0.]))\n",
        "        self.eta_log_sigma = nn.Parameter(torch.tensor([0., 0., 0.]))\n",
        "    \n",
        "    def dist(self):\n",
        "        eta_sigma = torch.exp(self.eta_log_sigma)\n",
        "        q_w = torchdist.Normal(self.eta_mu, eta_sigma)\n",
        "        \n",
        "        return q_w\n",
        "    '''\n",
        "    def rsample(self):\n",
        "        eta_sigma = torch.exp(self.eta_log_sigma)\n",
        "        q_w = torchdist.Normal(self.eta_mu, eta_sigma)\n",
        "        \n",
        "        # shape of w: (3,)\n",
        "        w = q_w.rsample()\n",
        "        \n",
        "        return w\n",
        "    '''\n",
        "\n",
        "class ParameterDistribution:\n",
        "    def __init__(self, dist):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        dist: dict\n",
        "            key: paramter name\n",
        "            value: torch.distributions.distribution.Distribution\n",
        "        \"\"\"\n",
        "        if not isinstance(dist, OrderedDict):\n",
        "            raise ValueError('dist must be OrderedDict')\n",
        "        self.dist = dist\n",
        "\n",
        "    def sample(self):\n",
        "        w_sample = OrderedDict()\n",
        "        for n, d in self.dist.items():\n",
        "            w_sample[n] = d.sample()\n",
        "\n",
        "        return w_sample\n",
        "\n",
        "    def rsample(self):\n",
        "        w_sample = OrderedDict()\n",
        "        for n, d in self.dist.items():\n",
        "            w_sample[n] = d.rsample()\n",
        "\n",
        "        return w_sample\n",
        "\n",
        "    def log_prob(self, w):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        w: dict\n",
        "            key: parameter name\n",
        "            value: torch.Tensor\n",
        "        \"\"\"\n",
        "        sum_log_prob = 0\n",
        "        for k, v in w.items():\n",
        "            distribution = self.dist[k]\n",
        "            sum_log_prob += distribution.log_prob(v).sum()\n",
        "\n",
        "        return sum_log_prob\n",
        "\n",
        "class VIModel(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(VIModel, self).__init__()\n",
        "        # set param\n",
        "\n",
        "        param_dict = self.get_params(model)\n",
        "        self.dist = self.normal_dist(param_dict)        \n",
        "        self.__setparams(param_dict)        \n",
        "\n",
        "    def get_params(self, model):\n",
        "        param_dict = OrderedDict()\n",
        "        for n, p in model.named_parameters():\n",
        "            mu = nn.Parameter(torch.zeros_like(p.data))\n",
        "            log_sigma = nn.Parameter(torch.zeros_like(p.data))\n",
        "            \n",
        "            eta_dict = {\n",
        "                'mu': mu,\n",
        "                'log_sigma': log_sigma\n",
        "            }\n",
        "            param_dict[n] = eta_dict\n",
        "\n",
        "        return param_dict\n",
        "\n",
        "    def normal_dist(self, param_dict):\n",
        "        dist = OrderedDict()\n",
        "        for n, eta_dict in param_dict.items():\n",
        "            mu = eta_dict['mu']\n",
        "            log_sigma = eta_dict['log_sigma']\n",
        "            # sigma = torch.exp(log_sigma)\n",
        "\n",
        "            # dist[n] = torchdist.Normal(mu, sigma)\n",
        "            dist[n] = CustomNormal(mu, log_sigma)\n",
        "\n",
        "        return dist\n",
        "\n",
        "    def __setparams(self, param_dict):\n",
        "        for n, eta_dict in param_dict.items():\n",
        "            for eta_name, eta_param in eta_dict.items():\n",
        "                # parameter\n",
        "                name =  '_'.join([n.replace('.', '_'), eta_name])\n",
        "                setattr(self, name, eta_param)\n",
        "                \n",
        "\n",
        "def normal_dist(model):\n",
        "    dist = OrderedDict()\n",
        "    for n, p in model.named_parameters():\n",
        "        mu = nn.Parameter(torch.zeros_like(p.data))\n",
        "        sigma = torch.exp(nn.Parameter(torch.zeros_like(p.data)))        \n",
        "        dist[n] = torchdist.Normal(mu, sigma)\n",
        "\n",
        "    return dist\n",
        "\n",
        "def normal_prior_dist(model):\n",
        "    dist = OrderedDict()\n",
        "    for n, p in model.named_parameters():\n",
        "        param_size = p.size()        \n",
        "        mu = torch.zeros(param_size)\n",
        "        # [10, 10, ...]\n",
        "        sigma = torch.zeros((1,)).new_full(param_size, 10.0)\n",
        "        dist[n] = torchdist.Normal(mu, sigma)\n",
        "\n",
        "    return dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjMlRDMN4KdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kl_divergence(q_w, p_w, model, x, y):\n",
        "\n",
        "    # sampling from q(w)\n",
        "    w_sample = q_w.rsample()\n",
        "    \n",
        "    # l1_p_w = w_sample['linear1.p_weight']\n",
        "    # print(l1_p_w, id(l1_p_w))\n",
        "    # print(model.linear1.p_weight, id(model.linear1.p_weight))\n",
        "\n",
        "    # print('w_sample', w_sample)\n",
        "    # model.load_state_dict(w_sample)\n",
        "    # freeze_param(model)\n",
        "    # printw(model)\n",
        "    # setw(model, w_sample, '') \n",
        "    model.set_params(w_sample)\n",
        "\n",
        "    # l1_p_w = model.linear1._parameters['p_weight']\n",
        "    # print(l1_p_w, id(l1_p_w))\n",
        "    # print(model.linear1.p_weight, id(model.linear1.p_weight))\n",
        "    \n",
        "    # calculate f(x)\n",
        "    # p(y|x,w) = N(f(x; w), 1)\n",
        "    output = model(x)\n",
        "\n",
        "    # print('output', output)\n",
        "    p_y_xw = torchdist.Normal(output, torch.ones_like(output))\n",
        "\n",
        "    # log(p(w, x, y)) = log(p(w)) + sum(log(p(y|x,w)))    \n",
        "    val_log_joint_prob = p_w.log_prob(w_sample) + p_y_xw.log_prob(y).sum()\n",
        "\n",
        "    val_log_q_w = q_w.log_prob(w_sample)\n",
        "    \n",
        "    return val_log_q_w - val_log_joint_prob\n",
        "\n",
        "\n",
        "def loss_func(model, x, y):\n",
        "    y_pred = model(x)\n",
        "    loss = ((y - y_pred)**2).mean()\n",
        "    return loss\n",
        "\n",
        "def freeze_param(model):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def setw(module, w_dict, prefix):\n",
        "    var_names = list(module._parameters.keys())\n",
        "    for var_name in var_names:\n",
        "        if prefix == '':\n",
        "            full_name = var_name\n",
        "        else:\n",
        "            full_name = '.'.join([prefix, var_name])\n",
        "        print(full_name)\n",
        "        value = w_dict[full_name]        \n",
        "        # module.__setattr__ == \n",
        "        \n",
        "        # value_param =  nn.Parameter(value, requires_grad=False)\n",
        "        # dengerous process\n",
        "        value.__class__ = nn.Parameter\n",
        "        setattr(module, var_name, value)\n",
        "        print('test')\n",
        "        # module.register_parameter(var_name, value_param)\n",
        "        # module._parameters[var_name] = value\n",
        "        \n",
        "    for child_name, child_module in module._modules.items():\n",
        "        if prefix == '':\n",
        "            child_full_name = child_name\n",
        "        else:\n",
        "            child_full_name = '.'.join([prefix, child_name])\n",
        "        setw(child_module, w_dict, child_full_name)\n",
        "\n",
        "def printw(module, prefix=''):\n",
        "    var_names = list(module._parameters.keys())\n",
        "    for var_name in var_names:        \n",
        "        if prefix == '':\n",
        "            full_name = var_name\n",
        "        else:\n",
        "            full_name = '.'.join([prefix, var_name])\n",
        "        print(full_name)\n",
        "        print(getattr(module, var_name))        \n",
        "\n",
        "    for child_name, child_module in module._modules.items():\n",
        "        if prefix == '':\n",
        "            child_full_name = child_name\n",
        "        else:\n",
        "            child_full_name = '.'.join([prefix, child_name])\n",
        "        printw(child_module, child_full_name)\n",
        "\n",
        "def write_graph(writer, model, x):\n",
        "    writer.add_graph(model, input_to_model=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEMKHByHrdgv",
        "colab_type": "text"
      },
      "source": [
        "## exec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pn6FEfV4KdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = LinearNet2()\n",
        "model = TensorLinearNet()\n",
        "vimodel = VIModel(model)\n",
        "q_w = ParameterDistribution(vimodel.dist)\n",
        "p_w = ParameterDistribution(normal_prior_dist(model))\n",
        "\n",
        "optimizer = torch.optim.SGD(params=vimodel.parameters(), lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "87ydpXz34KdS",
        "colab_type": "code",
        "outputId": "bd199c8e-0920-4960-dc05-77dde428fc54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.train()\n",
        "for i in range(10000):    \n",
        "    with torch.set_grad_enabled(True):    \n",
        "        optimizer.zero_grad()\n",
        "        # loss = kl_divergence2(q_w, p_w, vimodel, x_train, y_train)\n",
        "        loss = kl_divergence(q_w, p_w, model, x_train, y_train)        \n",
        "        # loss = loss_func(model, x_train, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    \n",
        "    if (i+1) % 100 == 0:\n",
        "        # mu = vimodel.eta_mu.detach().numpy()\n",
        "        # sigma = torch.exp(vimodel.eta_log_sigma.detach()).numpy()\n",
        "        # print('loss: %f mu: %s sigma: %s' % (loss.detach().numpy(), str(mu), str(sigma)))\n",
        "        # print(loss.size())\n",
        "        print('iter: %d loss: %f ' % (i, loss.item(),))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter: 99 loss: 772.380493 \n",
            "iter: 199 loss: 653.631958 \n",
            "iter: 299 loss: 585.818054 \n",
            "iter: 399 loss: 639.038391 \n",
            "iter: 499 loss: 645.086365 \n",
            "iter: 599 loss: 614.361755 \n",
            "iter: 699 loss: 593.973877 \n",
            "iter: 799 loss: 594.942566 \n",
            "iter: 899 loss: 520.285034 \n",
            "iter: 999 loss: 572.937073 \n",
            "iter: 1099 loss: 573.818665 \n",
            "iter: 1199 loss: 581.060364 \n",
            "iter: 1299 loss: 507.344910 \n",
            "iter: 1399 loss: 573.329529 \n",
            "iter: 1499 loss: 567.001282 \n",
            "iter: 1599 loss: 582.096558 \n",
            "iter: 1699 loss: 578.445312 \n",
            "iter: 1799 loss: 573.031799 \n",
            "iter: 1899 loss: 586.380920 \n",
            "iter: 1999 loss: 562.461975 \n",
            "iter: 2099 loss: 593.880676 \n",
            "iter: 2199 loss: 528.276672 \n",
            "iter: 2299 loss: 567.287903 \n",
            "iter: 2399 loss: 563.055603 \n",
            "iter: 2499 loss: 558.969849 \n",
            "iter: 2599 loss: 581.409485 \n",
            "iter: 2699 loss: 577.058716 \n",
            "iter: 2799 loss: 577.416382 \n",
            "iter: 2899 loss: 572.287781 \n",
            "iter: 2999 loss: 573.747559 \n",
            "iter: 3099 loss: 570.390503 \n",
            "iter: 3199 loss: 550.226685 \n",
            "iter: 3299 loss: 572.549194 \n",
            "iter: 3399 loss: 573.384399 \n",
            "iter: 3499 loss: 560.764832 \n",
            "iter: 3599 loss: 577.071716 \n",
            "iter: 3699 loss: 566.533936 \n",
            "iter: 3799 loss: 552.322327 \n",
            "iter: 3899 loss: 575.149109 \n",
            "iter: 3999 loss: 562.129089 \n",
            "iter: 4099 loss: 553.386841 \n",
            "iter: 4199 loss: 559.478638 \n",
            "iter: 4299 loss: 551.935974 \n",
            "iter: 4399 loss: 548.111572 \n",
            "iter: 4499 loss: 557.098938 \n",
            "iter: 4599 loss: 558.016602 \n",
            "iter: 4699 loss: 556.339294 \n",
            "iter: 4799 loss: 562.883850 \n",
            "iter: 4899 loss: 577.605408 \n",
            "iter: 4999 loss: 546.836121 \n",
            "iter: 5099 loss: 565.441711 \n",
            "iter: 5199 loss: 772.497314 \n",
            "iter: 5299 loss: 575.151001 \n",
            "iter: 5399 loss: 525.846069 \n",
            "iter: 5499 loss: 496.648041 \n",
            "iter: 5599 loss: 539.842529 \n",
            "iter: 5699 loss: 566.181152 \n",
            "iter: 5799 loss: 532.900024 \n",
            "iter: 5899 loss: 846.522339 \n",
            "iter: 5999 loss: 550.587463 \n",
            "iter: 6099 loss: 482.161896 \n",
            "iter: 6199 loss: 559.349854 \n",
            "iter: 6299 loss: 539.224243 \n",
            "iter: 6399 loss: 538.752197 \n",
            "iter: 6499 loss: 569.310425 \n",
            "iter: 6599 loss: 484.507782 \n",
            "iter: 6699 loss: 566.163452 \n",
            "iter: 6799 loss: 558.237000 \n",
            "iter: 6899 loss: 568.100098 \n",
            "iter: 6999 loss: 567.452881 \n",
            "iter: 7099 loss: 566.824524 \n",
            "iter: 7199 loss: 553.619324 \n",
            "iter: 7299 loss: 506.459320 \n",
            "iter: 7399 loss: 541.594666 \n",
            "iter: 7499 loss: 499.898621 \n",
            "iter: 7599 loss: 530.069336 \n",
            "iter: 7699 loss: 500.438904 \n",
            "iter: 7799 loss: 494.681702 \n",
            "iter: 7899 loss: 519.150818 \n",
            "iter: 7999 loss: 434.295868 \n",
            "iter: 8099 loss: 441.341156 \n",
            "iter: 8199 loss: 455.330200 \n",
            "iter: 8299 loss: 462.558899 \n",
            "iter: 8399 loss: 430.339600 \n",
            "iter: 8499 loss: 416.395599 \n",
            "iter: 8599 loss: 447.707397 \n",
            "iter: 8699 loss: 387.952637 \n",
            "iter: 8799 loss: 381.960358 \n",
            "iter: 8899 loss: 407.871765 \n",
            "iter: 8999 loss: 383.724152 \n",
            "iter: 9099 loss: 405.061829 \n",
            "iter: 9199 loss: 389.122467 \n",
            "iter: 9299 loss: 376.816040 \n",
            "iter: 9399 loss: 435.214722 \n",
            "iter: 9499 loss: 369.486450 \n",
            "iter: 9599 loss: 425.712463 \n",
            "iter: 9699 loss: 386.431946 \n",
            "iter: 9799 loss: 344.502960 \n",
            "iter: 9899 loss: 403.398071 \n",
            "iter: 9999 loss: 348.919891 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQWSlcCF4Kdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9mOfcn24Kdg",
        "colab_type": "text"
      },
      "source": [
        "## prediction\n",
        "\n",
        "Calculate prediction distribution\n",
        "$$\n",
        "\\begin{align}\n",
        "p(y_*| x_*, X, Y) &= \\int p(y_*| x_*, W) p(W| X, Y) dW \\\\\n",
        "&\\approx \\int p(y_*| x_*, W) q(W; \\eta) dW \n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skswvUkj4Kdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(q_w, model, x, n_samples):    \n",
        "    \n",
        "    approx_y = 0    \n",
        "    with torch.no_grad():\n",
        "        for i in range(n_samples):\n",
        "            # sampling from q(w)\n",
        "            w_sample = q_w.sample()\n",
        "            model.set_params(w_sample)\n",
        "            # calculate f(x)\n",
        "            output = model(x)\n",
        "\n",
        "            # p(y|x,w) = N(f(x; w), 1)\n",
        "            p_y_xw = torchdist.Normal(output, torch.ones_like(output))\n",
        "\n",
        "            # sampling from p(y, w)\n",
        "            y_sample = p_y_xw.sample()\n",
        "\n",
        "            approx_y += y_sample / n_samples\n",
        "    \n",
        "    return approx_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-T_EbsM4Kdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_data(q_w, model):\n",
        "    n_samples = 100\n",
        "    x_pred = 5 * torch.rand(100, 1)\n",
        "    y_pred = predict(q_w, model, x_pred, n_samples)\n",
        "    \n",
        "    return x_pred, y_pred\n",
        "\n",
        "x_pred, y_pred = predict_data(q_w, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF8MgxlM4Kdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "e269c34b-339e-4e65-93d9-ec0269e37db3"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "print(len(axes))\n",
        "axes[0].plot(x_train.numpy(), y_train.numpy(), 'o')\n",
        "axes[1].plot(x_pred.numpy(), y_pred.numpy(), 'o')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fabf6fb47b8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04oj1yPC4Kdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UOCXFKe4Kdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_joint_prob(w0, w1, w2, x, y):\n",
        "    prior_w0 = torchdist.Normal(torch.tensor(0.), 10*torch.tensor(1.))\n",
        "    prior_w1 = torchdist.Normal(torch.tensor(0.), 10*torch.tensor(1.))\n",
        "    prior_w2 = torchdist.Normal(torch.tensor(0.), 10*torch.tensor(1.))\n",
        "    \n",
        "    linear = w0 + w1*x + w2*x**2\n",
        "    likelihood = torchdist.Normal(linear, torch.ones_like(linear))\n",
        "    \n",
        "    return (\n",
        "        prior_w0.log_prob(w0) +\n",
        "        prior_w1.log_prob(w1) +\n",
        "        prior_w2.log_prob(w2) +\n",
        "        likelihood.log_prob(y).mean()\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6bGlFup4Kdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "w0 = torch.nn.Parameter(torch.tensor(1.))\n",
        "w1 = torch.nn.Parameter(torch.tensor(1.))\n",
        "w2 = torch.nn.Parameter(torch.tensor(1.))\n",
        "\n",
        "optimizer = torch.optim.Adam(params=[w0, w1, w2], lr=1e-3)\n",
        "\n",
        "for i in range(30000):\n",
        "    optimizer.zero_grad()\n",
        "    log_joint_prob_value = log_joint_prob(w0, w1, w2, x_train, y_train)\n",
        "    loss_value = - log_joint_prob_value\n",
        "    loss_value.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (i+1) % 1000 == 0 or (i==0):\n",
        "        print(loss_value.detach().numpy())\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPwyJ8S-4Kd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}