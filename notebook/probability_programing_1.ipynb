{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.distributions as torchdist\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dist = torchdist.Normal(loc=torch.tensor(0.), scale=torch.tensor(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = normal_dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.6541)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = normal_dist.sample([100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0771, -1.5466,  0.2884,  1.0425,  0.5454, -0.7535, -0.8863, -1.9649,\n",
       "         1.4845, -1.2679,  1.5053,  0.3087,  0.8753, -0.7226, -0.2196, -0.7932,\n",
       "        -1.7360, -2.8748,  0.6508,  0.6414, -0.1379,  0.5310,  0.7292,  1.0037,\n",
       "         0.3915, -0.3077, -1.6156, -1.0584,  0.3957,  2.3781,  0.0935, -2.0646,\n",
       "        -0.5939, -0.1284, -0.1470,  0.9330, -0.7404,  1.4943, -0.1264,  0.5002,\n",
       "         0.3606,  1.1733, -1.0369, -0.1545,  1.6796, -0.1438, -0.5004,  0.1363,\n",
       "         0.3740, -1.0412,  0.1299, -0.2962, -1.4899, -2.0192, -0.0910, -0.3518,\n",
       "         2.6431,  1.1347, -0.4285,  0.1258,  0.8439, -0.7216, -0.1777, -0.9818,\n",
       "        -0.5263,  0.4214, -1.2704,  0.5404, -0.5254, -1.1265, -1.7954, -0.9965,\n",
       "         0.7182, -2.6893,  0.3045, -0.5148, -0.1577, -0.1463, -0.0425, -0.2962,\n",
       "         0.2282,  1.2408, -1.7098, -1.0748,  0.0246,  0.3392, -0.7891,  0.0578,\n",
       "         0.0186, -2.2881,  0.2632,  1.7177, -0.5182,  0.8976, -0.1576,  1.5942,\n",
       "         0.7322,  0.2230, -0.6350, -1.1250])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  5.,  7., 15., 23., 22., 13.,  8.,  3.,  2.]),\n",
       " array([-2.8748193 , -2.323025  , -1.7712307 , -1.2194365 , -0.66764224,\n",
       "        -0.11584795,  0.43594632,  0.9877406 ,  1.5395348 ,  2.091329  ,\n",
       "         2.6431234 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_poly():\n",
    "    x = 5 * torch.rand(100, 1)\n",
    "    linear_op = -3 - 4*x + x**2\n",
    "    y = torchdist.Normal(linear_op, 1).sample()\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = toy_poly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2421aa66080>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train.numpy(), y_train.numpy(), 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        \n",
    "    def forward(self, w, x):\n",
    "        \"\"\"\n",
    "        w: shape of (3,)\n",
    "        x: shape of (batch,)\n",
    "        \"\"\"\n",
    "        #         phi_x = torch.tensor([])\n",
    "        y = w[0] + w[1]*x + w[2]*x**2\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VImodel(nn.Module):\n",
    "    \"\"\"\n",
    "    q(w; eta)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(VImodel, self).__init__()\n",
    "        self.eta_mu = nn.Parameter(torch.tensor([0., 0., 0.]))\n",
    "        self.eta_log_sigma = nn.Parameter(torch.tensor([0., 0., 0.]))\n",
    "    \n",
    "    def dist(self):\n",
    "        eta_sigma = torch.exp(self.eta_log_sigma)\n",
    "        q_w = torchdist.Normal(self.eta_mu, eta_sigma)\n",
    "        \n",
    "        return q_w\n",
    "    '''\n",
    "    def rsample(self):\n",
    "        eta_sigma = torch.exp(self.eta_log_sigma)\n",
    "        q_w = torchdist.Normal(self.eta_mu, eta_sigma)\n",
    "        \n",
    "        # shape of w: (3,)\n",
    "        w = q_w.rsample()\n",
    "        \n",
    "        return w\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(vmodel, model, x, y):\n",
    "    q_w = vmodel.dist()\n",
    "    w_sample = q_w.rsample()    \n",
    "    \n",
    "    output = model(w_sample, x)    \n",
    "    \n",
    "    # p(y|x,w) = N(f(x; w), 1)\n",
    "    p_y_xw = torchdist.Normal(output, torch.ones_like(output))\n",
    "    # p(w) = N(0, 10)\n",
    "    p_w = torchdist.Normal(torch.tensor([0., 0., 0.]), torch.tensor([10., 10., 10.]))\n",
    "    \n",
    "    # log(p(w, x, y)) = log(p(w)) + 1/n * sigma(log(p(y|x,w)))\n",
    "    val_log_joint_prob = p_w.log_prob(w_sample).sum() + p_y_xw.log_prob(y).mean()\n",
    "    \n",
    "    val_log_q_w = q_w.log_prob(w_sample).sum()\n",
    "    \n",
    "    return val_log_q_w - val_log_joint_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vimodel = VImodel()\n",
    "model = LinearNet()\n",
    "optimizer = torch.optim.SGD(params=vimodel.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26.812496 mu: [-0.00021048  0.0002079   0.00241458]\n",
      "loss: 18.832735 mu: [-0.15953322 -0.20465852 -0.18758607]\n",
      "loss: 21.290607 mu: [-0.29363307 -0.3346249  -0.11052269]\n",
      "loss: 17.090652 mu: [-0.42486292 -0.47146088 -0.09016807]\n",
      "loss: 17.018867 mu: [-0.54783016 -0.590821   -0.02180043]\n",
      "loss: 17.026001 mu: [-0.66617954 -0.70755076  0.03447024]\n",
      "loss: 20.906048 mu: [-0.7864518 -0.8387914  0.0219383]\n",
      "loss: 25.302828 mu: [-0.89560825 -0.9479581   0.06749553]\n",
      "loss: 16.262108 mu: [-1.0036962  -1.0597554   0.09145799]\n",
      "loss: 18.547161 mu: [-1.0997602  -1.1511965   0.15948977]\n",
      "loss: 20.494411 mu: [-1.1986444  -1.255567    0.16997397]\n",
      "loss: 14.492522 mu: [-1.2912115 -1.3467085  0.2169843]\n",
      "loss: 14.101868 mu: [-1.3817797  -1.443674    0.22008407]\n",
      "loss: 15.475110 mu: [-1.4657048  -1.5261906   0.26431867]\n",
      "loss: 14.671127 mu: [-1.5480297 -1.6125643  0.2782606]\n",
      "loss: 14.154516 mu: [-1.6239567  -1.6860789   0.32570735]\n",
      "loss: 14.538898 mu: [-1.6999624 -1.7652081  0.3416909]\n",
      "loss: 12.164493 mu: [-1.7707897 -1.8361855  0.3735126]\n",
      "loss: 13.901186 mu: [-1.8430278 -1.916199   0.3618573]\n",
      "loss: 13.985053 mu: [-1.9054612 -1.9755219  0.4087339]\n",
      "loss: 18.355547 mu: [-1.9703377 -2.0457497  0.4100106]\n",
      "loss: 13.386320 mu: [-2.0280795 -2.0995965  0.4592466]\n",
      "loss: 12.252517 mu: [-2.0861564  -2.1607811   0.47023782]\n",
      "loss: 12.241352 mu: [-2.1454096  -2.225496    0.46723303]\n",
      "loss: 13.052933 mu: [-2.195121  -2.2732413  0.5044382]\n",
      "loss: 12.425845 mu: [-2.2466457  -2.3260067   0.52269095]\n",
      "loss: 14.000224 mu: [-2.2949955 -2.3761187  0.53807  ]\n",
      "loss: 12.601088 mu: [-2.3418465 -2.4240332  0.5556693]\n",
      "loss: 13.163125 mu: [-2.3868797  -2.4714336   0.56506443]\n",
      "loss: 11.224277 mu: [-2.4281554 -2.5131664  0.5846881]\n",
      "loss: 11.104707 mu: [-2.4678693 -2.5512335  0.6149209]\n",
      "loss: 12.275169 mu: [-2.5071878 -2.594176   0.6167446]\n",
      "loss: 11.734338 mu: [-2.5449755 -2.6334603  0.6289828]\n",
      "loss: 11.848306 mu: [-2.5823495  -2.675983    0.62021995]\n",
      "loss: 11.946148 mu: [-2.6169267  -2.7096872   0.64349616]\n",
      "loss: 11.916880 mu: [-2.6483824 -2.7412443  0.6620727]\n",
      "loss: 12.052802 mu: [-2.6793983  -2.7753642   0.66403437]\n",
      "loss: 12.592891 mu: [-2.711026  -2.8118641  0.6556121]\n",
      "loss: 14.674116 mu: [-2.737246   -2.8347723   0.69003767]\n",
      "loss: 12.393883 mu: [-2.7657955 -2.8653345  0.6955381]\n",
      "loss: 12.279412 mu: [-2.7946131 -2.900038   0.6795271]\n",
      "loss: 7.459534 mu: [-2.81776   -2.9159415  0.7333964]\n",
      "loss: 10.574296 mu: [-2.8435202  -2.9479446   0.71410036]\n",
      "loss: 13.896599 mu: [-2.865333  -2.9698539  0.72949  ]\n",
      "loss: 12.216817 mu: [-2.8870428 -2.9916036  0.7446845]\n",
      "loss: 14.162481 mu: [-2.9081552 -3.0130649  0.7574414]\n",
      "loss: 9.998183 mu: [-2.9301646 -3.0391471  0.7490604]\n",
      "loss: 11.848566 mu: [-2.9504435  -3.0595567   0.76207685]\n",
      "loss: 11.133087 mu: [-2.9695363  -3.0816617   0.75879043]\n",
      "loss: 12.475505 mu: [-2.9881191  -3.1043315   0.75034297]\n",
      "loss: 11.543226 mu: [-3.004307  -3.1175861  0.7782321]\n",
      "loss: 11.919758 mu: [-3.0215337  -3.1372056   0.77872187]\n",
      "loss: 11.688233 mu: [-3.0354161 -3.151624   0.7887686]\n",
      "loss: 10.409632 mu: [-3.0500157 -3.1688874  0.7862526]\n",
      "loss: 11.722592 mu: [-3.063758  -3.1817935  0.802561 ]\n",
      "loss: 10.835610 mu: [-3.077655  -3.1982415  0.800734 ]\n",
      "loss: 11.092027 mu: [-3.089892   -3.2095249   0.81700957]\n",
      "loss: 10.058978 mu: [-3.1033826 -3.2256773  0.8133192]\n",
      "loss: 11.284060 mu: [-3.1161773 -3.2417257  0.8066631]\n",
      "loss: 11.356926 mu: [-3.1272626  -3.2535107   0.81354725]\n",
      "loss: 11.390866 mu: [-3.1378572  -3.262726    0.83098584]\n",
      "loss: 9.473508 mu: [-3.1458817  -3.2687924   0.85185224]\n",
      "loss: 12.671476 mu: [-3.1562257 -3.2837012  0.8377734]\n",
      "loss: 11.954254 mu: [-3.1678576 -3.2998137  0.822908 ]\n",
      "loss: 12.717437 mu: [-3.1759584  -3.3066912   0.83908004]\n",
      "loss: 12.837530 mu: [-3.1873813  -3.3207855   0.83414596]\n",
      "loss: 10.473426 mu: [-3.1927736 -3.3215606  0.868564 ]\n",
      "loss: 10.767300 mu: [-3.200865  -3.331502   0.8682629]\n",
      "loss: 15.053724 mu: [-3.2126799 -3.3514457  0.8336664]\n",
      "loss: 11.806514 mu: [-3.2186306 -3.3513517  0.8748387]\n",
      "loss: 12.305711 mu: [-3.2243764  -3.3591151   0.87319404]\n",
      "loss: 11.199943 mu: [-3.2340224  -3.3756688   0.84534985]\n",
      "loss: 11.048465 mu: [-3.239019  -3.3801143  0.8574055]\n",
      "loss: 17.599552 mu: [-3.2484539 -3.3927588  0.8481001]\n",
      "loss: 11.683100 mu: [-3.2512672  -3.391831    0.87705284]\n",
      "loss: 11.467859 mu: [-3.2594872  -3.4062364   0.85202307]\n",
      "loss: 14.513137 mu: [-3.2631152  -3.408921    0.86657435]\n",
      "loss: 12.043767 mu: [-3.2664814  -3.4113328   0.87986857]\n",
      "loss: 12.665663 mu: [-3.2730632  -3.4227314   0.86198235]\n",
      "loss: 12.817554 mu: [-3.2752147 -3.423178   0.8788344]\n",
      "loss: 11.484714 mu: [-3.2803545 -3.4300246  0.8778138]\n",
      "loss: 10.459853 mu: [-3.2855382 -3.436892   0.8763038]\n",
      "loss: 12.824031 mu: [-3.2892232 -3.4418733  0.8773661]\n",
      "loss: 12.653494 mu: [-3.2932422 -3.4453824  0.8872422]\n",
      "loss: 10.608104 mu: [-3.2976062  -3.4513066   0.88604975]\n",
      "loss: 10.350547 mu: [-3.2997997  -3.4537284   0.89224833]\n",
      "loss: 11.508862 mu: [-3.3031754 -3.4592466  0.8874906]\n",
      "loss: 10.299715 mu: [-3.3048751  -3.460987    0.89493316]\n",
      "loss: 11.516034 mu: [-3.3085406 -3.4672403  0.8880299]\n",
      "loss: 11.010504 mu: [-3.3115344  -3.4706824   0.89263743]\n",
      "loss: 11.811999 mu: [-3.3126667 -3.469482   0.9126643]\n",
      "loss: 12.633848 mu: [-3.3176103 -3.480395   0.8869929]\n",
      "loss: 12.322564 mu: [-3.3208902  -3.4866993   0.87773347]\n",
      "loss: 11.528634 mu: [-3.3217108  -3.4840689   0.90295714]\n",
      "loss: 10.575814 mu: [-3.3231745  -3.4876246   0.89894396]\n",
      "loss: 11.694347 mu: [-3.3247576  -3.4885077   0.90872973]\n",
      "loss: 10.175838 mu: [-3.3284826 -3.4947143  0.9021247]\n",
      "loss: 10.225866 mu: [-3.3298767 -3.4956574  0.9107026]\n",
      "loss: 12.069822 mu: [-3.3309746 -3.5008647  0.8956144]\n",
      "loss: 11.872923 mu: [-3.3324773 -3.5024314  0.9012023]\n",
      "loss: 12.102298 mu: [-3.3345754  -3.5081463   0.88851625]\n",
      "loss: 11.828833 mu: [-3.3356357  -3.509869    0.89140207]\n",
      "loss: 12.367976 mu: [-3.3348408  -3.5085826   0.90116084]\n",
      "loss: 11.410131 mu: [-3.3359518  -3.5088167   0.91194004]\n",
      "loss: 13.224559 mu: [-3.3376148  -3.516183    0.88796556]\n",
      "loss: 13.400390 mu: [-3.3387327  -3.5170517   0.89582855]\n",
      "loss: 11.925136 mu: [-3.3394835 -3.5167994  0.9070719]\n",
      "loss: 11.128916 mu: [-3.3403115  -3.5212808   0.89394766]\n",
      "loss: 11.194156 mu: [-3.342417  -3.5267382  0.8822145]\n",
      "loss: 11.684545 mu: [-3.3406625  -3.51852     0.92279696]\n",
      "loss: 12.902004 mu: [-3.3422205  -3.5234408   0.91120535]\n",
      "loss: 11.812960 mu: [-3.3418057 -3.5254033  0.905049 ]\n",
      "loss: 10.784203 mu: [-3.341877  -3.5250633  0.9133159]\n",
      "loss: 9.768022 mu: [-3.342913   -3.528838    0.90561575]\n",
      "loss: 10.075880 mu: [-3.3453677 -3.5337346  0.8984257]\n",
      "loss: 14.221076 mu: [-3.3447235 -3.5345154  0.8977561]\n",
      "loss: 9.550406 mu: [-3.346823  -3.5388732  0.8919702]\n",
      "loss: 14.068097 mu: [-3.3454344  -3.5365012   0.90412503]\n",
      "loss: 11.044363 mu: [-3.3463507  -3.5390537   0.90194863]\n",
      "loss: 11.424930 mu: [-3.3455124  -3.538909    0.90461904]\n",
      "loss: 11.514423 mu: [-3.3456032 -3.5380218  0.9154221]\n",
      "loss: 18.396418 mu: [-3.3472016 -3.5420341  0.9081393]\n",
      "loss: 11.397233 mu: [-3.3469498 -3.5392518  0.92718  ]\n",
      "loss: 14.124281 mu: [-3.3491642 -3.5487714  0.8938507]\n",
      "loss: 12.012840 mu: [-3.3510516  -3.5508394   0.89806265]\n",
      "loss: 12.425160 mu: [-3.347372   -3.5411758   0.93625474]\n",
      "loss: 10.523733 mu: [-3.3487828 -3.5460608  0.9237223]\n",
      "loss: 11.994990 mu: [-3.3519368 -3.5573156  0.8864763]\n",
      "loss: 11.507030 mu: [-3.3505442  -3.5497987   0.92442536]\n",
      "loss: 11.318528 mu: [-3.3515182 -3.5553112  0.906188 ]\n",
      "loss: 10.885575 mu: [-3.3508909 -3.553298   0.9189776]\n",
      "loss: 11.470119 mu: [-3.3522954 -3.5572593  0.9114813]\n",
      "loss: 13.777523 mu: [-3.3525076 -3.5570533  0.9191983]\n",
      "loss: 11.072863 mu: [-3.3534052 -3.5594983  0.9164754]\n",
      "loss: 11.395103 mu: [-3.3513386  -3.556705    0.92657393]\n",
      "loss: 9.537954 mu: [-3.3506105 -3.5593016  0.9147   ]\n",
      "loss: 10.795897 mu: [-3.3513887  -3.562194    0.90860355]\n",
      "loss: 12.145736 mu: [-3.352563  -3.5649526  0.9046275]\n",
      "loss: 9.184980 mu: [-3.3517957 -3.5624208  0.9196521]\n",
      "loss: 16.160542 mu: [-3.351531  -3.5643208  0.9134989]\n",
      "loss: 9.739652 mu: [-3.350416  -3.560391   0.9337001]\n",
      "loss: 12.240701 mu: [-3.351846   -3.564074    0.92622256]\n",
      "loss: 10.823115 mu: [-3.3535767  -3.5697227   0.91036993]\n",
      "loss: 11.335590 mu: [-3.3524878 -3.5679507  0.9199239]\n",
      "loss: 10.903345 mu: [-3.3556237 -3.5780096  0.8874002]\n",
      "loss: 11.631480 mu: [-3.3538506 -3.5719254  0.9155397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 11.719726 mu: [-3.353878  -3.573086   0.9146844]\n",
      "loss: 12.809627 mu: [-3.3543918 -3.576275   0.9060949]\n",
      "loss: 12.064063 mu: [-3.3511655 -3.5696478  0.9301079]\n",
      "loss: 11.568466 mu: [-3.3513844  -3.5737927   0.91373783]\n",
      "loss: 11.628743 mu: [-3.353008  -3.5788558  0.9000982]\n",
      "loss: 9.330519 mu: [-3.3528156 -3.5770175  0.9141305]\n",
      "loss: 15.873258 mu: [-3.3541765  -3.5800843   0.90932024]\n",
      "loss: 13.402539 mu: [-3.3521583  -3.5752175   0.92895955]\n",
      "loss: 11.002305 mu: [-3.351418   -3.576003    0.92601264]\n",
      "loss: 11.248577 mu: [-3.3505647  -3.5751953   0.93055385]\n",
      "loss: 13.229175 mu: [-3.3516867 -3.5799909  0.9157701]\n",
      "loss: 12.989222 mu: [-3.3521278  -3.5828052   0.90816045]\n",
      "loss: 11.116403 mu: [-3.351585   -3.5824256   0.91232663]\n",
      "loss: 11.413358 mu: [-3.350495   -3.5806277   0.92090446]\n",
      "loss: 12.359845 mu: [-3.3501978 -3.5803056  0.9251296]\n",
      "loss: 13.074423 mu: [-3.3473878 -3.5753076  0.94213  ]\n",
      "loss: 12.771024 mu: [-3.3478196 -3.5803118  0.9224297]\n",
      "loss: 13.472776 mu: [-3.3506873 -3.5892558  0.8942492]\n",
      "loss: 10.833201 mu: [-3.348521  -3.584759   0.9116851]\n",
      "loss: 11.391124 mu: [-3.347314  -3.5821788  0.9239029]\n",
      "loss: 12.181921 mu: [-3.3484743 -3.5848813  0.9189225]\n",
      "loss: 11.957655 mu: [-3.3458421  -3.5807714   0.93187654]\n",
      "loss: 10.912582 mu: [-3.3477619  -3.5881033   0.90784407]\n",
      "loss: 10.790586 mu: [-3.3461168 -3.5838752  0.9268898]\n",
      "loss: 11.752793 mu: [-3.3462753  -3.5875192   0.91273284]\n",
      "loss: 11.832411 mu: [-3.3440514 -3.582769   0.9317607]\n",
      "loss: 11.615628 mu: [-3.344884  -3.5889118  0.908565 ]\n",
      "loss: 11.789757 mu: [-3.3435056  -3.586709    0.91782314]\n",
      "loss: 12.812436 mu: [-3.3422604 -3.5838268  0.9314051]\n",
      "loss: 11.620658 mu: [-3.3423984 -3.587571   0.9164484]\n",
      "loss: 16.106888 mu: [-3.3408446 -3.585716   0.9226823]\n",
      "loss: 13.677861 mu: [-3.3405387 -3.5864773  0.9215461]\n",
      "loss: 12.159468 mu: [-3.337602  -3.5793033  0.9491551]\n",
      "loss: 13.517860 mu: [-3.3387163 -3.587257   0.9178763]\n",
      "loss: 12.251504 mu: [-3.3408356 -3.5951772  0.8917069]\n",
      "loss: 12.909048 mu: [-3.3407145  -3.5928292   0.90783256]\n",
      "loss: 15.672203 mu: [-3.3392055  -3.5877516   0.93094844]\n",
      "loss: 12.803358 mu: [-3.3407855 -3.59213    0.9199856]\n",
      "loss: 10.513634 mu: [-3.338732  -3.5878093  0.9367192]\n",
      "loss: 12.566525 mu: [-3.3407385 -3.5942185  0.9167443]\n",
      "loss: 12.800892 mu: [-3.3400214 -3.5929244  0.9241352]\n",
      "loss: 11.777431 mu: [-3.3393176  -3.5921743   0.92872477]\n",
      "loss: 12.309189 mu: [-3.3396935 -3.5947177  0.9219483]\n",
      "loss: 11.526999 mu: [-3.339015  -3.5951278  0.9208963]\n",
      "loss: 10.902375 mu: [-3.3388062 -3.595835   0.921158 ]\n",
      "loss: 12.031676 mu: [-3.3392746 -3.5964956  0.9239434]\n",
      "loss: 13.258431 mu: [-3.3368156 -3.5929334  0.9350157]\n",
      "loss: 13.233713 mu: [-3.3361    -3.5931778  0.9338081]\n",
      "loss: 11.925227 mu: [-3.3388014 -3.6022358  0.9035785]\n",
      "loss: 11.256767 mu: [-3.3365412 -3.5962567  0.9288612]\n",
      "loss: 10.016872 mu: [-3.3380744  -3.601807    0.91206175]\n",
      "loss: 12.413913 mu: [-3.3366969 -3.5980783  0.9286507]\n",
      "loss: 11.639041 mu: [-3.3369017 -3.5982246  0.9335285]\n",
      "loss: 11.294836 mu: [-3.3350194 -3.597398   0.9329147]\n",
      "loss: 12.902403 mu: [-3.3357291 -3.602567   0.912869 ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    loss = kl_divergence(vimodel, model, x_train, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 500 == 0 or (i==0):\n",
    "        print('loss: %f mu: %s' % (loss.detach().numpy(), str(vimodel.eta_mu.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-1.8370, -1.9110,  0.3676], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vimodel.eta_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 4.8414e-04, -9.9436e-01, -2.3029e+00], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vimodel.eta_log_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torchdist.Normal(torch.tensor([0., 10.]), torch.tensor([1., 1.]))\n",
    "w = q.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.,  5., 13., 25., 17., 14.,  9.,  4.,  3.,  5.]),\n",
       " array([ 8.144145 ,  8.580228 ,  9.016312 ,  9.4523945,  9.888477 ,\n",
       "        10.32456  , 10.760644 , 11.196727 , 11.63281  , 12.068893 ,\n",
       "        12.504976 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(w[:,1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_joint_prob(w0, w1, w2, x, y):\n",
    "    prior_w0 = torchdist.Normal(torch.tensor(0.), 10*torch.tensor(1.))\n",
    "    prior_w1 = torchdist.Normal(torch.tensor(0.), 10*torch.tensor(1.))\n",
    "    prior_w2 = torchdist.Normal(torch.tensor(0.), 10*torch.tensor(1.))\n",
    "    \n",
    "    linear = w0 + w1*x + w2*x**2\n",
    "    likelihood = torchdist.Normal(linear, torch.ones_like(linear))\n",
    "    \n",
    "    return (\n",
    "        prior_w0.log_prob(w0) +\n",
    "        prior_w1.log_prob(w1) +\n",
    "        prior_w2.log_prob(w2) +\n",
    "        likelihood.log_prob(y).mean()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174.15164\n",
      "38.347015\n",
      "20.815247\n",
      "18.843868\n",
      "16.873156\n",
      "14.854201\n",
      "13.132132\n",
      "11.94904\n",
      "11.34323\n",
      "11.142217\n",
      "11.097228\n",
      "11.072759\n",
      "11.048522\n",
      "11.029579\n",
      "11.019746\n",
      "11.017018\n",
      "11.01674\n",
      "11.016734\n",
      "11.016733\n",
      "11.016733\n",
      "11.016733\n",
      "11.016733\n",
      "11.016733\n",
      "11.016733\n",
      "11.016734\n",
      "11.016734\n",
      "11.016733\n",
      "11.016734\n",
      "11.016733\n",
      "11.016733\n",
      "11.016733\n"
     ]
    }
   ],
   "source": [
    "w0 = torch.nn.Parameter(torch.tensor(1.))\n",
    "w1 = torch.nn.Parameter(torch.tensor(1.))\n",
    "w2 = torch.nn.Parameter(torch.tensor(1.))\n",
    "\n",
    "optimizer = torch.optim.Adam(params=[w0, w1, w2], lr=1e-3)\n",
    "\n",
    "for i in range(30000):\n",
    "    optimizer.zero_grad()\n",
    "    log_joint_prob_value = log_joint_prob(w0, w1, w2, x_train, y_train)\n",
    "    loss_value = - log_joint_prob_value\n",
    "    loss_value.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 1000 == 0 or (i==0):\n",
    "        print(loss_value.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor(-2.8305, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(-3.9310, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(0.9795, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w0)\n",
    "print(w1)\n",
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
